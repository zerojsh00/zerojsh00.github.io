[ { "title": "(NLP) DistilBERT 리뷰 및 설명", "url": "/posts/DistilBERT/", "categories": "Natural Language Processing", "tags": "Language Model, NLP, Distillation, Paper Review", "date": "2023-02-20 00:00:00 +0900", "snippet": "이 포스트는 개인적으로 공부한 내용을 정리하고 필요한 분들에게 지식을 공유하기 위해 작성되었습니다. 지적하실 내용이 있다면, 언제든 댓글 또는 메일로 알려주시기를 바랍니다.01. Introduction2018년, 자연어처리 영역의 위대한 한 획을 그은 BERT를 대표로하여, 자연어처리 영역은 대규모의 사전학습 언어모델(large-scale pre-trained langauge models)을 활용한 전이학습(transfer learning) 방식이 주를 이루고 있다.당연하게도 언어모델이 커질수록 많은 파라미터들을 사용하게 되며, 그에 따라 훌륭한 성능을 달성할 수 있게 된다.01-1. 거대 언어모델의 맹점[출처] 원 논문 : DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter우선, 주요 언어모델들의 파라미터와 이에 대한 사전학습 비용을 가볍게 살펴보자.이제는 국민 언어모델이 된 BERT를 먼저 보자. BERT-base는 약 110,000,000(1억 1천만)개의 파라미터를, BERT-large는 약 340,000,000(3억 4천만)개의 파라미터를 가지고 있다.Google research에 따르면, BERT-large를 사전학습 하는 데 16개의 Cloud TPU로 4일이 꼬박 걸렸다고 한다. Cloud TPU v2로 가정했을 때, 16(TPU 수) * 4(학습 일) * 24(시간) * 4.5(시간 당 US$) = $6,912로 계산된다. 즉, BERT-large의 사전학습 비용을 원화로 환산하면 대략 890만 원 정도라고 볼 수 있다.생성 모델인 GPT-2는 어떨까? GPT-2는 약 1,500,000,000(15억)개의 파라미터를 가지고 있다.The Register에 따르면, GPT-2의 학습에는 시간 당 $256 만큼 소요되는 256개의 Google Cloud TPU v3 cores를 사용했다고 한다.$256를 어림 잡아 원화 33만 원으로 계산한다고 했을 때, 하루에 792만 원 가량으로 계산되는데, 놀라운 점은 GPT-2를 개발한 OpenAI는 사전학습에 소요된 시간을 공개하지조차도 않았다.이후 나온 GPT-3와 현재 화두가 되고 있는 ChatGPT의 경우, 175,000,000,000(1750억)개의 파라미터를 가지고 있다. 앞서 살펴본 모델과 단순 비교만 하더라도 실로 엄청난 규모이다.참고로 GPT-3를 학습하는 데 약 1200만 달러, 즉, 150억 원 정도가 소요되었다.01-2. DistilBERT의 등장 배경위와 같이 DistilBERT의 등장 이후에도 여전히 언어모델은 일반 기업들은 손대지도 못 할 정도의 초거대 모델로 개발되고 있다. 지금도 여전한 문제이기도 한 언어모델의 거대화는 DistilBERT의 등장 배경이기도 하다. 이와 함께 논문에서 언급한 내용들은 아래와 같다. 거대 언어모델을 학습하기 위한 연산에는 상당한 carbon footprint, 즉, 환경 비용(environmental cost)이 소요됨 거대 언어모델의 연산과 메모리 소요 등을 고려했을 때, 디바이스 상에서 실시간으로 사용되기 어려움따라서 본 논문은 지식 증류(knowledge distillation) 기법을 활용하여 거대 언어모델인 BERT(오늘날에는 BERT를 거대 모델로 치지 않겠지만…)를 경량화 하는 방식을 제시한다.02. 지식 증류 (Knowledge Distillation)지식 증류(knowledge distillation)란, 이미 사전학습 되어있는 대규모 모델인 teacher로부터 경량화된 압축 모델인 student로 AI의 지식을 나누어 주는 개념이다.증류(distillation)라는 단어가 액체 혼합물을 가열하여 액체 혼합물을 분리하는 과정을 의미한다는 점을 생각하면 그 뜻이 쉽게 와닿는다.사실 지식 증류에도 다양한 방식이 있겠으나, 본 논문에서는 Geoffrey Hinton의 Softmax Temperature를 이용하였다.02-1. Softmax Temperature기본 Softmax의 한계[출처] : Softmax Temperature and Prediction Diversity일반적인 지도학습의 분류 모델은 모델의 예측 결과(logit)에 softmax를 취한 분포와 원 핫 인코딩 된 정답의 분포 간의 크로스 엔트로피 로스를 최소화 한다.이에 따라 잘 학습된 모델은 정답 클래스에 대해서는 높은 확률로 분류해 낼 것이고, 오답 클래스에 대해서는 0에 가까운 값(near-zero)을 보일 것이다.하지만, 같은 non-zero의 오답 클래스라 하더라도 어떤 클래스는 조금이나마 더 정답 클래스와 유사할 것이다. 극단적인 예를 들면, 바둑이를 분류하는 태스크에서 멍멍이라는 오답이 스파게티라는 오답보다 더 강아지와 유사하지 않은가?여기서 ‘멍멍이’와 같은 지식을 암흑 지식(dark knowledge)라고 한다. softmax로 잘 학습된 분류기는 바둑이에 대해서는 0.99에 가까운 확률로 정답으로 분류를 하고, 멍멍이에 대해서는 0.000…1에 가까운 확률로 오답으로 분류할 것이다.무언가 완벽해보이지 않는다. 즉, 단순한 softmax는 엔트로피가 낮다!Softmax에 랜덤성을 더한 Temperature Scaling[출처] : Softmax Temperature and Prediction Diversity위와 같은 softmax 함수의 한계에 대한 해결 방법이 바로 temperature scaling으로, 모델의 예측 결과인 logit 벡터를 temperature 값 $T$만큼 나누어주는 softmax 방식이다.이를 수식으로 표현하면 $\\cfrac{\\exp{(z_i / T)}}{\\sum_j \\exp{(z_j / T)}}$와 같다. 즉, temperature $T=1$ 일 경우 softmax와 같아지는 구조이며, temperature $T \\to \\infty$ 일 경우 uniform distribution을 가진다.일반적으로 $T$는 1~20 정도의 값을 사용한다고 한다.이처럼 학습 시 temperature scaling을 적용한 확률을 soft target probability라고 한다. 학습을 마친 후 추론 시에는 scaling을 하지 않고, $T=1$인 기본 softmax를 사용한다. 이러한 방식은 generalization에 효과적이어서 테스트 데이터셋에 대해 더욱 좋은 성능을 보인다고 알려져 있다.02-2. Training Loss[출처] : Knowledge Distillation of Language ModelsDistilBERT를 학습하기 위해서는 Teacher - Student Cross Entropy (Distillation Loss), Student Masked Language Modeling Loss (MLM Loss), 그리고 Teacher - Student Cosine Embedding Loss을 활용하여 학습한다.우선, downstream 태스크가 아니므로, [MASK]를 예측하는 학습을 수행하는 점을 염두에 두자.Loss 1 : Teacher - Student Cross Entropy (Distillation Loss)먼저, 사전학습 된 teacher의 logit에 대해 temperature scaling이 적용된 softmax를 취하여 [MASK]에 대한 soft target label로 삼는다.이후 사전학습을 진행할 student의 logit에 대해서도 temperature scaling이 적용된 softmax를 취하여 나온 [MASK]에 대한 예측값을 구하고, 예측값과 soft target label 간의 크로스 엔트로피 로스를 구한다.이를 distillation loss라 한다. 즉, student 모델이 teacher 모델이 가지고 있는 지식을 전수받는 과정이다.수식으로 $L_{ce} = \\sum_{i} t_{i} * \\log(s_{i})$로 표현할 수 있으며, $t_i$는 teacher의 확률이며 $s_i$는 student의 확률이다.Loss 2 : Student Masked Language Modeling Loss (MLM Loss)사전학습을 진행할 student 모델에 대해 일반적인 BERT의 Masked Language Modeling(MLM) loss $L_{mlm}$을 적용한다. MLM loss에 대해서는 temperature scaling을 적용하지 않은 기본적인 softmax를 이용한, hard target, hard prediction을 활용한다.이를 student loss라고도 부른다.Loss 3 : Teacher - Student Cosine Embedding Loss저자들은 student 모델이 더욱 teacher 모델과 닮아질 수 있도록 코사인 유사도를 활용하기까지 했다. 단순히 입력 벡터 $x$가 정답 벡터 $y$와 같게 학습하는 지도학습 방식을 넘어, teacher 모델의 hidden 벡터와 student 모델의 hidden 벡터가 일치(align)되도록 학습하는 것이다.수식으로 $L_{cos} = 1- \\cos (T(x), S(x))$로 표현할 수 있으며, $x$는 입력 벡터, $T$와 $S$는 각각 teacher 모델 및 student 모델을 의미한다.(위 그림에 따르면, teacher 모델과 student 모델의 출력값인 $T(x)$와 $S(x)$로 cosine loss를 구하지 않고, 각 모델의 단어 임베딩을 직접 활용하여 cosine loss를 구한다.두 방식 중 어떤 방식을 활용했는지에 대한 구체적인 설명이 논문에 명시되어 있지는 않은 듯 하다.)Triple Loss = Loss 1 + Loss 2 + Loss 3결과적으로 최종적인 triple loss는 $L = \\alpha * L_{ce} + \\beta * L_{MLM} + \\gamma * L_{cos}$이며, 이때 $\\alpha + \\beta + \\gamma = 1$이다.03. DistilBERT의 디테일03-1. Student Model의 구조Next Sentence Prediction(NSP) 태스크를 수행하지 않음DistilBERT의 student 모델은 기본적으로 BERT와 동일하나, 다음과 같은 차이가 있다. token-type embedding의 제거 token-type embedding이란, transformers 라이브러리의 token_type_ids에 대응되며, BERT에서 [SEP] 토큰으로 두 문장 간 관계를 학습할 때 각 문장을 구분함 pooler의 제거 pooler란, BERT에서 얻은 contextual embedding 중 [CLS] 토큰의 임베딩에 해당됨 이러한 차이는 기존 BERT가 사전학습 할 때 수행하는 Next Sentence Prediction(NSP) 태스크를 수행하지 않음을 의미한다.teacher BERT를 활용한 초기화[출처] : Distillation of BERT-Like Models: The Theory또한 위 그림과 같이 teacher 모델의 레이어의 절반만을 복사하여 초기화함으로써 레이어의 수를 절반으로 감소시켰다.03-2. 기타 학습 세부 사항DistilBERT는 아주 큰 배치 사이즈(배치당 4K의 데이터)를 활용하여 학습하였다. NSP 태스크를 수행하지 않았으며, RoBERTa의 트릭인 dynamic masking 기법을 사용하였다. dynamic masking은 입력을 만들 때 마다 masking을 다시 하는 기법이다.데이터와 컴퓨트 파워BERT와 동일한 데이터인 English Wikipedia와 Toronto Book Corpus를 활용했다. DistilBERT 학습은 16GB V100 GPU 8대로 90시간이 소요되었다. 참고로 RoBERTa의 경우 32GB V100 GPU 1024대로 하루가 걸렸다는 점을 고려하면 대단한 수치다.04. 결과 및 결론distilBERT는 distillation 기법으로 빠르게 학습하였음에도 불구하고, 기존 BERT에 비해 40%나 가벼워졌고 60%나 빨라졌으며 97% 성능을 유지했다!05. 참고 문헌[1] 원 논문 : DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter[2] 블로그 : The Staggering Cost of Training SOTA AI Models[3] Harshit Sharma의 포스트 : Softmax Temperature and Prediction Diversity[4] kaggle : 📢NLPStarter4📄🤗DistilBert,Bert(Base-Cased)🤗:)[5] Alex Nim의 포스트 : Knowledge Distillation of Language Models[6] Remi Ouazan Reboul의 포스트 : Distillation of BERT-Like Models: The Theory" }, { "title": "(NLP) StarSpace", "url": "/posts/StarSpace/", "categories": "Natural Language Processing", "tags": "NLP, Embedding, Paper Review", "date": "2023-02-13 00:00:00 +0900", "snippet": "이 포스트는 개인적으로 공부한 내용을 정리하고 필요한 분들에게 지식을 공유하기 위해 작성되었습니다. 지적하실 내용이 있다면, 언제든 댓글 또는 메일로 알려주시기를 바랍니다.00. 들어가기에 앞서2017년, Facebook AI에서 공개한 StarSpace는 그 구조가 간단하면서도 다양한 도메인의 내용들을 임베딩할 수 있다는 강력한 장점을 가지고 있다.챗봇의 의도 분류기를 연구했던 시절에 처음 접했던 개념이었지만, 개인적인 필요에 의해 다시 한 번 살펴볼 일이 있어 이참에 본 포스트를 통해 정리하고자 한다.원 논문 StarSpace: Embed All The Things!를 참고하기를 바란다.01. Introduction “a general-purpose neural embedding model”StarSpace는 아래와 같이 다양한 문제들을 해결할 수 있는 신경망 임베딩 모델이다. 텍스트 분류 태스크 (자연어처리 분야) e.g., 감정 분석, 의도 분류 등 엔티티에 대해 랭크를 부여하는 태스크 (Information Retrieval 분야) e.g., 웹에서 쿼리를 날렸을 때, 웹 상의 수많은 도큐먼트들에 대해서 랭킹을 부여하는 등 협업 필터링 기반의 추천 (추천시스템 분야) 문서, 음악, 비디오 추천 등 이산적인 feature로 이루어진 콘텐츠에 대한 추천 (추천시스템 분야) e.g., 문서의 단어들 등 그래프 임베딩 (그래프 임베딩 분야) e.g., Freebase 기타 단어, 문장, 문서 등에 대한 임베딩 등등StarSpace 모델은 이처럼 다양한 분야에서 임베딩 태스크들에 응용할 수 있다는 특징으로 그 이름이 지어졌다.Star는 *, 즉, 모든 엔티티 타입을 의미하며, Space는 임베딩 공간을 의미하는데, 풀어보자면, 엔티티 타입이 어떠하든 모든지 한 공간에 임베딩 할 수 있다고 해석할 수 있다.02. Model02-1. 이산적인 특징 벡터를 입력 받는 StarSpaceStarSpace 모델을 통해 임베딩 하고자 하는 entity는 이산적인(discrete) 특징을 가진다. 대표적인 예로는 단어의 수를 셈하여 만드는 BOW(Bag-Of-Words) 벡터가 있겠다.풀고자하는 태스크에 따라 꼭 단어가 아니더라도, 특정 유저가 좋아요를 누른 영화나 물건 등과 같이 이산적으로 표현할 수 있는 특징이면 StarSpace 모델을 활용하기에 적합하다.(허나, 필자의 개인적인 생각과 경험으로는, 반드시 이산적인 특징 벡터만 가능한가 싶다. 예컨대 실수 값으로 이루어진 TF-IDF 벡터도 입력값으로 쓸 수 있어 보인다.)02-2. 서로 다른 종류의 엔티티를 같은 공간 상에 임베딩하는 StarSpaceStarSpace의 가장 강력한 특징은 서로 다른 종류의 엔티티를 같은 공간 상에 임베딩 할 수 있다는 점이다. ‘서로 다른 종류의 엔티티’란 뭘까? 예를 들면, 사람들이 올려놓은 게시글과, 이에 대해서 부여된 해시태그들이라고 생각해볼 수 있겠다.[출처 : Rasa Algorithm Whiteboard (Youtube)]위 그림을 살펴보자.(d2) : I love veggie pizza라는 document는 #pizza라는 해시태그가 달릴수도 있으며, #positive 및 #vegetarian이라는 해시태그 또한 달릴 수 있다. 또한 (d5) : Gimme Pepperoni Pizza라는 document 역시 피자와 관련된 글이므로 앞선 문장처럼 #pizza의 해시태그가 달릴 수 있다.이러한 관계들을 위의 그림과 같이 표(table) 형태로 표현할 수 있다.그렇다면 어떻게 해야 이러한 관계들을 이용하여 같은 공간 상에 임베딩 할 수 있을까?[출처 : Rasa Algorithm Whiteboard (Youtube)]StarSpace 모델의 핵심은 동일한 레이블(e.g., 해시태그)이 부여된 엔티티(e.g., document)는 가깝게 임베딩되고, 다른 레이블이 부여된 엔티티는 멀리 임베딩 되도록 하는 메커니즘이다.그렇게 학습을 마치고 나면, 엔티티 임베딩들과 레이블 임베딩들이 유사성을 기반으로 하여 일종의 클러스터를 이룰 것이다.이는 StarSpace가 가지는 중요한 특징이라고 할 수 있다. BERT와 같이 대규모 일반 도메인 말뭉치를 활용하여 학습하는 언어모델과 달리, 우리가 가지고 있는 엔티티에 해당하는 도메인으로 학습하기 때문에, 특정 closed domain task를 풀 때 훨씬 유용하게 사용될 수 있다.이러한 특징 때문에 Rasa에서 StarSpace를 시나리오 기반 챗봇의 의도 분류기로써 활용하는 것으로 생각된다.02-3. 모델의 구조[출처 : Rasa Algorithm Whiteboard (Youtube)]모델의 구조는 제법 심플하다. 엔티티에 대한 임베딩 및 레이블에 대한 임베딩을 각각 linear layer를 통과시켜 $k$ 차원의 공감에 projection 한다.그후 코사인 유사도 또는 벡터의 내적을 통해 유사도 점수를 구한 후, 해당 점수와 레이블 간의 ranking loss를 구하는 방식이다.[출처 : https://cw.fel.cvut.cz/old/_media/courses/xp36vpd/vpdstarspace.pdf]03. 구현아래는 StarSpace를 참고하여 의도 분류를 구현한 코드의 예시다.import torchimport torch.nn as nnimport torch.nn.functional as Fimport torch.optim as optimdevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')class StarSpace(nn.Module): def __init__(self, X_dim, n_labels, emb_dim=32, drop_rate=0.5): super().__init__() # feature들에 대한 임베딩 self.feature_emb_layer = nn.Sequential( nn.Linear(X_dim, 64), nn.ReLU(), nn.Dropout(p=drop_rate), nn.Linear(64, emb_dim) ).to(device) # 레이블에 대한 임베딩 self.label_emb = nn.Embedding(n_labels, emb_dim, max_norm=10.0).to(device) self.label_emb_layer = nn.Sequential( nn.ReLU(), nn.Linear(emb_dim, emb_dim), nn.ReLU(), nn.Linear(emb_dim, emb_dim) ).to(device) # loss self.ce_loss = nn.CrossEntropyLoss() # Softmax + CrossEntropyLoss self.softmax = nn.Softmax(dim=-1) def forward(self, X, y): # 임베딩 레이어를 통과하여 임베딩을 획득 feature_emb = self.feature_emb_layer(X) # 어차피 positive target 임베딩과 negative target 임베딩이 함께 있음 y_embs = self.label_emb_layer(self.label_emb.weight) # 정답에 대한 레이블의 스코어와 negative 레이블의 스코어가 함께 계산됨 sim_scores = torch.matmul(feature_emb, y_embs.transpose(0, 1)) loss = self.ce_loss(sim_scores, y) confidence, prediction = torch.max(self.softmax(sim_scores), dim=-1) return {\"loss\": loss, \"prediction\": prediction, \"confidence\": confidence}04. 참고 문헌[1] 원 논문 : StarSpace: Embed All The Things![2] Rasa Algorithm Whiteboard : StarSpace" }, { "title": "(NLP) BERTopic 개념 정리", "url": "/posts/BERTopic/", "categories": "Natural Language Processing", "tags": "Language Model, NLP, Topic Modeling, Paper Review", "date": "2022-09-21 00:00:00 +0900", "snippet": "이 포스트는 개인적으로 공부한 내용을 정리하고 필요한 분들에게 지식을 공유하기 위해 작성되었습니다. 지적하실 내용이 있다면, 언제든 댓글 또는 메일로 알려주시기를 바랍니다.01. Introduction전통적인 토픽 모델링의 방법으로는 Latent Dirichlet Allocation(LDA)와 Non-Negative Matrix Factorization(NMF)가 주로 사용된다. 이들은 document를 단어의 출현 빈도 기반으로 다루는 표현하는 방식인 Bag-of-Words(BoW)로써 설명한다는 특징이 있다. 따라서 모델이 단어들 간의 의미론적 관계를 포착하지 못하는 한계가 있다. 한편, BERT와 같은 트랜스포머 인코더 기반의 모델은 단어들 간의 양방향 문맥이 반영된 representation을 생성할 수 있다는 장점이 있다.BERTopic은 이러한 양방향의 의미를 파악할 수 있는 BERT의 장점을 토픽 모델링 태스크에 활용하고자 했다. 이를 위해, BERTopic은 사전 학습된 트랜스포머 기반 언어 모델(i.e., BERT)로부터 (1)document의 정보를 파악한 임베딩을 생성하고, 해당 임베딩으로 (2)차원 축소 및 클러스터링을 수행한 후, (3)class-based TF-IDF를 통해 토픽의 representation을 생성한다.02. Document EmbeddingsBERTopic은 벡터 공간 상에서 가까운 document는 의미론적으로 연관성이 있는 주제를 다룬다는 가정 하에, document를 벡터 공간 상에 임베딩 하였다. 임베딩 방법론으로는 BERT의 문장 임베딩 성능을 우수하게 개선시킨 Sentence-BERT(SBERT)를 활용했다. 논문에서는 SBERT를 사용하였으나, 이외에도 distil-BERT 등 어떠한 임베딩 방법을 사용하든 무관하다고 한다.아래의 코드는 distil-BERT로 임베딩을 구하는 예다. PyTorch 설치 이후, pip install sentence-transformers로 패키지를 설치하여 실행할 수 있다.from sentence_transformers import SentenceTransformermodel = SentenceTransformer('distilbert-base-nli-mean-tokens')embeddings = model.encode(data, show_progress_bar=True)출처 : 공식 포스트03. Document Clustering유사한 토픽을 가지는 document는 임베딩 공간 상에 가까이 위치하도록 클러스터링 하고자 한다.클러스터링에 앞서, 데이터의 차원이 크다면, 데이터 포인트 간의 최근접 거리가 멀어지는 차원의 저주가 발생하게 된다. (Allaoui et al., 2020)에 따르면, UMAP을 활용한 차원 축소 방식은 저차원 공간에서도 local 구조를 잘 보존할 수 있기 때문에 k-Means나 HDBSCAN 클러스터링과 함께 사용하면 성능 향상에 효과적으로 기여할 수 있다고 한다.이에 BERTopic의 저자들은 고차원 데이터의 local 및 global 특징 모두를 잘 보존할 수 있는 UMAP을 활용하여 document 임베딩의 차원을 축소하였다. 이후, 차원이 축소된 document 임베딩에 대해서 DBSCAN 알고리즘의 계층적(hierarchical) 버전인 HDBSCAN 알고리즘을 적용하여 클러스터링 하였다.아래의 코드는 UMAP을 활용하여 차원 축소된 임베딩을 구하는 예다. pip install umap-learn 명령으로 패키지를 설치할 수 있다.import umapumap_embeddings = umap.UMAP(n_neighbors=15, n_components=5, metric='cosine').fit_transform(embeddings)출처 : 공식 포스트또한 아래의 코드는 HDBSCAN을 통해 클러스터링을 수행하는 예다. pip install hdbscan 명령으로 관련 패키지를 설치할 수 있다.import hdbscancluster = hdbscan.HDBSCAN(min_cluster_size=15, metric='euclidean', cluster_selection_method='eom').fit(umap_embeddings)출처 : 공식 포스트04. Topic Representation through Class-based TF-IDF클러스터링을 완료하면, 각 클러스터마다 하나의 토픽이 배정될 것이다. 한편, 우리가 알고 싶은 정보는 결국 ‘각 클러스터들이 다른 클러스터와 어떤 점에서 다른 것이고, 각 document 클러스터에서 어떻게 토픽을 도출해내는가’라고 할 수 있다. 이에 BERTopic의 저자는 TF-IDF의 구조를 변형한 class-based TF-IDF를 제안한다. class-based TF-IDF는 개별 document가 아닌, document 클러스터(토픽) 관점에서 각 단어들의 중요도를 모델링한다. 즉, 각 클러스터마다 topic-word distribution을 구할 수 있는 것이다.TF-IDFclass-based TF-IDF를 보기 위해서 우선 TF-IDF부터 살펴보자. TF-IDF는 document 내에서 단어의 빈도수를 고려하여 중요한 정도를 가중치로 주는 방법으로,$W_{t,d}=tf_{t,d} \\cdot \\log(\\cfrac{N}{df_t})$ 와 같이 표현할 수 있다.우선, $tf_{t, d}$는 특정 document $d$에서 특정 단어 $t$의 등장 횟수를 의미한다. 즉, 특정 단어 $t$가 ‘특정’ document에서만 많이 나오면 TF-IDF 값이 커진다.또한 log term 안의 분모에 위치한 $df_t$는 특정 단어 $t$가 등장한 document의 수를 의미하고, 분자에 위치한 $N$은 총 document의 수를 의미한다. 따라서 분모에 위치한 $df_t$를 고려하면, 특정 단어 $t$가 ‘여러’ document 전반에 걸쳐서 많이 나오면 TF-IDF 값이 작아진다. 예를 들어, “a”나 “the”와 같은 단어의 경우 모든 document에서 많이 나오므로 그 값이 작다.Class-based TF-IDFclass-based TF-IDF는 document들로 클러스터링 된 군집들에 대하여 TF-IDF의 개념을 적용하기 위해 변형된 형태라고 볼 수 있으며, $W_{t, c}=tf_{t, c} \\cdot \\log(1 + \\cfrac{A}{tf_t})$로 정의한다.우선 class-based TF-IDF는 TF-IDF와 달리 $tf_{t, c}$를 사용한다. class-based TF-IDF에서는 클러스터 내 모든 document들을 concatenate 함으로써 단 하나의 single document로 간주하는데, $tf_{t, c}$는 특정한 ‘하나’의 클러스터(i.e., class), 다시 말해 concatenate 되어있는 모든 document들에서 특정 단어 $t$가 등장한 횟수를 의미한다. 따라서 특정 단어 $t$가 ‘특정’ 클러스터에서만 많이 나오면 class-based TF-IDF 값이 커진다.또한 log term 안의 분모에 위치한 $tf_t$는 ‘모든’ class에서 단어 $t$의 등장 횟수를 의미하고, 분자에 위치한 $A$는 클래스 당 평균 단어 수를 의미한다. 따라서 분모에 위치한 $tf_t$를 고려하면, 특정 단어 $t$가 ‘여러’ 클러스터 전반에 걸쳐서 많이 나오면 class-based TF-IDF 값이 작아진다. 참고로 여기서 1을 더한 이유는 이 값이 반드시 양수만 가질 수 있도록 하기 위함이다.이러한 과정을 마친 후, 자잘한 class-based TF-IDF representation을 사용자가 지정한 토픽의 수만큼 가장 가까운 representation과 반복적으로 merge 함으로써 토픽의 수를 조정할 수 있다.참고 문헌[1] 원 논문 : BERTopic: Neural topic modeling with a class-based TF-IDF procedure[2] 저자의 블로그 : Topic Modeling with BERT" }, { "title": "(K8S) 인그레스와 인그레스 컨트롤러", "url": "/posts/Ingress/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Network, Ingress", "date": "2022-09-16 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.인그레스의 간단한 개념인그레스(ingress)라는 단어는 외부에서 내부로 향하는 것을 의미한다. 예를 들어, 인그레스 트래픽은 외부에서 서버 내부로 들어오는 트래픽을 의미한다.쿠버네티스에서 인그레스란, 클러스터 외부에서 내부로 접근하는 요청들을 어떻게 처리할 것인지 정의해둔 규칙들의 모음이다. 인그레스는 아래와 같은 기능들을 제공한다. 트래픽 로드밸런싱 서비스에 외부 URL을 제공함 (외부 요청을 라우팅) /apple, /apple/red 등과 같이 특정 경로로 들어온 요청을 어떠한 서비스로 전달할지 정의하는 라우팅 규칙을 설정할 수 있음 SSL 인증서 처리 여러 개의 서비스로 요청을 라우팅할 때, 보안 연결을 위한 인증서를 쉽게 적용할 수 있음 도메인 기반 가상 호스팅을 제공함 같은 IP에 대해 다른 도메인 이름으로 요청이 왔을 때, 어떻게 처리할 것인지 정의할 수 있음 인그레스 오브젝트 자체는 위와 같은 기능들에 대해 규칙들을 정의해둔 리소스이고, 실제로 동작하기 위해서는 인그레스 컨트롤러라는 특별한 서버가 필요하다. 즉, 실제로 외부 요청을 받아들이는 인그레스 컨트롤러 서버가 인그레스 오브젝트에 정의된 규칙들을 로드해서 사용하는 것이다.인그레스 컨트롤러는 Nginx 웹 서버 인그레스 컨트롤러, GKE의 인그레스 컨트롤러, Contour, Istio, HAPROXY, Kong 등 매우 다양하게 존재한다. 이들 중 쿠버네티스 커뮤니티에서 활발히 사용되고 있는 Nginx의 인그레스 컨트롤러가 대표적이다. 인그레스 컨트롤러는 쿠버네티스에서 default로 배포하지 않기 때문에 직접 설치를 위한 YAML 파일을 내려받아 설치하여 디플로이먼트를 통해 배포하든 해야 한다.인그레스를 왜 사용할까?NodePort 또는 LoadBalancer 타입의 서비스를 사용해도 위의 기능들을 얼추 구현할 수는 있다. 그럼에도 인그레스를 사용해야 하는 이유가 있을까?위 그림과 같이 애플리케이션이 3개의 디플로이먼트로 생성되어 있다고 예를 들어보자.인그레스를 사용하지 않고서 NodePort 또는 LoadBalancer 타입의 서비스를 이용하여 클러스터 외부에서 파드에 접근할 수 있도록 하였다.그럴싸하게 작동할 수 있어 보이지만, 서비스마다 세부적인 설정을 할 때마다 복잡성이 증가하게 된다. 예를 들어, SSL/TLS 보안 연결, 접근 도메인에 따른 라우팅 등을 구현하기 위해서는 각 서비스와 디플로이먼트에 대해서 개별적으로 설정을 해야 한다.이와 같은 방법으로는 애플리케이션의 스케일이 커질수록 복잡성은 매우 커질 것이다.한편, 인그레스 오브젝트를 사용하면 서비스의 URL마다 따로따로 접근할 필요 없이, 하나의 인그레스 URL 엔드포인트를 사용하여 복잡성을 줄일 수 있다. 즉, 클라이언트는 인그레스의 URL로만 접근하게 되고, 요청에 따라 인그레스에 정의된 라우팅 규칙에 맞게 처리되어 적절한 디플로이먼트의 파드로 요청이 전달될 수 있는 것이다. 보안 연결 등과 같은 세부 설정 또한 서비스와 디플로이먼트가 아닌 인그레스에서 처리되기 때문에, 각 서비스와 디플로이먼트에 일일이 설정을 적용할 필요 없이 복잡한 설정들을 한번에 관리할 수 있다.인그레스 사용 방법인그레스를 사용하기 위해서는 다음의 순서를 따라야 한다. 인그레스 컨트롤러를 생성한다. 예를 들어, 공식 깃허브에서 제공되는 Nginx 인그레스 컨트롤러의 YAML 파일을 이용할 수 있다. 인그레스 컨트롤러를 외부로 노출하기 위해 인그레스의 서비스를 생성한다. kubectl apply -f {인그레스 컨트롤러 YAML 파일을 제공하는 경로}.yaml 명령으로 인그레스 컨트롤러를 실행한다 하더라도, 인그레스 컨트롤러 서버(e.g., Nginx)의 디플로이먼트만 생성되었을 뿐, 해당 (Nginx)서버의 파드에 접근할 수 있는 서비스가 생성된 것은 아니므로, 직접 생성해야 한다. 요청 처리 규칙을 정의하는 인그레스 오브젝트를 생성한다. 인그레스 오브젝트를 생성하면, 인그레스 컨트롤러는 항상 인그레스 리소스를 지켜보고 있다가 자동으로 로드해서 인그레스 컨트롤러 웹 서버(e.g., Nginx)에 적용한다. 기본적으로 모든 네임스페이스의 인그레스 리소스를 다룬다. 인그레스 컨트롤러 서버로 들어온 요청은 인그레스 규칙에 따라 적절한 서비스로 전달된다.인그레스 컨트롤러 생성의 예예를 들어, ingress-nginx를 생성하고자 한다면, https://kubernetes.github.io/ingress-nginx/deploy/ 사이트에서 아래 명령어를 참고하여 kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.3.1/deploy/static/provider/cloud/deploy.yaml 명령어로 생성할 수 있다.이후, 다음과 같이 ingress-nginx 네임스페이스의 디플로이먼트와 파드를 확인해보면 Nginx 웹 서버가 생성되어 있을 것이다.$ kubectl get deployment -n ingress-nginxNAME READY UP-TO-DATE AVAILABLE AGEingress-nginx-controller 1/1 1 1 6m41s$ kubectl get pods -n ingress-nginxNAME READY STATUS RESTARTS AGEingress-nginx-admission-create-sln9j 0/1 Completed 0 6m48singress-nginx-admission-patch-r7p5j 0/1 Completed 1 6m48singress-nginx-controller-b4fcbcc8f-sm4qm 1/1 Running 0 6m48s하지만 이처럼 YAML 파일을 통해 Nginx 인그레스 컨트롤러를 설치했다 하더라도, Nginx 디플로이먼트만 생성됐을 뿐, Nginx 웹 서버를 클러스터 외부로 노출하기 위한 서비스가 생성되지는 않았다. 따라서 다음 과정인 서비스를 환경에 맞게 생성해야 한다.인그레스 컨트롤러를 노출하기 위한 서비스 생성의 예# ingress-service-example.yamlapiVersion: v1kind: Servicemetadata: name: ingress-nginx namespace: ingress-nginx # ingress-nginx-controller 디플로이먼트가 위치한 ingress-nginx 네임스페이스에 서비스를 생성함spec: type: NodePort # AWS, GKE 등 LoadBalancer 타입의 서비스를 사용할 수 있다면 LoadBalancer를 사용함 ports: - name: http port: 80 targetPort: 80 protocol: TCP - name: https port: 443 targetPort: 443 protocol: TCP인그레스 컨트롤러를 노출하기 위한 서비스는 ingress-nginx-controller 디플로이먼트가 위치한 ingress-nginx 네임스페이스에 생성한다. 이 예제에서는 간단한 테스트를 위해서 NodPort 타입의 서비스를 만들었으나, LoadBalancer 타입의 서비스를 활용할 수 있는 AWS 등의 환경에서는 LoadBalancer 타입으로 서비스를 생성하여 사용한다.이후, kubectl apply -f ingress-service-example.yaml 명령으로 서비스를 실행한다.인그레스 오브젝트 생성의 예# ingress-example.yamlapiVersion: networking.k8s.io.v1beta1kind: Ingress # 인그레스 오브젝트를 생성하므로metadata: name: ingress-examplespec: rules: - host: simon.example.com # 해당 도메인 이름으로 접근하는 요청에 대해서 처리 규칙을 적용함 http: paths: - path: /subpath # 해당 경로에 들어온 요청을 backend에 정의된 서비스로 전달함 backend: serviceName: hostname-service # '/subpath' 경로로 들어온 요청을 hostname-service라는 Servce에 전달함 servicePort: 80 # serviceName에 설정한 서비스의 포트kubectl apply -f ingress-example.yaml 명령어를 통해, 요청을 처리하는 규칙을 정의하는 인그레스 오브젝트를 생성할 수 있다. 이후, 인그레스 컨트롤러가 인그레스 오브젝트를 발견하여 규칙을 적용한다.참고로 위 예제에서는 simon.example.com/subpath라는 요청이 있을 때, ‘hostname-service’라는 이름의 서비스로 요청을 전달한다. kubectl apply -f hostname-deployment.yaml 및 kubectl apply -f hostname-service.yaml 명령으로 미리 파드와 서비스를 생성해두어야 한다. (이 과정은 생략)참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스[3] 따배쿠 강의 : 8-1 Kubernetes Ingress 개념과 Ingress Controller 설치!" }, { "title": "(K8S) 쿠버네티스에서의 CoreDNS", "url": "/posts/CoreDNS-in-Kubernetes/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Network, CoreDNS", "date": "2022-09-16 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.리눅스에서의 DNS/etc/hosts리눅스 환경에서 DNS를 사용할 수 있는 방법은 /etc/hosts 파일을 이용하는 것이다. 이는 IP와 도메인 이름을 매핑하는 역할을 한다. 예를 들어, 아래와 같이 /etc/hosts 파일을 열어보면, 127.0.0.1이 localhost로 등록되어 있는 것을 확인할 수 있다.$ cat /etc/hosts# localhost is used to configure the loopback interface# when the system is booting. Do not change this entry.##127.0.0.1\tlocalhost... 생략 .../etc/resolv.conf/etc/hosts 파일에 도메인이 등록되어 있지 않는 경우, DNS resolver, 즉, 사용하고자 하는 DNS 서버(네임 서버) 목록을 기록한 파일인 /etc/resolv.conf를 이용한다. resolv.conf의 nameserver 란에 해당 서버에서 사용할 DNS 서버를 지정할 수 있다.Core DNS의 필요성위와 같이 각각 IP 주소가 할당되어 있는 파란색 파드와 보라색 파드가 있다고 하자. 각 파드에서 위와 같이 /etc/hosts에 상대 파드의 IP 주소와 도메인 이름을 기입해두면, 각자 상대방의 도메인 이름을 이용할 수 있겠다. 문제는 클러스터 내에 파드가 매우 많다는 점이다. 즉, 이러한 방법은 적합하지 않다.반면, 10.96.0.10을 사용하는 DNS 서버가 있다고 하자. 이 경우, DNS 서버에 각 파드의 이름(실제로는 ‘.’ 대신 ‘-’를 사용한 파드의 IP 주소)을 저장해두고, 각 파드에서는 /etc/resolv.conf에 nameserver와 DNS 서버의 IP 주소를 매핑함으로써 DNS 서버에서 한꺼번에 도메인 이름을 관리할 수 있다. 이러한 방식이 쿠버네티스의 CoreDNS가 도메인 이름을 관리하는 방식이다.CoreDNS클러스터 내에 배포되어 있는 CoreDNS는 CNCF 재단에서 관리하는 프로젝트로, 1.12 버전 이후 DNS 서버를 배포하는 역할을 한다. (1.12 버전 이전에는 kube-dns가 사용되었다.)CoreDNS는 쿠버네티스 클러스터를 지켜보고 있다가 새로운 파드나 서비스가 생성되면 CoreDNS의 데이터베이스에 DNS record를 생성한다.CoreDNS 서버는 kube-system 네임스페이스에서 레플리카셋을 통해 두 개의 파드로 배포되어 있다. 따라서 다른 컴포넌트가 CoreDNS 파드에 접근할 수 있도록 CoreDNS의 서비스를 이용한다.CoreDNS의 서비스는 kube-system 네임스페이스에서 kube-dns라고 부른다. 이러한 CoreDNS의 서비스, 즉, kube-dns의 IP 주소가 모든 파드의 /etc/resolv.conf 파일의 nameserver 란에 기입되어야 하는데, 이마저도 파드가 생성될 때 쿠버네티스가 자동으로 처리해준다.참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스[3] 산티아고의 기술 블로그 : Kubernetes CoreDNS" }, { "title": "(K8S) 쿠버네티스에서의 DNS", "url": "/posts/DNS-in-Kubernetes/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Network, DNS", "date": "2022-09-15 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.각각의 노드는 node name과 IP 주소가 부여되어 있으며, 이들은 DNS 서버에 등록되어 있다.그러나 이번에는 노드에 대한 DNS가 아닌, 쿠버네티스 클러스터 내부에서 사용 가능한 DNS를 다루고자 한다. 즉, 클러스터 내에서 파드 간 통신을 할 때 IP가 아닌 도메인을 설정해두고 사용하는 개념을 다룬다.built-in DNS 서버쿠버네티스는 클러스터를 생성할 때 default로 built-in DNS 서버를 배포한다. 참고로, 쿠버네티스를 직접 수동으로 설치한다면, 쿠버네티스 DNS 서버 또한 직접 설치해야 한다.default namespace 하에서쿠버네티스 클러스터 내부에서 사용하는 도메인은 서비스와 파드에 대해서 사용할 수 있고, 일정한 패턴을 가지고 있다.예를 들기 위해서, 노드 단위로는 신경쓰지 않고, 노드 내에 있는 파드와 서비스만을 예시로 다룬다. 위와 같이, default namespace에서 test 파드와 web 파드가 존재하고, test 파드에서 web 파드로 접근하기 위해 web-service 서비스를 만들었다고 해보자. 각각은 모두 IP 주소가 할당되어 있다.쿠버네티스는 서비스와 파드에 대해서 DNS record를 생성한다. 그 덕에 서비스에 접근할 때 IP 주소가 아니라 DNS name으로 접근할 수 있다. 예를 들어, 서비스가 생성될 때마다 쿠버네티스의 DNS 서비스는 위 그림의 표와 같이 서비스의 이름과 IP 주소를 매핑하는 record를 생성한다. 따라서 클러스터 내 어떤 파드든지 web-service라는 서비스 이름으로 서비스에 접근할 수 있게 된다.또 다른 namespace 하에서web 파드와 web-service 서비스가 apps라는 또 다른 namespace에 있다고 가정하자. 이 경우, test 파드에서 web 파드에 접근하기 위해서 web-service를 거친다면, namespace 이름인 apps를 마치 이름의 성(last name)으로 여기고, web-service.apps와 같이 namespace 이름을 명시해주어야 접근할 수 있다.서비스의 DNS record서비스의 경우, {서비스의 이름}.{namespace의 이름}-svc-cluster.local이 도메인 이름이 된다.풀어 설명하자면, 어떤 namespace 하에 있는 모든 서비스와 파드는 namespace의 이름(e.g., apps)이라는 subdomain에 그룹화 된다. 또한 모든 서비스들은 svc라고 불리우는 또 다른 subdomain에 그룹화 된다. 마지막으로 모든 파드들과 서비스들은 default로 cluster.local로 불리우는 root domain에 그룹화 된다. 따라서 위 예시에서 IP 주소가 아닌, 도메인 이름으로 서비스에 접근하고자 하면, web-service.apps.svc.cluster.local와 같이 접근할 수 있다.파드의 DNS record파드의 경우, {파드 IP 주소('.' 대신 '-' 사용)}.{namespace의 이름}-pod-cluster.local이 도메인 이름이 된다.풀어 설명하자면, 파드의 IP 주소를 입력할 때, .을 -로 대체하여 10.244.2.5와 같은 표기 대신 10-244-2-5와 같이 사용한다. namespace는 서비스에서처럼 동일하게 namespace 이름을 사용하지만, 타입은 pod가 된다. 이후, 서비스와 동일하게 cluster.local을 붙임으로써 도메인 이름으로 접근할 수 있다.참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스[3] 쿠버네티스 공식 documentation : DNS for Services and Pods[4] 아리수 님의 블로그 : 쿠버네티스 DNS(kubernetes dns)" }, { "title": "(K8S) 서비스 네트워킹", "url": "/posts/Service-Networking/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Network, Service", "date": "2022-09-14 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.이전 글들에서 파드 간에 네트워크 연결이 될 수 있도록 많은 개념들을 정리했지만, 사실 파드들끼리 직접적으로 연결되도록 설정할 일은 많이 없고, 그대신 서비스(서비스)를 이용해야 한다.Recap: 서비스다음과 같이 노드 NODE1, NODE2, NODE3가 있고, 각 노드 안에는 파드(동그라미)들이 존재한다고 하자. 자신이 아닌 다른 파드에서 호스트되는 서비스를 이용하고 싶다면, 반드시 해당 파드의 서비스(그림에서 세모)를 통해 접근해야 한다. 예를 들어, NODE1의 파란색 파드가 주황색 파드에 접근하고자 하면, 반드시 주황색 서비스를 생성하고 이를 통해 접근해야 한다. 이 경우, 주황색 서비스는 별도의 IP(10.99.13.178)가 부여되는 ClusterIP 타입의 서비스이다. 서비스는 클러스터 내에서 모두가 접근할 수 있으므로, 다른 노드에 있는 파드들 또한 주황색 서비스를 통해서 접근할 수 있게 된다.한편, 보라색 파드는, 가령 웹 애플리케이션과 같이, 클러스터 내부 뿐만 아니라 외부에서도 접근이 되어야 하는 파드라고 해보자. 이 경우, 보라색 서비스 또한 ClusterIP 타입과 유사하게 IP(10.99.13.178)를 가지는 서비스이며, 클러스터 내부에서 모두 보라색 서비스를 거쳐 접근할 수 있다. 다른 점은 클러스터 외부에서 접근할 수 있도록 클러스터 내 모든 노드에서 특정 포트(30080)를 개방하고 있다. 이 경우, 보라색 서비스는 NodePort 타입의 서비스이다.이번글은 어떻게 서비스가 위와 같이 IP 주소를 할당 받을 수 있으며, 클러스터 내부에서 접근될 수 있는지, 그리고 NodePort 타입의 경우 각 노드에서 어떻게 포트를 통해 외부 사용자가 접근할 수 있는지 등을 간단하게 짚고 간다.Kubelet과 파드쿠버네티스의 모든 노드에는 kubelet이 하나씩 존재하며, 각 kubelet은 kube-apiserver와 통신하며 파드를 노드에 생성한다. kubelet이 파드를 생성할 때, 해당 파드의 네트워크를 구성하기 위해 CNI 플러그인을 호출한다.Kube-proxy와 서비스kube-proxy는 쿠버네티스에서 서비스를 만들었을 때 Cluster IP나 NodePort로 접근할 수 있게 하는 실제 조작을 수행하는 컴포넌트다.쿠버네티스의 각 노드에는 kube-proxy 또한 하나씩 존재하며, 각 kube-proxy는 kube-apiserver와 통신하며 서비스를 노드에 생성한다. 파드와는 다르게, 서비스는 cluster-wide한 개념이므로, 특정 노드에 할당되어 생성되지는 않으며, 클러스터 전반에 걸쳐서 존재하는 개념이다.엄밀하게 말하자면, 서비스는 그 실체가 없다고 볼 수도 있다. 파드와 서비스를 비교했을 때, 파드는 컨테이너 네임스페이스가 별도로 존재하고, IP가 할당된 인터페이스도 있지만, 서비스에는 그런 개념이 없다. 서비스는 단지 가상 객체(virtual object)일 뿐이다.그렇다면 어떻게 서비스에 IP 주소가 부여되고, 서비스를 통해서 파드에 있는 애플리케이션에 접근할 수 있는 것일까?우선, 사전에 정의되어 있는 서비스의 IP:Port의 범위(predfined range)들이 있다고 하자. 각 노드에서 실행되고 있는 kube-proxy 컴포넌트는 IP:Port(그림에서 10.99.13.178:80) 정보가 들어오면, 사전에 정의되어 있는 서비스의 IP:Port 범위에 따라 해당 서비스의 IP:Port에 대응되는 클러스터 내 특정 노드의 파드(그림에서 10.244.1.2)로 전달하는 forwarding rule을 정의하여 사용한다.Forwarding RuleIP:Port 트래픽이 있을 때, kube-proxy가 특정 노드의 파드로 요청을 전달하기 위한 관리 방법으로는 iptables(default proxy mode), userspace, IPVS가 있다.참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스[3] 김징어 님의 블로그 : [k8s] kube-porxy가 네트워크를 관리하는 3가지 모드(userspace, iptables, IPVS)" }, { "title": "(NLP) ELECTRA 리뷰 및 설명", "url": "/posts/ELECTRA/", "categories": "Natural Language Processing", "tags": "Language Model, NLP, NLU, Paper Review", "date": "2022-09-13 00:00:00 +0900", "snippet": "이 포스트는 개인적으로 공부한 내용을 정리하고 필요한 분들에게 지식을 공유하기 위해 작성되었습니다. 지적하실 내용이 있다면, 언제든 댓글 또는 메일로 알려주시기를 바랍니다.01. 개요ICLR 2020에서 Google Brain 팀은 새로운 사전 학습 방법론으로 ELECTRA를 제안했다. ELECTRA는 “Efficiently Learning an Encoder that Classifies Token Replacements Accurately”의 약자로, 사전 학습에서의 효율성을 개선하여 BERT보다 빠르게 사전 학습 할 수 있으면서 downstream task에서도 높은 성능을 보였다.02. 기존(BERT) 사전 학습 방식의 문제점언어 모델이 토큰들에 대한 representation을 학습하는 대표적인 방법은 denoising autoencoder 방식이다. 이 방식은 BERT의 Masked Language Modeling(MLM) 방식이 대표적인데, 일반적으로 레이블링이 되어 있지 않은 입력 시퀀스의 일부(대략 15%)를 [MASK] 토큰으로 치환하고, 치환된 [MASK] 토큰의 원래 단어가 무엇이었는지를 맞추는 방식으로 학습한다. Transformer의 self-attention은 양방향의 문맥을 파악할 수 있으므로 이러한 MLM 방식은 매우 효과적인 결과를 낼 수 있다. 하지만 BERT 같은 커다란 언어 모델의 학습이 고작 15% 정도의 [MASK]로 치환된 토큰들만을 이용하여 학습해야 하기 때문에 계산 비용이 매우 크다는 단점이 있다.ELECTRA의 저자들은 이처럼 적은 수의 [MASK]로 치환된 토큰들만 가지고서 큰 언어 모델을 학습하는 방식이 비효율적이라고 지적하며, MLM 방식의 사전 학습이 아닌, Replaced Token Detection(RTD)이라는 새로운 사전 학습 방식을 제안한다.03. ELECTRA의 구조ELECTRA의 사전 학습 방식은 마치 GAN과 같이 Generator와 Discriminator 네트워크의 학습으로 이루어진다. ELECTRA의 이름에서 알 수 있듯이, Generator와 Discriminator 모두 기본적으로 BERT처럼 Transformer의 Encoder 구조이다. 이때, Discriminator가 바로 ELECTRA 모델에 해당하며, Generator는 사전 학습 시 Discriminator의 입력값을 만들어주는 네트워크에 불과하다. 사전 학습을 마치면 Generator는 떼어내고 Discriminator만을 이용하여 downstream task에 대해 fine tuning 한다.ELECTRA의 사전 학습 방식이 Generator와 Discriminator 구조로 이루어져 있고 jointly 학습되기 때문에 GAN과 같이 학습될 것이라고 생각할 수 있으나, 엄연히 다르다. GAN에서는 Generator가 Discriminator를 속이기 위해서 adversarial하게 학습을 하지만, ELECTRA의 사전 학습에서는 Generator가 maximum likelihood로 학습한다.GeneratorGenerator는 BERT의 사전 학습에서 Next Sentence Prediction(NSP)를 제외한 학습 방법, 즉, MLM만을 적용한 사전 학습 방법과 동일하다.우선, 입력 토큰 시퀀스 $\\mathbf{x}=[x_1, x_2, … , x_n]$이 주어졌을 때, 전체 토큰의 약 15%($k=\\lceil 0.15n \\rceil$)개의 토큰을 [MASK]로 치환하여 마스킹할 위치의 집합 $\\mathbf{m}=[m_1, m_2, …, m_k]$을 만든다. 이때 마스킹 위치는 수식으로 $m_i \\sim \\text{unif}{1, n} \\text{ for } i=1 \\text{ to }k$ 로 표현할 수 있다.마스킹할 위치의 집합 $\\mathbf{m}$이 결정되었다면, 해당 위치의 토큰은 [MASK]로 치환하는데, 이를 $\\mathbf{x}^{masked}=\\text{REPLACE}(\\mathbf{x}, \\mathbf{m}, \\text{[MASK]})$로 표현할 수 있다.Generator는 이후 BERT의 MLM과 동일한 방식으로 [MASK]로 치환된 토큰의 원래 토큰이 무엇이었는지 예측한다. $t$번째 토큰을 예측한다고 하면, 아래와 같이 softmax로 표현할 수 있다.$p_G(x_t | \\mathbf{x}) = \\cfrac{\\exp{(e(x_t)^T h_G(\\mathbf{x})_t)}}{\\sum_x^\\prime\\exp{(e(x^\\prime)^T h_G(\\mathbf{x})_t)}}$이때, $h_G(\\mathbf{x})$는 Generator 네트워크를 거쳐 나온 contextualized vector representations를 의미한다. 따라서 $h_G(\\mathbf{x})_t$는 $t$번째 [MASK] 토큰의 representation이 되겠다. 또한 $e(\\cdot)$는 토큰의 임베딩을 의미한다.최종적으로 Generator는 BERT의 MLM과 같은 손실 함수를 이용해서 학습한다.$\\mathcal{L}_\\text{MLM} (\\mathbf{x}, \\theta_G) = \\mathbb{E}\\bigg( \\sum_{ i \\in \\mathbf{m} } -\\log{p_G(x_i | \\mathbf{x}^{\\text{masked}})} \\bigg)$DiscriminatorDiscriminator는 Generator의 입력 토큰 시퀀스에서 [MASK] 부분을 Generator가 예측한 값으로 대입하여 입력값으로 사용한다. 그 예시는 다음과 같다. 원래 입력 토큰 시퀀스 $\\mathbf{x}$ [ the, chef, cooked, the, meal ] Generator의 입력 토큰 시퀀스 $\\mathbf{x}^{\\text{masked}}$ [ [MASK], chef, [MASK], the, meal ] 원래 입력 토큰 시퀀스의 15%를 마스킹 함 Discriminator의 입력 토큰 시퀀스 $\\mathbf{x}^{\\text{corrupt}}$ [ the, chef, ate, the, meal ] the 토큰은 Generator가 정확히 예측하였음 ate 토큰은 cooked가 정답이지만, Generator가 확률적으로 plausible 예측하였음 즉, Discriminator의 입력 토큰 시퀀스는 Generator의 예측값을 기반으로 원래 입력 토큰 시퀀스가 재구성되기 때문에, 일부 토큰이 확률적으로 그럴싸할 수는 있지만 원래 토큰과는 다른 토큰으로 구성되어 있을 수 있다(plausible but synthetically generated replacements).이렇게 Generator의 예측으로 [MASK] 토큰을 대체하여 재구성한 Discriminator의 입력 토큰 시퀀스를 $\\mathbf{x}^{\\text{corrupt}}=\\text{REPLACE}(\\mathbf{x}, \\mathbf{m}, \\mathbf{\\hat{x}})$라고 표현할 수 있다. 이때 Generator의 softmax를 통해 예측한 토큰을 $\\hat{x}_i \\sim p_G(x_i | \\mathbf{x}^{\\text{masked}}) \\text{ for } i \\in \\mathbf{m}$ 로 표현할 수 있다.최종적으로 Discriminator는 입력 시퀀스의 각 토큰이 원래 토큰인지(original), 아니면 Generator에 의해 대체된 토큰(replaced)인지를 구분하는 문제로 학습한다. 이는 sigmoid output layer로 구현되며 $t$번째 토큰에 대한 예측값은 $D(\\mathbf{x}^{\\text{corrupt}}, t) = \\text{sigmoid}(w^{T}h_{D}(\\mathbf{x}^{\\text{corrupt}})_t)$로 표현할 수 있다. 이때, $h_D(\\mathbf{x}^{\\text{corrupt}})$는 Discriminator 네트워크를 거쳐 나온 contextualized vector representations를 의미한다.최종적으로 Discriminator는 아래와 같은 크로스 엔트로피 손실 함수를 이용해서 학습한다.$\\mathcal{L}_{\\text{Disc}}(\\mathbf{x}, \\theta_D)=\\mathbb{E}\\bigg( \\sum_{t=1}^{n} -1(\\mathbf{x}_t^{\\text{corrupt}}=\\mathbf{x}_t) \\log{D(\\mathbf{x}^{\\text{corrupt}}, t)} -1(\\mathbf{x}_t^{\\text{corrupt}} \\neq \\mathbf{x}_t) \\log{(1-D(\\mathbf{x}^{\\text{corrupt}},t))} \\bigg)$Combined LossELECTRA는 궁극적으로 다음과 같이 Generator의 loss와 Discriminator의 loss를 결합하여 손실 함수를 구성하고, 이 손실 함수가 최소화되도록 사전 학습을 진행한다.$\\min_{\\theta_G, \\theta_D} \\sum_{\\mathbf{x} \\in \\mathcal{X}} \\mathcal{L}_\\text{MLM}(\\mathbf{x}, \\theta_G) + \\lambda \\mathcal{L}_\\text{Disc}(\\mathbf{x}, \\theta_D)$이때 $\\mathcal{X}$는 대규모 raw 텍스트 코퍼스를 의미하며, $\\lambda$(논문에서는 $\\lambda=50$을 사용함)는 Generator와 Discriminator의 스케일을 맞추는 파라미터이다. 한편, 사전 학습 과정에서 sampling 과정을 거치기 때문에 Discriminator의 loss는 Generator로 back-propagate 되지 않는다.04. ExperimentsWeight Sharing만약, Generator와 Discriminator 네트워크 크기가 동일하다면, 두 네트워크의 가중치를 공유해서 사용하는 것이 더욱 효율적일 수 있을 것이라 생각할 수 있다. 이러한 호기심에 대해 ELECTRA 저자들은 두 네트워크가 동일한 크기라고 가정한 후 가중치를 공유하는 실험을 진행해보았다.(1)가중치를 공유하지 않은 경우와 (2)토큰 임베딩만을 공유한 경우, 그리고 (3)모든 가중치를 공유한 경우 각각에 대하여 GLUE score를 측정한 결과, 각각 83.6, 84.3, 84.4점을 달성했다. 즉, 가중치를 공유하면 성능이 향상된다는 것이다. 그러나, (3)모든 가중치를 공유한 경우에는 (2)토큰 임베딩만을 공유한 경우에 비해 아주 약간의 성능 향상은 있었으나, Generator가 Discriminator와 반드시 동일한 크기만큼 커야 한다는 제약이 있다는 점을 고려하여 단점이 더 크다고 할 수 있다. 따라서 저자들은 (2)토큰 임베딩만을 공유하는 경우를 최적으로 여기고 사용한다.Smaller GeneratorsGenerator와 Discriminator의 크기가 동일하면 그만큼 학습할 때의 계산량도 상당할 것이다. ELECTRA의 저자들은 Generator의 크기를 작게하여 계산량을 줄여보았다. 실험 결과, 오히려 Generator의 크기가 Discriminator의 크기보다 작을 때(대략 Discriminator의 1/4 ~ 1/2 크기) 더 높은 GLUE score를 달성할 수 있었다. 저자들은 이 현상에 대해서 너무나 Generator의 크기가 커지면, Discriminator는 실제 데이터의 분포를 모델링 하는 것 보다 Generator를 모델링 하는 데 파라미터를 많이 사용하게되는 단점이 있을 것이라고 해석했다.Training AlgorithmsELECTRA의 저자들은 다음과 같이 Generator와 Discriminator의 크기를 동일하게 설정한 후 Two-Stage 방식으로 학습을 해보았다. 우선, Generator만 n스텝 학습한다. 이후, Generator의 가중치로 Discriminator의 가중치를 초기화하고, Generator의 가중치는 고정한 후, Discriminator만 n스텝 학습한다.또한 GAN과 같이 Generator를 adversarial한 방식으로도 구성하여 실험해보았다. 결과적으로는 다양한 시도을 했지만 성능 향상엔 큰 도움을 얻을 수 없었으며, 기본적인 방식으로 Generator와 Discriminator를 결합하여(jointly) 학습할 때 성능이 가장 좋았다.Small Models저자들은 GPU 한 대에서도 빠르게 ELECTRA를 사전 학습 할 수 있도록 ELECTRA-small 모델을 개발해서 실험해보았다. BERT-Base의 하이퍼파라미터를 사용하되, 시퀀스 길이를 512 토큰에서 128 토큰으로, 배치 사이즈를 256에서 128로, 은닉층의 차원을 768에서 256으로, 임베딩 차원을 768에서 128로 줄여서 실험해보았다. 그럼에도 불구하고 Table 1에서 볼 수 있듯, 놀라울 수준의 GLUE score를 달성하였다.Large Models저자들은 SOTA 모델들과 비교해보기 위해서 BERT-LARGE에 준하는 ELECTRA-LARGE 모델을 개발하여 실험해 보았다. ELECTRA-400K는 RoBERTa 사전 학습의 대략 1/4 수준의 연산만 수행한 모델인데도 불구하고, Table 2에서 알 수 있듯, GLUE dev set에서 RoBERTa와 XLNet에 준하는 성적을 거두었다. RoBERTa의 연산 수준만큼 사전 학습 한 ELECTRA-1.75M 모델은 대부분의 태스크에서 최고점을 기록했다. Table 3에서 알 수 있듯, ELECTRA는 GLUE test set에서도 대부분의 태스크에서 최고점을 달성했다.ELECTRA는 SQuAD 데이터셋에서도 매우 우수한 결과를 보였다.05. 결론ELECTRA는 언어의 representation을 학습하기 위해서 replaced token detection이라는 새로운 self-supervised task기법을 제시하였다. 이는 기존의 사전 학습 방식들에 비해서 연산을 효율적으로 수행할 수 있으며, 실제로 downstream task에서도 훌륭한 성능을 보였다.06. 참고 문헌[1] 원 논문 : ELECTRA: pre-training text encoders as discriminators rather than generators[2] Scatter Lab의 블로그 : tech.scatterlab.co.kr/electra-review" }, { "title": "(K8S) CNI Weave의 기초 개념", "url": "/posts/CNI-Weave/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Network, CNI, WeaveNet", "date": "2022-09-13 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.CNI 솔루션 중에서 Weave에 대한 간단한 컨셉을 다룬다.CNI 솔루션을 쓰지 않는 경우의 한계CNI 솔루션을 사용하지 않는다면, 파드 간 통신을 가능하게 하기 위해서는 위와 같이 네트워크 주소와 게이트웨이 주소 간의 매핑 관계를 routing table로 일일이 정의해야 한다. 위 예시에서는 노드와 파드가 몇 개 되지 않아서 수동으로 설정하는 것이 가능하겠지만, 실제 운영 환경에서는 노드와 파드가 매우 많아서 일일이 설정하는 것이 불가능할 수 있다.WeaveNet의 간단한 개념출처 : https://ykarma1996.tistory.com/179Weaveworks의 WeaveNet은 도커 호스트 간에 오버레이 네트워크를 제공한다. 여기서 오버레이란 “덮어 씌우다”라는 뜻이다. 즉, 오버레이 네트워크의 기본 개념은 실제로 복잡할 수 있는 엔드 포인트 간의 네트워크 구조를 추상화하여 네트워크 통신 경로를 단순화 하는 것이다.오버레이 네트워크가 구현된 WeaveNet의 작동 방식을 살펴보자면, 각 도커 호스트(노드)에 WeaveNet의 peer라고 불리우는 에이전트를 배포한다. 각 노드에 배포된 peer 에이전트들은 클러스터 내의 파드 및 IP 정보 등 네트워크 토폴로지를 알고 있기 때문에, 이들을 활용하면 사용자가 직접 routing table을 통해 네트워크 주소와 게이트웨이 주소의 매핑 관계를 정의하지 않고서도 컨테이너 간의 통신이 가능해진다.또한 WeaveNet은 각 노드에 Weave Bridge를 구축하고 IP 주소를 할당한다. (참고로, 하나의 파드는 여러 bridge에 연결될 수 있다. 예를 들어, 도커 bridge에도 연결되면서 동시에 Weave Bridge에도 연결될 수 있다.) 특정 파드로부터 발생한 패킷이 다른 노드에 있는 파드로 전송된다면, WeaveNet은 해당 패킷을 가로채서(intercept) 캡슐화 한 후, WeaveNet의 오버레이 네트워크를 이용해 해당 패킷을 전송한다. 오버레이 네트워크를 통해 전송된 패킷이 목적지 노드에 도착하면, 해당 노드에 있는 peer 에이전트가 캡슐화된 정보를 복원하여 목적지 파드로 정보를 전송한다.Deploy WeaveWeave의 peer 에이전트는 각 노드마다 하나씩 배포되어야 하기 때문에 데몬셋으로 배포된다. 쿠버네티스 시스템이 잘 설치되어 있고, 노드 간 네트워크 설정들이 알맞게 설정되었으며, 컨트롤 플레인의 기본적인 컴포넌트들이 배포되어 있는 상태라면, kubectl apply -f \"https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\\n')\" 명령으로 WeaveNet을 간단하게 설치할 수 있다.Weave의 IPAM(IP Address Management)파드에 IP 주소를 할당하는 CNI 플러그인virtual bridge network와 파드에는 어떻게 IP가 할당되는 것일까? 이 IP 주소 정보는 어디에 저장되는 것이며, 무엇이 관리하는 것일까? 우선, 파드에 IP주소를 할당하는 주체는 CNI 플러그인이다.직접 수동으로 네트워크를 구축한다고 했을 때 사용하는 스크립트를 살펴보면, 플러그인 내에서 컨테이너 네트워크 네임스페이스에 IP 주소를 할당하는 섹션이 있다. 즉, CNI 플러그인이 IP 할당을 담당한다.IP가 중복되지 않도록 관리하는 host-local 플러그인, 그리고 한계점그렇다면, 어떠한 메커니즘으로 IP들이 중복되지 않게 할당될 수 있도록 관리되는 것일까? 가장 쉬운 방식으로, 위와 같이 각 호스트마다 IP가 어떤 파드에 할당되어 있는지를 파일로써 관리할 수 있겠다. 위 예제에서는 직접 스크립트를 코딩하여 구현하는 모습을 보였지만, 사실 이 과정이 이미 구현된 CNI 플러그인이 있다.위와 같이 각각의 호스트 로컬에서 IP 주소를 관리하는 방식이 구현된 플러그인을 host-local 플러그인이라고 한다. 하지만 이 방식 또한 여전히 스크립트 내부에서 플러그인을 적용해야 하는 문제가 있다.CNI 설정 파일에서 ipam 설정 활용하기/etc/cni/net.d/net-script.conf 경로에 있는 CNI 설정 파일에는 ipam을 설정할 수 있는 섹션이 있다. 이곳에 플러그인의 타입과 더불어 사용될 subnet 및 route 정보를 기입할 수 있다. 이러한 설정 파일을 활용하면, 스크립트에 직접 하드코딩을 하지 않고서도 적절한 플러그인을 적용할 수 있다.Weave의 예시위의 과정들은 네트워크 솔루션 제공자들에 따라 조금씩 차이가 있으므로, Weave를 예로 들어 살펴보자. Weave는 기본적으로 전체 네트워크에 10.32.0.0/12 대역의 IP 주소를 사용하는데, 이는 10.32.0.1 ~ 10.47.255.254에 해당되며, 총 1,048,574개다. 각 노드에 데몬셋으로 배포되어 있는 WeaveNet의 peer 에이전트는 이 구간 내의 IP를 쪼개어 구간 별로 나누어가지며, 자신의 노드에 있는 파드들에 IP를 순차적으로 할당한다. 참고로 각 구간 또한 사용자가 직접 설정할 수 있다.참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스[3] 모두의 근삼이 님의 블로그 : Calico?Weave? CNI에 관하여[4] WeaveWroks 공식 documentation : Fast Datapath &amp; Weave Net" }, { "title": "(K8S) 네트워크 기초 정리 - CNI", "url": "/posts/Container-Networking-Interface/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Network, CNI", "date": "2022-09-12 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.CNI의 필요성이전 ‘도커의 네트워크 글’에서 bridge network를 통해서 여러 네트워크 네임스페이스에 배치된 컨테이너들을 연결하는 방법을 살펴보았다.정리하자면, 그 과정은 다음과 같다. Create Network Namespace Create Bridge Network/Interface Create vEth Pairs (Pipe, Virtual Cable) Attach vEth to Namespace Attach Other vEth to Bridge Assign IP Addresses Bring the interfaces up Enable NAT - IP Masquerade위와 같은 절차로 컨테이너들을 연결하는 방식은 도커 뿐만 아니라 rkt, Mesos, 쿠버네티스 등 컨테이너의 네트워킹을 다루는 솔루션이라면 모두 사용하는 방식이다.모두가 사용하는 방식인 만큼, 일종의 표준을 만들어 사용하는 것이 편리하므로, 이 과정을 하나의 프로그램으로 만들 필요가 생겼다.CNI 개념이러한 필요에 따라 Container Networking Interface(CNI)가 탄생하게 되었다.CNI는 Cloud Native Computing Foundation(CNCF)의 프로젝트로, 네트워크 인터페이스를 구성하기 위해서 어떻게 플러그인이 개발되어야 하는지와 같은 상세한 내용과 라이브러리들로 구성되어 있다.예를 들면 다음과 같은 내용들이 정의되어 있는 것이다. Container Runtime must create network namespace. Identify network the container must attach to. Container Runtime to invoke Network Plugin (bridge) when container is ADDed. Container Runtime to invoke Network Plugin (bridge) when container is DELeted. JSON format of the Network Configuration … Must manage IP Address assignment to PODs Must Return results in a specific formatCNI는 BRIDGE, VLAN, IPVLAN, MACVLAN, WINDOWS, DHCP, host-local 등의 플러그인들이 준비되어 있다.이외에도 서드파티의 플러그인인 Weavenet, Flannel, Cilium, vmware NSX, Calico 등도 이용할 수 있으며, 이러한 모든 서드파티 플러그인들도 CNI의 표준을 구현한 것이다.CNI를 구현하지 않은 도커한편, 참고로 도커는 CNI를 구현하지 않았다. 도커는 도커 자체의 표준인 Container Network Model(CNM)을 구현하였다.따라서 도커에서 CNI의 플러그인들을 사용하기 위해서는 특별한 방법을 써야 한다.docker run --network=none nginx처럼 컨테이너를 실행할 때 none 옵션을 주고 나서, bridge add 2e34dcf34 /var/run/netns/2e34dcf34 명령 처럼 CNI 플러그인을 수동으로 직접 세팅하여 활용할 수 있다.사실 이러한 방법이 쿠버네티스가 활용하는 방법이며, none network로 도커 컨테이너를 생성한 후 CNI 플러그인을 활용한다.쿠버네티스와 CNI앞서 CNI는 네트워크 인터페이스를 구성하기 위해서 어떻게 플러그인이 개발되어야 하는지와 같은 상세한 내용과 라이브러리들로 구성되어 있다고 했다. 그렇다면, 쿠버네티스에서 이러한 CNI의 플러그인들을 사용하기 위해서는 어떻게 해야 할까?CNI 플러그인에 대한 설정은 클러스터 내 각 노드의 kubelet.service에서 정의된다. 이를 살펴보면, --network-plugin=cni라고 명시되어 있는 것을 알 수 있다. ps -aux | grep kubelet 명령을 통해 실행 중인 kubelet service를 살펴보아도 동일한 설정을 확인할 수 있다.cni-bin-dir : CNI 플러그인이때, --cni-bin-dir=/opt/cni/bin로 설정되어 있는 것을 볼 수 있다. cni-bin-dir에는 지원되는 모든 CNI 플러그인들이 실행 될 수 있는 상태(executables)로 구성되어 있다.cni-conf-dir : CNI 설정 파일또한, --cni-conf-dir=/etc/cni/net.d로 설정되어 있다. cni-conf-dir에는 CNI와 관련한 설정 파일(configuration files)들이 있다. 이 예에서는 bridge의 설정 파일이 있다. 이를 열어보면, 다음과 같이 정의되어 있는데, 이 포맷이 바로 플러그인 설정과 관련한 CNI 표준으로 정의되어 있는 포맷이다.위 bridge 설정 파일을 간단하게 살펴보자. 우선, mynet이라는 이름이며, bridge type이다. isGateway 설정은 bridge 네트워크 인터페이스가 gateway로써 사용되기 위해서 IP 주소를 필요로 한다는 뜻이다. ipMasq 설정은 IP Masquerade 기능에 대한 설정으로, 해당 네트워크로부터 외부로 나갈 때 IP Masquerade 기능을 사용할지 여부를 명시한다. ipam 설정은 파드에 할당될 서브넷, IP 주소 등 IPAM(IP Address Management)에 관한 설정을 한다.참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스" }, { "title": "(K8S) 네트워크 기초 정리 - 도커의 네트워크", "url": "/posts/Docker-Networking/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Network, Docker", "date": "2022-09-11 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.도커의 네트워크 옵션 및 네트워크 네임스페이스와 관련한 내용들을 정리해보고자 한다.bridge(docker0)출처 : https://kangwoo.kr/2020/08/17/도커-네트워크/컨테이너의 네트워크 설정 옵션은 여러가지가 있지만, 기본적으로는 bridge 네트워크(docker0)가 있다. 이 네트워크 설정 옵션은 docker run 명령을 실행할 때 사용되는 기본값이므로, 별다른 설정을 추가할 필요가 없다.bridge 네트워크는 내부 사설 네트워크(internal private network)로, 도커가 호스트에 설치될 때, default로 생성되며, 컨테이너와 도커 호스트를 연결해주는 역할을 한다. 이 네트워크는 default로 172.17.0.x 대역의 주소를 가진다. 기본적으로 bridge 모드를 사용할 경우, 컨테이너들은 분리된 네트워크 네임스페이스에 배치되며, 자동으로 172.17.0.x의 IP가 순차적으로 할당된다.docker network ls 명령을 입력해보면 bridge 이름의 네트워크가 있는 것을 확인해 볼 수 있다. 도커가 설치된 호스트에서는 이러한 bridge 네트워크를 docker0라는 이름으로 부른다. ip link 명령으로 docker0 bridge가 존재하는 것을 확인해볼 수 있다.컨테이너가 생성될 때마다, 우선적으로 도커는 해당 컨테이너를 위한 네트워크 네임스페이스를 만든다. 그 후, 컨테이너 네트워크 네임스페이스 측에 연결될 eth0@XXXX이름의 인터페이스와 docker0 bridge 네트워크 측에 연결된 vethXXXX 이름의 인터페이스를 짝으로 만들며, 각각을 컨테이너와 docker0 bridge 네트워크에 연결한다. 내부적으로 ip link add docker0 type bridge와 같이 네트워크 네임스페이스에서 별도의 ip를 할당하고 연결하는 기술을 구현하는 것이다.–network none 옵션이외에도, 사용자의 선택에 따라서 다른 네트워크 드라이버를 쓸 수도 있다. 예를 들어, docker run --network none nginx와 같이 --network none 옵션을 줄 수 있다. --network none 옵션을 통해 도커를 실행하면, 컨테이너는 어떠한 네트워크에도 연결되지 않게 된다. 즉, 컨테이너 내부에서 외부로 접근할 수도 없고, 외부로부터 컨테이너 내부로 접근할 수도 없다. 이 명령으로는 여러 컨테이너를 생성하여 실행한다고 하더라도 각각이 네트워크에 연결되어 있지 않기 때문에 컨테이너 간 통신이 될 수도 없고, 마찬가지로 각 컨테이너 내부에서 외부로 접근할 수도 없다.–network host 옵션다음으로는, docker run --network host nginx와 같이 --network host 옵션을 줄 수도 있다. --network host 옵션은 컨테이너가 도커 호스트의 네트워크에 연결되도록 하는 옵션으로, 호스트와 컨테이너 간에 네트워크가 분리되지 않도록(no network isolation) 한다. --network host 옵션으로 도커를 실행한 경우, 만약 컨테이너의 80번 포트를 리스닝하는 웹 애플리케이션을 배포했다고 하면, 컨테이너와 호스트 간 별도의 포트 매핑 없이 호스트의 80번 포트에서도 웹 애플리케이션에 접근할 수 있게 된다. 한편, 동일한 포트를 리스닝하는 컨테이너의 인스턴스를 추가적으로 실행하면, 두 컨테이너의 프로세스는 동일한 호스트의 네트워크를 공유하는 꼴이기 때문에 제대로 동작하지 않게 된다.기타이외에도 도커가 자체적으로 제공하는 드라이버로는 컨테이너(container), 오버레이(overlay)가 추가적으로 있으며, 서드파티 플러그인으로는 weave, flannel, openvswitch 등이 있다.참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스[3] 도커 공식 documentation : Use bridge networks[4] 지구별 여행자 님의 블로그 : 도커 네트워크" }, { "title": "(K8S) 네트워크 기초 정리 - 스위치, 라우터, 게이트웨이", "url": "/posts/Switching-Routing/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Network, Switch, Router, Gateway", "date": "2022-09-07 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.이번에는 CKA 과정에서 다루는 네트워크 내용을 이해할 수 있도록 네트워크의 기본적인 개념들을 정리한다.스위치(Switch)의 기본 개념스위치(switch)는 허브(Hub)와 동일하게 여러 장비를 연결하고 통신을 중재하는 장비다. 허브와 스위치는 내부 동작 방식은 다르지만, 여러 장비를 연결하고 케이블을 한곳으로 모아주는 역할은 같다. 허브는 단순히 전기 신호를 재생성해 출발지를 제외한 모든 포트에 전기 신호를 내보내지만, 스위치는 허브와 달리 MAC주소를 이해할 수 있어 목적지 MAC 주소의 위치를 파악하고 목적지가 연결된 포트로만 전기 신호를 보낸다.아래와 같이 컴퓨터A와 컴퓨터B가 있다고 할 때, A와 B가 통신하기 위해서는 A와 B 모두를 스위치에 연결해야 한다.즉, 스위치는 두 컴퓨터를 연결해주는 네트워크를 만들어준다.ip link 명령을 통해서 각 호스트의 인터페이스를 확인할 수 있으며, 위 예의 경우 eth0이 인터페이스가 된다. eth0 인터페이스를 통해 스위치에 연결된 각 컴퓨터는 192.168.1.X의 IP 주소를 할당하여 사용함으로써 하나의 네트워크를 이루게 된다. 각 컴퓨터의 IP 주소는 위 그림과 같이 ip addr add {IP 주소}/24 dev eth0 명령으로 등록할 수 있다. 이후 ping을 통해 서로 연결된 것 또한 확인할 수 있다.아무튼, 핵심은 스위치를 통해 컴퓨터가 연결되어 통신 될 수 있다는 점이다. 스위치를 통한 통신은 동일한 네트워크 상에서만 가능하다. 즉, 다른 네트워크로 패킷을 주고 받을 수 없다.라우터(Router)의 기본 개념네트워크의 크기가 점점 커지고, 먼 지역에 위치한 네트워크와 통신해야 하는 필요성이 늘어나면서 라우터(router)가 필요해졌다. 라우터는 아래 그림처럼 네트워크 주소가 서로 다른 장비들을 연결할 때 사용한다. 최근 일반 사용자가 라우터 장비를 접하기는 어렵다.게이트웨이(Gateway)의 기본 개념아래와 같이 192.168.1.X를 사용하는 네트워크와, 192.168.2.X를 사용하는 네트워크가 있다고 해보자.만약, 192.168.1.11 컴퓨터B가 다른 네트워크에 있는 192.168.2.10 컴퓨터C에 통신하려면 어떻게 해야 할까? 서로 다른 네트워크에 접근해야 하기 때문에 라우터를 사용해야 한다.위 예에서 라우터는 두 개의 분리된 네트워크를 연결해주므로, 각 네트워크로부터 각 IP 주소(192.168.1.1 및 192.168.2.1)를 할당 받는다.route 명령어를 입력하면, routing 설정들이 있는 kernel의 routing table을 확인할 수 있다. 아무런 설정도 하지 않은 채, route 명령어를 입력하면, 아무런 정보가 나타나지 않는다. 즉, 컴퓨터B는 컴퓨터C에 연결될 수 없다. ip route add 192.168.2.0/24 via 192.168.1.1 명령을 통해서 192.168.1.1 gateway를 거치면 192.168.2.0의 네트워크에 접근할 수 있다는 설정을 등록할 수 있다. 이러한 설정을 마치고 나면, 컴퓨터B가 라우터를 통해 상대 네트워크에 있는 컴퓨터C에 접근할 수 있다.한편, 이러한 설정은 일일이 수행해야 하는데, 예를 들어 컴퓨터C에서 컴퓨터B에 접근하기 위해서도 위와 같은 방식으로 ip route add 192.168.1.0/24 via 192.168.2.1 명령을 통해서 192.168.2.1 gateway를 거쳐 192.168.1.0 네트워크에 접근할 수 있다는 설정을 등록해야 한다. 수많은 네트워크마다 모두 이러한 방식으로 등록하는 것은 불가능하다. 따라서 ip route add default via 192.168.2.1 명령과 같이 default gateway를 설정해 줄 수도 있다.참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스[3] 토리대디 님의 블로그 : 네트워크 장비, 허브(Hub), 스위치(Switch), 라우터(Router) 개념 및 정리" }, { "title": "(K8S) 스토리지 클래스와 다이나믹 프로비저닝", "url": "/posts/Storage-Class/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Storage, Volume, Storage Class, Provisioning", "date": "2022-09-07 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.182강 Storage Class앞서 PV와 PVC를 생성하는 방법을 살펴보았고, 파드 정의 YAML 파일에서 어떻게 PVC를 적용하는지도 살펴보았다.Static Provisioning Volume지금까지 살펴보았던 방식은 다음과 같은 workflow를 가졌다. Create a PersistentVolume that has volume properties like capacity, permissions, and class. Create a PersistentVolumeClaim to request storage and bind to a persistent volume. Configure a Pod to use the volume claim to mount a volume in a container.이러한 방식을 static provisioning 방식이라고 한다.static provisioning 방식을 다시 살펴보기 위해, Google Cloud persistent disk로 PVC를 생성해본다고 하자. static provisioning 방식의 문제는 PV를 생성하기 전에, 반드시 아래와 같이 Google Cloud에 디스크를 생성해야만 한다는 점이다.gcloud beta compute disks create\\ --size 1GB --region us-east1 pd-disk애플리케이션이 스토리지를 필요로 할 때마다 직접 Google Cloud에서 디스크를 프로비전해야 하며, 생성한 디스크의 이름과 동일한 이름을 이용해서 다음과 같이 PV 정의 파일을 생성해야 한다.# pv-definition.yamlapiVersion: v1kind: PersistentVolumemetadata: name: pv-vol1spec: accessModes: - ReadWriteOnce capacity: storage: 500Mi gcePersistentDisk: pdName: pd-disk # 생성한 디스크의 이름과 동일한 이름을 사용한다. fsType: ext4하지만 매번 이렇게 볼륨 스토리지(여기서는 Google Cloud 디스크)를 직접 수동으로 생성하고, 볼륨에 대한 정보를 YAML 파일에 적는 것은 번거로운 일이다.Storage Class와 Dynamic Provisioning위와 같은 방식이 아니라, 애플리케이션이 볼륨 스토리지를 필요로 할 때마다 볼륨이 자동으로 프로비전 되면 훨씬 수월할 것이다. 예를 들어, Google Cloud에 자동으로 Google Storage가 프로비전되어 PVC에 따라서 자동으로 파드에 연동까지 되는 것이 지원되면 한결 편할 것이다. 이를 위해서 쿠버네티스에는 storage class가 활용된다. storage class는 PV의 dynamic provisioning을 지원한다.dynamic provisioning은 PVC이 요구하는 조건과 일치하는 PV가 존재하지 않는다면, 자동으로 PV과 외부 스토리지를 함께 프로비저닝하는 기능이다. 따라서 dynamic provisioning을 사용하면 위에서 살펴본 바와 같이 외부 스토리지를 직접 미리 생성해두지 않아도 된다. PVC를 생성하면 외부 스토리지가 자동으로 생성되기 때문이다.Dynamic Provisioning 예시static provisioning을 위해서는 PV 정의 YAML, PVC 정의 YAML, 파드 정의 YAML 파일들이 필요했다. 그러나 dynamic provisioning은 PV을 직접 수동으로 생성하지 않기 때문에 PVC 정의 YAML, 파드 정의 YAML 파일만 필요하다. 그대신, storage class(SC)를 활용하므로 SC 정의 YAML이 필요하다.SC 정의 파일의 예# sc-definition.yamlapiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: google-storage # PVC 정의 파일에서 strageClassName 설정에 명시하여 연동한다.provisioner : kubernetes.io/gce-pd # Google Cloud를 사용하는 경우parameters: type: # 다양한 프로비저너마다 다양한 옵션이 존재한다. replication-type: # 다양한 프로비저너마다 다양한 옵션이 존재한다.PVC 정의 파일의 예# pvc-definition.yamlapiVersion: v1kind: PersistentVolumeClaimmetadata: name: myclaim # 파드 정의 YAML 파일 내 persistentVolumeClaim 설정에 명시하여 연동한다.spec: accessModes: - ReadWriteOnce storageClassName: google-storage resources: requests: storage: 500Mi파드 정의 파일의 예참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스" }, { "title": "(NLP) RoBERTa 리뷰 및 설명", "url": "/posts/RoBERTa/", "categories": "Natural Language Processing", "tags": "Language Model, NLP, NLU, Paper Review", "date": "2022-09-07 00:00:00 +0900", "snippet": "이 포스트는 개인적으로 공부한 내용을 정리하고 필요한 분들에게 지식을 공유하기 위해 작성되었습니다. 지적하실 내용이 있다면, 언제든 댓글 또는 메일로 알려주시기를 바랍니다.01. 요약RoBERTa는 Robustly Optimized BERT approach의 약자이다. ELMo, GPT, BERT, XLM, XLNet 등 self-training 방식인 기존 언어 모델들은 기존 모델들에 비해 비약적인 성능 향상을 보였다. 하지만, 이처럼 다양한 방식의 모델들이 존재함에도 불구하고, 모델 관점에서 무엇이 성능을 극대화하는 요인인지 알기 어려웠다.Facebook AI의 RoBERTa 저자들은 BERT의 사전학습 방식이 상당히 undertrained 되어 있다고 주장하며, BERT 이후 나온 post-BERT 방식을 능가하는 새로운 사전학습 방식으로 RoBERTa를 제안했다. BERT의 사전학습에는 상당한 하드웨어 자원과 학습 시간이 필요하여, 다방면에서 실험을 진행해보는 데 한계가 있을 수 있다. 그럼에도 불구하고 RoBERTa의 저자들은 모델 관점에서 BERT의 디자인을 다양하게 변형 및 실험해보았다는 기여를 했다. 이러한 시도의 결과로, 저자들은 RoBERTa를 통해 undertrained 되어 있는 BERT를 더욱 강건하게 최적화 할 수 있는 방법을 제시했다.02. RoBERTa의 특징RoBERTa는 BERT와 유사하지만, 다음과 같은 특징이 있다. 특징1 : 더욱 많은 데이터를 사용하여, 더욱 큰 batch로, 더욱 오래 모델을 학습하였다. 특징2 : BERT의 사전학습 방식에서 Next Sentence Prediction(NSP) 태스크를 제거하였다. 특징3 : 더욱 긴 sequence로 학습하였다. 특징4 : 사전학습 데이터에 더욱 동적 마스킹 방식을 적용하였다.특징1 - 더욱 많은 데이터, 더욱 큰 batch, 더욱 오래 학습더욱 많은 데이터BERT처럼 대규모 코퍼스로 사전학습하는 방식의 언어 모델은 학습 데이터의 크기가 매우 중요하다. (Baevski et al. 2019)에 따르면, 데이터의 규모를 키우는 것이 end-task의 성능 향상에 도움이 된다고 한다. RoBERTa 이전에도 original BERT보다 더욱 많은 데이터를 사용했던 시도들은 있었으나, 해당 데이터들이 공개되어 있지는 않았다. 따라서 RoBERTa 저자들은 최대한 많은 학습 데이터를 활용해서 언어 모델을 학습해보고자 했다. 사용한 데이터는 아래와 같다. BOOK CORPUS와 영어 WIKIPEDIA original BERT를 학습하기 위해서 사용되었던 16GB의 데이터다. CC-NEWS RoBERTa에서 추가됨 저자들이 수집한 2016년 9월 ~ 2019년 2월 동안의 뉴스 데이터로, 6,300 만 개의 크롤링된 영어 뉴스 기사로 구성되었으며, 76GB에 달한다. OPEN WEB TEXT RoBERTa에서 추가됨 최소 3개의 좋아요를 받은 Reddit으로부터 추출된 텍스트 데이터로, 38GB에 달한다. STORIES RoBERTa에서 추가됨 CommonCrawl 데이터의 일부로, 31GB에 달한다. 더욱 큰 batch(Ott et al., 2018)에 따르면, 기계번역 모델은 큰 미니배치 사이즈를 이용할 때 더욱 빠르게 수렴되고 좋은 성능을 낼 수 있다. (You et al., 2019)는 이러한 방식이 BERT에도 적용된다고 주장한다. 이에 RoBERTa 저자들은 더욱 큰 배치 사이즈를 적용해보았다.위와 같이 배치 사이즈(bsz)와 스텝(steps)의 곱이 유사하도록 환경을 구성함으로써 계산 복잡도를 유사하게 맞추어 놓은 후 비교했을 때, 배치 사이즈가 커질 때 perplexity(PPL)과 end-task의 정확도 모두 증가할 수 있음을 확인했다.더욱 오래 학습RoBERTa의 저자들은 더욱 오랜 스텝 동안 사전학습 하는 것이 궁극적으로 더 나은 성능을 보이는지를 실험하였다.특징2 - Next Sentence Prediction 태스크 제거original BERT는 사전학습 시 두 개의 문장 segment를 입력하는데, 50%는 같은 문서에서 인접한 문장들을, 50%는 다른 문서에서 각각 추출한 문장들을 사용하여 두 문장이 인접한 문장인지를 학습한다. 이를 Next Sentence Prediction(NSP) 태스크라고 하며, NSP loss로 구현된다.original BERT가 이러한 방식으로 학습하는 이유는 BERT가 NSP loss를 이용해서 학습했을 때 Question-answering NLI(QNLI), Multi-genre NLI(MNLI), SQuAD 데이터 태스크를 더욱 잘 수행하였기 때문이다. 한편, (Lample and Conneau, 2019) 등 여러 연구들은 NSP loss의 필요성에 대한 의문을 제시했다. 이러한 간극을 이해하기 위해서 RoBERTa는 다양한 실험을 통해 NSP loss의 효과를 입증하고자 했다.실험1 : SEGMENT-PAIR with NSP이 방식은 original BERT와 동일한 입력값 설정으로, 두 segment로 이루어진 입력값이 입력되지만, 통합 512 토큰 이하가 사용된다. 두 segment는 인접해 있을 수도 있고, 아닐 수도 있다.실험2 : SENTENCE-PAIR with NSP두 sentence(완전한 자연어 문장)로 이루어진 입력값이 입력된다. 이 경우, 512 토큰에 맞추어 가공한 segment에 비해 문장이 짧을 수 있으므로, 배치 사이즈를 늘림으로써 전체적인 토큰의 수가 실험1과 유사하도록 설정되었다. 두 sentence는 인접해 있을 수도 있고, 아닐 수도 있다.실험3 : FULL-SENTENCES without NSP통합 512 토큰 이하로 구성된, 인접한 sentence(완전한 자연어 문장)들로 이루어진 입력값이 입력된다. 이때 sentence는 두 문장 이상이 가능하다. 인접한 문장들이지만, 하나의 문서(document)를 넘어서는 경우, 다음 문서에서 문장을 샘플링하되, 다른 문서로 넘어갔다는 표시를 위해 별도로 특별한 separator 토큰을 추가 해준다. 그리고 NSP loss를 사용하지 않았다.실험4 : DOC-SENTENCES without NSP실험3과 유사하게 입력값을 구성한다. 그러나 하나의 문서를 넘어서는 문장 구성은 허용하지 않는다. 문서 끝에서 추출되는 문장들은 512 토큰보다 짧을 수 있으니, 이러한 경우 동적으로 배치 사이즈를 늘려줌으로써 조정했다. 그리고 NSP loss를 사용하지 않았다.실험 결과우선, 예상대로 실험2(SENTENCE-PAIR with NSP)는 original BERT의 방식인 실험1(SEGMENT-PAIR with NSP)에 비해 downstream task 성능이 떨어졌다. 이를 통해, sentence를 사용하는 경우, 문장이 짧을 때 long-range dependencies가 있을 수 있으며, 이에 따라 모델이 long-range 맥락을 학습할 수 없다는 가설을 입증했다.또한, NSP loss를 제거했음에도 불구하고 downstream task의 성능 향상을 볼 수 있었다. 특히 실험4(DOC-SENTENCES without NSP)의 결과가 두드러졌지만, 매번 배치 사이즈를 동적으로 변경시켜주어야 한다는 불편함이 있어 이후 실험에서는 실험3(FULL-SENTENCES without NSP)의 방식을 활용했다고 한다.특징3 - 더욱 긴 sequence로 학습original BERT처럼 최대 512 길이의 토큰 sequence를 사용하되, 다른 점으로는 short sequence를 랜덤하게 사용하지 않았고, 처음 90%의 업데이트 동안 reduced sequence length를 사용하지 않았다.특징4 - 동적 마스킹 방식 적용original BERT는 Masked Language Model(MLM) 학습 방식을 위해 [MASK] 토큰을 전처리 단에서 만들어사용한다. 이는 학습 단계에서 고정된 데이터이므로 static masking이라 할 수 있다. 이 경우, 모델은 매 epoch마다 동일하게 마스킹된 데이터를 중복하여 보게된다. RoBERTa에서는 [MASK] 토큰을 전처리 단계에서 만드는 것이 아니라, 모델에 텍스트 데이터가 주입되는 시점에 생성해서 사용한다. 이렇게 동적으로 데이터를 마스킹하는 방식을 dynamic masking 이라고 한다. dynamic masking 기법은 더욱 많은 텍스트 데이터를 활용하여 더욱 오래 사전학습하는 RoBERTa에 필수적이며, 실제로 downstream task 성능 향상에도 기여했다고 한다.03. RoBERTa 실험 세팅논문에서는 BERT-LARGE 크기의 아키텍처(레이어 수 = 24, 히든 사이즈 = 1024, 어텐션 헤드 수 = 16, 355M 파라미터)를 사용하였다. 1024개의 V100 GPU로 대략 하루 정도의 시간동안 학습했다.04. RoBERTa 실험 결과더욱 많은 데이터(data 160GB)로, 더 크게(bsz 8K), 더 오래(500K) 사전학습 할수록 성능이 좋아지는 것을 볼 수 있다.GLUE, SQuAD, RACE datasets로 실험한 결과들을 비교해보면, 많은 Natural Language Understanding(NLU) 태스크에서 RoBERTa가 SOTA를 달성하였다.05. 참고 문헌[1] 원 논문 : https://arxiv.org/pdf/1907.11692.pdf" }, { "title": "(K8S) 퍼시스턴트 볼륨 클레임(Persistent Volume Claim)", "url": "/posts/Persistent-Volume-Claims/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Storage, Volume, Persistent Volume Claim", "date": "2022-09-06 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.Recap : 퍼시스턴트 볼륨과 퍼시스턴트 볼륨 클레임앞서 정리한 글에서 퍼시스턴트 볼륨(PV)과 퍼시스턴트 볼륨 클레임(PVC)에 대한 개념을 살펴보았다.퍼시스턴트 볼륨과 퍼시스턴트 볼륨 클레임은 각각 별도의 오브젝트로서, 퍼시스턴트 볼륨은 쿠버네티스 클러스터 인프라 관리자가 미리 생성해두는 것이고, 퍼시스턴트 볼륨 클레임은 사용자(개발자)가 스토리지를 이용하기 위해서 생성하는 것이다.쿠버네티스는 퍼시스턴트 볼륨 클레임을 sufficient capacity, access modes, volume modes, storage class와 같은 요청 속성을 고려하고, 이에 적합한 퍼시스턴트 볼륨과 매칭하여 바인딩 한다.이때 모든 PVC는 단 한 개의 PV과 바인딩 된다.그러나, 이러한 요청 속성을 고려했음에도 하나의 PVC에 여러 개의 PV가 적합하다고 매칭될 경우, labels와 selector를 이용해서 특정 레이블과 매칭되는 조합으로 바인딩하는 것이 가능하다.만약, PVC에 매칭 될 수 있는 PV가 존재하지 않는다면, PVC는 새로운 볼륨이 생겨나기 전까지 pending 상태로 머물러있게 된다. 이후, 새로운 볼륨이 생겨나면 자동으로 pending 상태의 PVC와 바인딩 된다.퍼시스턴트 볼륨 클레임 생성하기PV와 유사하게, PVC를 생성하는 방식은 위와 같다. 마찬가지로 kubectl get persistentvolumeclaim 명령을 통해서 생성된 PVC를 확인할 수 있다.퍼시스턴트 볼륨 클레임 삭제하기kubectl delete persistentvolumeclaim {PVC 이름} 명령을 통해서 생성했던 PVC를 삭제하는 것 또한 가능하다.퍼시스턴트 볼륨 반환 정책PV와 바인딩된 PVC를 삭제하면, PV는 어떻게 될까? PV정의 YAML 파일에서 PV가 어떻게 처리될지 직접 설정할 수 있는데, 이를 PV 반환 정책이라고 한다.Retain 설정YAML 파일 내의persistentVolumeReclaimPolicy 설정에서 정의할 수 있는데, default는 Retain으로, PVC를 삭제하여 PV가 released 상태가 되더라도 관리자가 직접 PV를 제거하지 않는 한 PV는 남아있게 하겠다는 설정이다. PV가 남아있다 하더라도 PV에 아직 데이터가 남아있기(retain) 때문에, 다른 PVC에 의해 사용될 수 있는 상태는 아니다.Delete 설정Delete로 설정할 경우, PVC가 삭제되어 PV가 released 상태가 되면 PV와 연결된 디스크 내부 자체가 자동으로 함께 제거된다.Recycle 설정Recycle로 설정할 수 있는데 deperecated 되어있다.파드에서 퍼시스턴트 볼륨 클레임 사용하기PVC 생성을 완료했으면, 아래의 예제와 같이 파드 정의 YAML 파일 내 persistentVolumeClaim 설정 부분에서 PVC 이름을 기입하여 사용할 수 있다.apiVersion: v1kind: Podmetadata: name: mypodspec: containers: - name: myfrontend image: nginx volumeMounts: - mountPath: \"/var/www/html\" name: mypd volumes: - name: mypd persistentVolumeClaim: claimName: myclaim레플리카셋이나 디플로이먼트에서도 동일한 방식으로 사용할 수 있다.참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스" }, { "title": "(K8S) 퍼시스턴트 볼륨(Persistent Volume)", "url": "/posts/Persistent-Volumes/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Storage, Volume, Persistent Volume", "date": "2022-09-05 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.YAML을 이용한 볼륨 마운트의 문제앞서 쿠버네티스에서 파드 정의 YAML 파일을 이용해서 볼륨의 정보를 직접 입력해 사용하는 방법을 살펴보았다.볼륨을 간단하게 테스트하기 위한 용도라면 이와 같은 방법으로 사용해도 크게 문제될 것은 없다.그렇지만 실제로 애플리케이션을 개발한 뒤 YAML 파일로 배포할 때는 이러한 방법이 바람직하지 않을 수 있다.파드를 아주 많이 사용하는 환경을 고려하면, 파드 정의 YAML 파일마다 일일이 어떤 볼륨을 마운트 할지를 기록해야 한다.만약 volume mount 관련한 변경 사항이 있다면, 모든 YAML 파일을 수정해야만 한다.또한 YAML 파일에 특정 네트워크 스토리지(NFS, Gluster FS, iSCSI, AWS EBS …)를 사용해야 한다고 명시해두었다고 할 때, 만약 이 YAML 파일을 다른 개발 부서에 배포하거나 웹상에 공개해야 할 경우에도 문제가 될 수 있다.예를 들어, YAML 파일에 네트워크 볼륨으로 NFS를 사용해야 한다고 명시해서 고정해두었다면, 다른 네트워크 볼륨은 사용할 수 없고 반드시 NFS를 사용해야만 하는 문제가 있다.NFS가 아닌 Gluster FS나 iSCSI 등을 사용하고 싶다면, 해당 네트워크 볼륨 타입을 명시하는 별도의 YAML 파일을 여러 개 만들어 배포해야 한다.퍼시스턴트 볼륨(PV)과 퍼시스턴트 볼륨 클레임(PVC)이러한 불편함을 해결하기 위해서 쿠버네티스에서는 퍼시스턴트 볼륨(Persistent Volume, PV)과 퍼시스턴트 볼륨 클레임(Persistent Volume Claim, PVC)이라는 오브젝트를 제공한다. 핵심 아이디어는 파드 정의 YAML에서 네트워크 볼륨이 NFS인지, Gluster FS인지, AWS EBS인지 등을 명시하지 않더라도 적합한 볼륨을 사용할 수 있도록 하자는 것이다.우선, 쿠버네티스 클러스터를 관리하는 인프라 관리자와 애플리케이션을 배포하려는 사용자(개발자)가 나뉘어 있다고 하자.인프라 관리자는 NFS, Ceph와 같은 여러 종류의 네트워크 볼륨을 쿠버네티스로 가져와서 PV 리소스를 미리 생성해둔다.즉, 여러가지 네트워크 볼륨(스토리지) 서버에 접근할 수 있는 엔드 포인트를 준비해두는 것이다.이후, 사용자(개발자)는 YAML 파일에 “이 파드는 데이터를 저장해야 하므로, 마운트 할 수 있는 외부 볼륨이 필요하다”는 의미로 PVC를 명시한다.그러면 쿠버네티스는 인프라 관리자가 생성한 PV의 속성과 사용자가 요청한 PVC 요구 사항이 일치한다면, 두 개의 리소스를 매칭시켜 바인드 한다.퍼시스턴트 볼륨 생성하기# pv-definition.yamlapiVersion: v1kind: PersistentVolumemetadata: name: pv-vol1 # PV의 이름spec: accessModes: - ReadWriteOnce # ReadOnlyMany | ReadWriteOnce | ReadWriteMany capacity: storage: 1Gi # PV로 사용하는 스토리지의 용량 hostPath: # 스토리지 역할을 할 호스트의 폴더 경로, not recommended path: /tmp/data퍼시스턴트 볼륨은 위와 같이 PersistentVolume 정의 YAML 파일을 작성한 후, kubectl create -f pv-definition.yaml 명령을 통해 생성할 수 있으며, kubectl get persistentvolume 명령을 통해 확인할 수 있다.단, 위와 같이 스토리지 역할을 할 호스트의 폴더 경로를 직접 지정하는 방식은 여러 개의 노드를 사용할 경우, 쿠버네티스가 스토리지의 경로 및 그 안에 있을 데이터가 모두 동일하다고 간주할 수 있으므로 문제의 여지가 있다.따라서 아래의 예와 같이 여러 네트워크 스토리지들 중 하나를 사용하도록 설정하는 것이 바람직하다.# pv-definition.yamlapiVersion: v1kind: PersistentVolumemetadata: name: pv-vol1 # PV의 이름spec: accessModes: - ReadWriteOnce # ReadOnlyMany | ReadWriteOnce | ReadWriteMany capacity: storage: 1Gi # PV로 사용하는 스토리지의 용량 awsElasticBlockStore: # AWS EBS를 사용하는 경우 다음과 같이 설정한다. volumeID: &lt;volume-id&gt; fsType: ext4참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스" }, { "title": "(K8S) 쿠버네티스의 볼륨(Volumes)", "url": "/posts/Volumes/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Storage, Volume", "date": "2022-09-04 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.도커 컨테이너는 기본적으로 일시적(transient)이다. 즉, 필요한 경우 실행되었다가 이후 종료되며 컨테이너가 삭제된다. 컨테이너 내에 있는 데이터 또한 마찬가지로, 컨테이너가 제거되면 그 안에 있는 데이터 또한 사라진다. 컨테이너 내의 데이터를 영구적으로 사용하고 싶다면, 볼륨을 생성하여 컨테이너와 연동해야 한다.그렇다면, 쿠버네티스에서는 어떻게 구현될 수 있을까? 도커 컨테이너와 마찬가지로, 쿠버네티스의 파드 또한 일시적이므로, 생성되기도 하며 제거되기도 한다.파드 내에 존재하는 데이터 또한 제거될 때 사라진다. 도커 컨테이너에서와 마찬가지로, 파드 내의 데이터를 영구적으로 사용하기 위해서 볼륨을 생성하여 파드와 연동할 수 있다.Volumes &amp; Mounts예를 들어, 단일 노드에서 1부터 100 사이의 랜덤한 숫자를 만들어내는 간단한 파드를 구성한다고 해보자. 만들어진 숫자는 컨테이너 내 /opt/number.out 경로에 저장된다고 가정해보자. 이 경우, 위에서와 같이 volumeMounts 설정에서 mountPath란에 컨테이너에서 마운트 될 볼륨의 경로를 입력하고, volumes 설정에서 hostPath란에 단일 노드의 경로를 입력함으로써 volume mount가 적용된 파드를 생성할 수 있다.그러나 노드가 하나가 아니라 여러 개로 구성된 경우, 위와 같은 방식으로 설정하면 문제가 된다. 쿠버네티스는 hostPath에 기입한 /data 경로가 여러 노드에 각각 존재하는 것이 아닌, 단 하나 존재하는 것으로 여기며, 그 경로 내에 있는 데이터도 동일할 것으로 간주하기 때문이다. 실제로는 노드가 다르기에 /data 경로와 그 안의 데이터들은 각각 다를 것이다.쿠버네티스에서는 다양한 스토리지 솔루션으로 이러한 문제를 해결할 수 있다. 예를 들어, AWS EBS를 볼륨으로 사용한다면 아래와 같이 volumes 설정을 변경하여 사용할 수 있다.스토리지 솔루션은 종류 또한 다양한데, 표준 스토리지 솔루션으로는 NFS, GlusterFS, Flocker, Scale IO, Ceph FS등이 있으며, 퍼블릭 클라우드 솔루션으로는 AWS EBS, Azure Disk, Google Persistent Disk 등이 있다.참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스" }, { "title": "(K8S) 도커의 스토리지(Storage in Docker)", "url": "/posts/Storage-in-Docker/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Storage", "date": "2022-09-03 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.이번에는 file system과 docker storage driver에 대해서 간략히 살펴보고자 한다.즉, 도커가 데이터를 어떻게 저장하는지, 그리고 컨테이너의 파일 시스템을 어떻게 관리하는지를 살펴본다.도커가 로컬 파일 시스템에서 데이터를 어떻게 저장하는지부터 살펴보자.도커를 설치하면, 도커는 /var/lib/docker 폴더 경로를 생성한다. 이 경로 밑에는 aufs, containers, image, volume 등 다양한 폴더들이 생성된다. 이곳이 default로 도커가 데이터를 저장하는 경로가 된다.예컨대, 컨테이너와 관련된 모든 파일들은 containers 폴더, 이미지와 관련된 모든 파일들은 image 폴더에, 그리고 도커 컨테이너에 의해서 만들어진 볼륨들은 volume 폴더에 저장된다.Recap : 도커의 레이어 구조그런데, 도커는 어떻게 이미지와 컨테이너의 파일들을 저장할까? 이를 알기 위해서는 도커의 레이어 구조를 알아야 한다.아래와 같은 Dockerfile이 있다고 해보자.FROM UbuntuRUN apt-get update &amp;&amp; apt-get -y install pythonRUN pip install flask flask-mysqlCOPY . /opt/source-codeENTRYPOINT FLASK_APP=/opt/source-code/app.py flask rundocekr build Dockerfile -t simon/my-custom-app또 위와 매우 유사한, 아래와 같이 Dockerfile2가 있다고 해보자.FROM UbuntuRUN apt-get update &amp;&amp; apt-get -y install pythonRUN pip install flask flask-mysqlCOPY app2.py /opt/source-codeENTRYPOINT FLASK_APP=/opt/source-code/app2.py flask rundocekr build Dockerfile2 -t simon/my-custom-app-2Dockerfile2는 Dockerfile에서 일부만 변경되었다. 이 경우 Dockerfile2를 위해서 120MB가 되는 우분투 이미지(첫 줄)와 300MB 정도 되는 apt package(두 번째 줄) 등을 모두 다시 받아야 한다면 매우 비효율적이다.따라서 도커는 레이어 구조를 사용한다. 즉, Dockerfile과 Dockerfile2 모두 세 번째 줄까지는 동일한 내용이므로, 캐시로부터 동일한 레이어로 공유한다. 그리고 Dockerfile2에서 변경 사항이 생긴 네 번째 줄과 마지막 줄만 새롭게 레이어로 생성한다. 이러한 방식으로 도커는 이미지를 더욱 빨리 빌드할 수 있으며, 디스크 공간도 효율적으로 사용할 수 있는 것이다. 이를 그림으로 나타내면 아래와 같다.이미지 레이어(Image Layer)와 컨테이너 레이어(Container Layer)다시 Dockerfile을 살펴보자. docekr build Dockerfile -t simon/my-custom-app 명령어를 통해서 Dockerfile을 빌드하면, 이미지 레이어(Image Layer)라는 레이어가 다음과 같이 생성된다. 이 레이어들은 모두 read only 레이어이므로, 변경될 수 없으며, 부득이 변경하고자 한다면 Dockerfile을 변경 후 다시 빌드하는 수밖에 없다. Layer 5 : Update Entrypoint with “flask” command Layer 4 : Source code Layer 3 : Changes in pip package Layer 2 : Changes in apt package Layer 1 : Base Ubuntu Layer이후, docker run simon/my-custom-app 명령으로 이 Dockerfile을 실행(run)하면 image layer 위에 추가로 컨테이너 레이어(Container Layer)라는 레이어가 하나 더 생긴다. 이는 read &amp; write 레이어로, write 기능이 있다. 즉, 로그 데이터라든지, temporary 파일이라든지, 혹은 사용자들에 의해서 변경되는 내용들 등 컨테이너에 의해서 생성되는 데이터들이 저장되는 데 사용되는 레이어다. Layer 6: Container Layer이러한 컨테이너 레이어는 컨테이너가 살아있을 때에만 존재하며, 컨테이너 실행이 중단되면 해당 레이어와 이곳에 저장되어 있던 변경 사항 데이터들도 사라진다.Copy-on-Wirte 메커니즘위와 같은 상황에서 read only인 이미지 레이어에 있는 app.py 파일에 변경 사항이 생기면 어떻게 해야 할까? 동일한 이미지 레이어는 해당 레이어를 사용하는 여러 컨테이너들에서 공유되기 때문에, read only인 이미지 레이어의 app.py는 변경이 불가능할까?Copy-on-Write(CoW) 메커니즘을 사용하면 변경할 수 있다. CoW 메커니즘은 read only 레이어에 있는 파일에 변경 사항이 생길 때 이를 처리하는 가장 쉬운 방법이다.위와 같이, 우선적으로 read only인 이미지 레이어에 있는 파일을 write가 가능한 컨테이너 레이어에 복사한다. 그 후, write가 가능한 레이어에 복사된 파일에 대해서 변경 사항을 적용한다. 즉, 이미지 레이어에 있는 파일 자체가 변경되는 것은 아닌 셈이다. 이때 컨테이너는 변경 사항이 적용된 레이어의 파일만 볼 수 있을 뿐, 이미지 레이어에 존재하는 파일은 볼 수 없다.그러나 이러한 방식에는 문제가 있다. 컨테이너를 삭제하면, 컨테이너 레이어도 함께 삭제되기 때문이다. 즉, 변경 사항이 반영된 app.py 파일도 함께 사라지게 된다. 따라서 영구적으로 데이터를 관리하는 방식이 필요하다.CoW 메커니즘의 한계를 보완하는 Volume MountCoW의 문제를 해결하는 방법으로 volume mount를 통해 컨테이너에서 persistent volume을 사용할 수 있다.우선, docker volume create {볼륨_이름} 명령을 통해서 볼륨을 생성한다. 이는 /var/lib/docker/volumes/{볼륨_이름} 경로를 만들어 낸다. 이후, docker run -v {볼륨_이름}:{컨테이너_내의_경로} {이미지_이름}명령으로 이미지를 실행시키면, persistent volume이 마운트된다.예를 들어, mysql 이미지를 data_volume이라는 이름의 볼륨에 마운트 하고자 한다면, docker volume create data_volume 명령으로 data_volume을 생성한 후, 컨테이너 내에서 mysql의 데이터가 저장되는 default 위치인 /var/lib/mysql 경로를 입력하여 docker run -v data_volume:/var/lib/mysql mysql 명령으로 mysql 이미지를 실행한다. 이를 도식으로 표현하면 다음과 같다.이처럼 volume mount를 활용하면 컨테이너를 삭제해도 데이터가 호스트에 보존될 수 있다.한편, docker volume create {볼륨_이름} 명령으로 볼륨을 생성하지 않고서, docker run -v 명령으로 volume mount를 적용한다면 어떻게 될까? 이 경우, 도커에 의해 -v 옵션 이후에 입력한 볼륨 이름으로 볼륨이 자동으로 생성된 후 마운트 된다. 정리하자면, volume mount를 통해 도커의 볼륨 디렉토리와 컨테이너를 마운트 할 수 있는 것이다.Bind Mount만약, 도커 호스트 내 어떤 곳에 이미 데이터가 존재한다면, 해당 데이터의 경로를 컨테이너에 bind mount 할 수 있다. 이 경우, docker run -v {데이터가 존재하는 절대 경로}:{컨테이너_내의_경로} {이미지 이름} 명령을 실행하여 bind mount 할 수 있다. 정리하자면, bind mount를 통해 도커 호스트 내 어떤 경로든 컨테이너와 마운트 할 수 있는 것이다.Storage Driver지금까지 살펴보았듯, 컨테이너를 실행할 때 write가 가능한 컨테이너 레이어를 만들고, 이미지 레이어로부터 파일을 복사하는 등, 스토리지와 관련한 일련의 과정을 수행하는 주체를 storage driver라고 부른다. storage driver는 AUFS, ZFS, BTRFS, Device Mapper, Overlay, Overlay2 등이 있으며, OS에 따라서 어떤 storage driver를 사용할지가 자동으로 결정된다. 예를 들어, 우분투의 경우 default로 AUFS를 사용한다.Volume Driver Plugins in Docker앞서, 컨테이너나 이미지의 스토리지를 관리하는 storage drivers를 살펴보았다. 또한 스토리지를 영구적으로 사용하기 위해서는 볼륨을 생성해서 마운트해야 하는 것 또한 살펴보았다.이때, 볼륨은 storage driver에 의해서 관리되지 않는다. 볼륨은 volume driver에 의해서 관리된다. volume driver의 default volume driver로는 Local이 있다. Local 볼륨은 도커 호스트에서 볼륨을 생성하고, /var/lib/docker/volumes 경로에 데이터를 저장하도록 관리하는 역할을 수행한다. 이외에도 서드파티 솔루션에 마운트가 가능하도록 지원해주는 volume driver의 종류는 매우 다양한데, Azure File Storage, Convoy, DigitalOcean Block Storage, Flocker, gce-docker, GlusterFS, NetApp, RexRay, Portworx, VMware vSphere Storage 등이 있다.docker run --volume-driver {volume_driver_이름} 명령으로 원하는 volume driver를 지정하여 마운트해 사용할 수 있다.참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스" }, { "title": "(K8S) 네트워크 정책(Network Policy) 기초 개념", "url": "/posts/Network-Policy/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Security, Network", "date": "2022-09-03 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.네트워크 트래픽에서의 Ingress와 Egress 개념네트워크 트래픽은 ingress와 egress로 구분할 수 있다. ingress란 외부로부터 서버 내부로 유입되는 네트워크 트래픽을 의미하고, egress는 서버 내부에서 외부로 나가는 트래픽을 의미한다.쿠버네티스의 “All Allow” Rule쿠버네티스 클러스터 내에 있는 파드들은 기본적으로 상호 간 communication이 가능하도록 되어있다.쿠버네티스의 default 네트워크 설정인 all allow는 특정 파드로부터 다른 어떠한 파드나 서비스로든 네트워크 트래픽이 전송되도록 하는 규칙이다.Network Policy위 그림과 같이 웹 서버에 대한 파드와 백 엔드 서버에 대한 파드, 그리고 데이터베이스 서버에 대한 파드가 있다고 예를 들어보자. 앞서 언급했듯, 기본적으로 쿠버네티스는 클러스터 내 모든 파드들끼리 서로 communication이 가능해야 하므로, 위의 그림과 같이 표현될 수 있다.그러나, 웹 서버 파드가 데이터베이스 서버 파드와 직접적으로 communication 할 필요가 없는 경우를 고려하면, 위와 같이 모든 파드가 연결되어 있는 네트워크 설정을 원하지 않을 수 있다. 이때, 데이터베이스 서버는 백 엔드 서버 파드로부터의 ingress 트래픽만 허용되고, 웹 서버 파드로부터의 ingress 트래픽은 허용되지 않도록 설정할 수 있다. 바로, 레플리카셋에서 다루었던 label과 selector를 이용하는 것이다.아래와 같이 네트워크 정책(Network Policy)을 정의할 수 있다.# policy-definition.yamlapviVersion: networking.k8s.io/v1kind: NetworkPolicy # network policy도 파드나 ReplicaSet처럼 쿠버네티스의 오브젝트다.metadata: name: db-policyspec: podSelector: # 아래 레이블에 매치되는 파드(DB 파드)에 대해서 적용한다. matchLabels: role: db policyTypes: # ingress 트래픽에 대해 규칙을 정의한다. - 2022-09-17-Ingress ingress: - from: # 아래 레이블에 매치되는 파드(api-pod, 즉 백 엔드 파드)로부터 들어오는 ingress 트래픽 - podSelector:\t matchLabels:\t name: api-pod ports: - protocol: TCP port: 3306 # 허용하고자 하는 파드 포트이후, kubectl create -f policy-definition.yaml 명령을 통해서 규칙을 생성한다.주의할 점network policy는 Kube-router, Calico, Romana, Weave-net Container Network Interface(CNI)에서만 지원되며, Flannel 환경에서는 지원되지 않는다.참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스" }, { "title": "(K8S) Security Context", "url": "/posts/Security-Context/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Security", "date": "2022-08-29 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.도커 컨테이너를 실행할 때, docker run --user=1000 ubuntu sleep 3600 명령과 같이 컨테이너를 실행하는 데 필요한 사용자의 ID와 같은 security 정보들을 입력해주어야 할 때가 있다. 쿠버네티스에서도 이러한 설정들을 해야하는 경우들이 있다.쿠버네티스에서의 security 설정은 컨테이너 레벨에서도 할 수 있고, 파드 레벨에서도 할 수 있다. 파드 레벨에서 security 설정을 세팅한다면, 파드 내 모든 컨테이너에 해당 설정이 적용되는 구조다. 컨테이너 레벨과 파드 레벨 둘다 설정할 경우, 컨테이너 레벨의 설정이 파드 레벨의 설정을 덮어쓴다.파드 레벨에서의 Security Context 설정아래와 같이 spec 섹션에서 securityContext 부분을 통해 설정할 수 있다.apiVersion: v1kind: Podmetadata: name: web-podspec: # 아래 부분에서 security 관련 설정을 한다. securityContext: runAsUser: 1000 containers: - name: ubuntu image: ubuntu command: [\"sleep\", \"3600\"]컨테이너 레벨에서의 Security Context 설정아래와 같이 securityContext 설정을 container 설정 섹션에서 정의한다.apiVersion: v1kind: Podmetadata: name: web-podspec: containers: - name: ubuntu image: ubuntu command: [\"sleep\", \"3600\"] # container 설정 안에서 securityContext를 정의한다. securityContext: runAsUser: 1000참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스" }, { "title": "(K8S) 쿠버네티스 서비스 계정(Service Accounts)", "url": "/posts/Service-Accounts/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Security, Authentication", "date": "2022-08-28 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.쿠버네티스에는 두 종류의 계정(account)이 존재하는데, 하나는 사람이 사용하는 user account이며, 다른 하나는 기계나 bot 등이 사용하는 service account이다. user account의 예로는 클러스터를 관리하는 관리자 계정이나 애플리케이션을 배포하는 개발자 계정 등이 있다. service account의 예로는 프로메테우스(prometheus)와 같은 모니터링 애플리케이션, 애플리케이션 배포를 위한 빌드 자동화 툴인 젠킨스(Jenkins) 등이 있다.Service Account와 인증을 위한 토큰service account에 대해 더욱 살펴보자. 예를 들어, K8S 대시보드라는 애플리케이션을 만들었다고 가정해보자. 이 애플리케이션은 kube-apiserver에 request를 보내서 파드 정보를 받아온 후, 가져온 정보들을 웹을 통해 나열해주는 간단한 기능을 제공한다고 해보자. 이 경우, K8S 대시보드 애플리케이션은 쿠버네티스 외부의 third-party application에 해당하므로, kube-apiserver에 query를 보내기 위해서는 클러스터에 접근할 수 있도록 인증(authentication)이 필요하다. 이때 service account가 사용된다.service account를 생성하는 방법은 kubectl create serviceaccount {service account의 이름} 명령어를 입력하여 생성할 수 있다.또한, kubectl get serviceaccount 명령을 통해 현재 생성되어 있는 service account를 확인할 수 있다.[node1 ~]$ kubectl create serviceaccount dashboard-saserviceaccount/dashboard-sa created[node1 ~]$ kubectl get serviceaccountNAME SECRETS AGEdashboard-sa 1 7sdefault 1 2m45skubectl describe serviceaccount {service account의 이름} 명령을 통해서 다음과 같이 service account를 자세히 확인할수도 있다.[node1 ~]$ kubectl describe serviceaccount dashboard-saName: dashboard-saNamespace: defaultLabels: &lt;none&gt;Annotations: &lt;none&gt;Image pull secrets: &lt;none&gt;Mountable secrets: dashboard-sa-token-gtb2qTokens: dashboard-sa-token-gtb2qEvents: &lt;none&gt;특이한 점으로, Tokens: dashboard-sa-token-gtb2q와 같이 토큰이라는 정보가 생성되어 있는 것을 확인할 수 있다.service account의 객체가 생성되면, 해당 객체의 service account 토큰이 자동으로 만들어진다. 이 토큰은 쿠버네티스 외부의 애플리케이션이 kube-apiserver에 접근할 때 인증하기 위해 사용된다. 이후 이 토큰을 저장하기 위한 시크릿 객체가 만들어지며, 토큰은 시크릿 객체 내부에 저장된다. 토큰이 저장된 시크릿 객체는 service account와 연동된다.토큰의 정보는 kubectl describe secret {secret 객체에 저장되어 있는 토큰의 이름} 명령을 통해서 확인할 수 있다.[node1 ~]$ kubectl describe secret dashboard-sa-token-gtb2qName: dashboard-sa-token-gtb2qNamespace: defaultLabels: &lt;none&gt;Annotations: kubernetes.io/service-account.name: dashboard-sa kubernetes.io/service-account.uid: 56802a9f-c87f-43bb-ac5f-6c7eb104e960Type: kubernetes.io/service-account-tokenData====namespace: 7 bytestoken: eyJhbGciOiJSUzI1NiIsImt ... 생략 ...앞서, 이 토큰 정보는 쿠버네티스 API에 접근할 때 인증하기 위해서 사용된다고 했다.예를 들면, curl https://192.168.56.70:6443/api -insecure --header \"Authorization: Bearer eyJhbGci0iJSUzI1NiIsImt ... 생략 ...\"과 같이 사용할 수 있다.이 예에서 예로 들은 K8S 대시보드와 같은 third-party application에서는 service account 토큰을 컨피그로 지정해서 사용할수도 있다.default service account한편, kubectl get serviceaccount 명령을 입력해보면, 다음과 같이 default service account가 생성되어 있는 것을 확인할 수 있다.[node1 ~]$ kubectl get serviceaccountNAME SECRETS AGEdashboard-sa 1 7sdefault 1 2m45sdefault service account와 이에 대한 토큰은 파드가 생성될 때마다 자동으로 해당 파드에 volume mount 형태로 마운트 된다. 예를 들어서 아래와 같이 파드를 만든다고 해보자.# pod-definition.yamlapiVersion: v1kind: Podmetadata: name: my-kubernetes-dashboardspec: containers: - name: my-kubernetes-dashboard image: mykubernetes-dashboard위의 파드 정의 YAML 파일에는 volume mount라든지 시크릿에 관한 어떠한 설정도 정의해두지 않았다.그러나 이 파드를 생성한 후, kubectl describe pod my-kubernetes-dashboard명령을 통해서 해당 파드를 살펴보면, volumes 부분에 default 토큰이 시크릿 타입으로 마운트되어 있는 것을 확인할 수 있다.해당 토큰에 대한 정보는 /var/run/secrets/kubernetes.io/serviceaccount 경로에서 확인할 수 있으며, kubectl exec -it my-kubernetes-dasyboard cat /var/run/secrets/kubernetes.io/serviceaccount/token와 같이 토큰을 확인해 볼수도 있다.한편, 이러한 default service account는 인증이 매우 제한적이기 때문에, 간단한 쿠버네티스 API 쿼리에만 permission이 있다.직접 생성한 service account 사용하기default service account가 아닌, 직접 만든 service account를 사용하기 위해서는 아래와 같이 파드 설정 YAML 파일에 serviceAccountName 설정을 추가해주면 된다.# pod-definition.yamlapiVersion: v1kind: Podmetadata: name: my-kubernetes-dashboardspec: containers: - name: my-kubernetes-dashboard image: mykubernetes-dashboardserviceAccountName: dashboard-sa # 직접 생성한 service account의 이름을 입력한다.serviceAccountName 설정을 변경한 이후, 변경 사항을 파드에 적용하기 위해서는 반드시 해당 파드를 제거한 후 재생성해야 한다.한편, 디플로이먼트의 경우, 파드 정의 YAML 파일에 serviceAccountName을 변경하면 자동으로 변경이 적용된다.쿠버네티스가 자동으로 default service account를 생성해서 파드에 마운트하는 것을 원치 않는다면, 아래와 같이 파드 정의 YAML 파일에 automountServiceAccountToken 설정을 추가해주면 된다.# pod-definition.yamlapiVersion: v1kind: Podmetadata: name: my-kubernetes-dashboardspec: containers: - name: my-kubernetes-dashboard image: mykubernetes-dashboardautomountServiceAccountToken: False # default service account 토큰이 파드에 자동으로 마운트되지 못하게 한다.참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스" }, { "title": "(K8S) 프라이빗 레지스트리로부터 이미지 받아오기", "url": "/posts/Image-Security/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Security, Image", "date": "2022-08-28 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.이번 글은 프라이빗 컨테이너 레지스트리나 레포지터리로부터 이미지를 받아오기 위해 시크릿 객체를 사용하는 방법을 정리하는 글이다.이미지 네이밍의 기본파드 정의 YAML 파일에 이미지를 받아오는 부분은 image: {이미지/레포지터리 이름}의 형태로 입력한다.이러한 형태는 도커의 이미지 네이밍 컨벤션을 따르는 것이다. 예를 들어, nginx 이미지를 받아오고자 한다면, image: nginx가 되겠다.별다른 설정 없이 image: {이미지/레포지터리 이름}이라고 입력하면, image: library/{이미지/레포지터리 이름}이 된다.nginx를 예로 들면, image: library/nginx가 되겠다. 이때, library란 도커의 공식 이미지들이 저장되어 있는 default account의 계정이다.별도로 사용자/계정을 입력하고자 한다면, library 대신 image: {사용자/계정 이름}/{이미지/레포지터리 이름}와 같이 입력하면 된다.그렇다면, image: {사용자/계정 이름}/{이미지/레포지터리 이름}이라는 이미지는 어디에 저장되어 있는 것일까?별다른 설정이 없으면, 도커의 default registry인 docker hub를 의미하며, image: docker.io/{사용자/계정 이름}/{이미지/레포지터리 이름}을 의미하게 된다.nginx를 예로 들면, image: docker.io/library/nginx가 되는 셈이다. docker hub 이외에도 구글의 registry인 gcr.io 등 다양한 registry가 존재한다.private registry의 이미지 사용하기도커의 경우AWS, GCP, Azure 등 다양한 클라우드 서비스 제공 업체들이 private registry를 제공한다. 도커의 경우, private 이미지를 실행하기 위해서는 우선적으로 docker login {private 레지스트리 주소}를 입력 후 username과 password를 입력하여 로그인을 해야 한다.그 후, docker run {private 레지스트리 주소}/{사용자/계정 이름}/{이미지/레포지터리 이름} 명령어를 통해 실행한다.예를 들면, docker run private-registry.io/apps/internal-app과 같이 실행할 수 있겠다.쿠버네티스의 경우 : docker-registry 시크릿 객체쿠버네티스로 돌아와서, 이를 파드 정의 YAML 파일에 입력하기 위해서는 어떻게 해야 할까?image : {private 레지스트리 주소}/{사용자/계정 이름}/{이미지/레포지터리 이름}와 같은 방식으로 이미지 경로는 입력할 수 있겠으나, 도커에서 로그인 정보를 입력했던 것처럼 비밀 정보(즉, authentication 문제)들은 어떻게 처리해야 할까?이를 위해서는 시크릿 객체를 생성해서 username이나 password 같은 정보들을 입력해주어야 한다.이 예에서는 시크릿 객체의 이름을 ‘regcred’라 하겠다. 아래와 같이 docker-registry라는 시크릿을 이용해서 도커의 credential을 입력한다.docker-registry는 built-in 시크릿 타입으로, 도커의 credential들을 저장하기 위해서 만들어졌다.이로써, regcred라는 이름의 시크릿으로 도커 credential을 입력하였다. 이후 아래와 같이 imagePullSecrets에 시크릿의 이름을 입력해주면 된다.참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스" }, { "title": "(K8S) Cluster Roles and Role Bindings", "url": "/posts/Cluster-Roles-and-Role-Bindings/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Security, Authorization, Cluster Roles", "date": "2022-08-24 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.네임스페이스 범주와 클러스터 범주네임스페이스 범주에서의 권한 부여앞서, Role Based Access Controls(RBAC)에서 role object와 role binding object를 통해서 역할에 따라 사용자나 그룹의 권한을 부여했다. 이처럼 RBAC에서의 권한 부여는 특정 namespace에 적용되는 것으로, 특정 namespace를 명시하지 않으면 default namespace에 대해서 role object에 정의된 내용에 따라 권한이 부여된다. 즉, namespace 단위에 권한을 부여하는 것이므로, 다음과 같이 나열된 namespace 범주에서 관리되는 resource에 대한 권한이 적용되는 것이다. namespace 범주에서 관리되는 resource 파드 레플리카셋 디플로이먼트 서비스 roles rolebindings configmaps PVC etc 클러스터 범주에서의 권한 부여한편, 특정 노드나 PV(Persistent Volume)와 같이, 아래 나열된 cluster 범주에서 관리되는 resource에 대해서 권한을 적용하고자 한다면 어떻게 해야할까?한편, 특정 노드나 PV(Persistent Volume)와 같이, 아래 나열된 cluster 범주에서 관리되는 resource에 대해서 권한을 적용하고자 한다면 어떻게 해야할까? cluster 범주에서 관리되는 resource 노드 PV(Persistent Volume) clusterroles clusterrolebindings certificatesigningrequests namespaces etc cluster의 범주에서 permission을 주기 위해서는, role object와 role binding object를 이용했던 것과 유사하게, clusterroles object와 clusterrolebindings object를 정의하고 사용자와 연결해야 한다.ClusterRole예를 들어, cluster-admin 계정에게 다음의 권한을 부여하고 싶다고 해보자. 노드를 볼 수 있음 노드를 생성할 수 있음 노드를 삭제할 수 있음cluster 범주에서 관리되는 resource에 대해서 위와 같은 권한을 부여할 수 있도록 다음과 같이 YAML 파일을 정의할 수 있다.# cluster-admin-role.yamlapiVersion: rbac.authorization.k8s.io/v1kind: ClusterRole # cluster 범주의 resource에 대한 역할 정의이므로 ClusterRole를 입력한다.metadata: name: cluster-administrator # cluster role의 이름을 정의한다.rules:- apiGroups: [\"\"] resources: [\"nodes\"] # 클러스터 내 권한을 부여할 자원을 입력한다. verbs: [\"list\", \"get\", \"create\", \"delete\"]이후 kubectl create -f cluster-admin-role.yaml 명령을 통해 clusterrole object를 생성할 수 있다.ClusterRoleBindingClusterRole object에 정의된 역할을 실제 사용자나 그룹에 적용하기 위해서 사용자와 역할을 연결하는 작업이 필요하다. 이는 아래와 같이 YAML 파일을 정의하여 ClusterRoleBindings object를 생성함으로써 가능하다.# cluster-admin-role-binding.yamlapiVersion: rbac.authorization.k8s.io/v1kind: ClusterRoleBinding # cluster 범주의 resource에 대한 binding 정의이므로 ClusterRoleBinding을 입력한다.metadata: name: cluster-admin-role-binding # binding 객체의 이름을 입력한다.subjects:- kind: User # 적용의 대상이 되는 사용자 정보를 입력한다. name: cluster-admin apiGroup: rbac.authorization.k8s.ioroleRef: # 적용될 역할 정보를 입력한다. kind: ClusterRole name: cluster-administrator # 앞서 정의한 ClusterRole의 metadata name을 적는다. apiGroup: rbac.authorization.k8s.io이후 kubectl create -f cluster-admin-role-binding.yaml 명령을 통해서 ClusterRoleBindings object를 생성할 수 있다.참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스" }, { "title": "(K8S) Role Based Access Controls(RBAC)", "url": "/posts/Role-Based-Access-Controls/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Security, Authorization, RBAC", "date": "2022-08-23 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.인가의 개념을 다루면서, Role Based Access Controls(RBAC)는 사용자나 그룹의 역할에 따라 permission을 부여하는 방식이라고 정의했다.그렇다면 쿠버네티스에서는 어떻게 역할을 생성할 수 있을까?Role Based Access Controls(RBAC)를 통한 인가 정의하기우선, 역할이 정의되어 있는 role object를 YAML 파일을 이용하여 생성한다.이후, role object에 정의되어 있는 역할이 특정 사용자나 그룹에 적용될 수 있도록 사용자와 role object를 연결시켜야 한다. 이러한 연결 과정은 role binding object를 통해서 정의되며, 이 또한 role object와 유사하게 YAML 파일을 이용하여 생성한다.Role Object의 정의예를 들어, 개발자들에게 다음과 같은 권한을 부여하고 싶다고 하자. 파드를 볼 수 있음 파드를 생성할 수 있음 파드를 삭제할 수 있음 ConfigMaps를 생성할 수 있음위와 같은 권한을 부여할 수 있도록 다음과 같이 YAML 파일을 정의할 수 있다.# developer-role.yamlapiVersion: rbac.authorization.k8s.io/v1kind: Rolemetadata: name: developer # role object의 이름을 적는다.rules:- apiGroups: [\"\"] resources: [\"pods\"] # 파드에 대한 설정을 정의한다. verbs: [\"list\", \"get\", \"create\", \"update\", \"delete\"] resourceNames: [\"&lt;파드 이름&gt;\"] # 특정 파드만 접근을 허용할 경우 이 행을 작성하며, 생략 또한 가능하다.- apiGroups: [\"\"] resources: [\"ConfigMap\"] # ConfigMap에 대한 설정을 정의한다. verbs: [\"create\"]이후 kubectl create -f developer-role.yaml 명령을 통해서 role object를 생성할 수 있다.Role Binding Object의 정의 : 사용자와 Role Object를 연결함role object에 정의된 역할을 실제 사용자나 그룹에 적용하기 위해서 사용자와 역할을 연결하는 작업이 필요하다.이는 아래와 같이 YAML 파일을 정의하여 role binding object를 생성함으로써 가능하다.# devuser-developer-binding.yamlapiVersion: rbac.authorization.k8s.io/v1kind: RoleBindingmetadata: name: devuser-developer-bindingsubjects:- kind: User # 적용의 대상이 되는 사용자 정보를 입력한다. name: dev-user apiGroup: rbac.authorization.k8s.ioroleRef: # 적용될 역할 정보를 입력한다. kind: Role name: developer # 앞서 정의한 role object의 metadata name을 적는다. apiGroup: rbac.authorization.k8s.io이후 kubectl create -f devuser-developer-binding.yaml 명령을 통해서 role binding object를 생성할 수 있다.위 과정을 마치고 나면, dev-user 계정의 개발자는 default namespace의 파드와 컨피그맵에 접근할 수 있게 된다. 특정 namespace에 대한 접근 permission을 주고 싶다면, metadata 내에서 namespace를 지정함으로써 접근 권한을 줄 수 있다.View RBAC생성된 role object들을 보고자 한다면, kubectl get roles 명령을 통해서 확인할 수 있다. kubectl describe role &lt;role object 이름&gt; 명령으로 role object를 자세히 볼 수도 있다.생성된 role binding object들을 보고자 한다면, kubectl get rolebindings 명령을 통해서 확인할 수 있다. 마찬가지로, kubectl describe rolebinding &lt;role binding object 이름&gt; 명령으로 role binding object를 자세히 볼 수도 있다.Check Access사용자가 본인이 특정 리소스에 권한이 있는지 확인하고자 한다면, kubectl auth can-i 명령어로 확인할 수 있다. 예를 들어, kubectl auth can-i create deployments 또는 kubectl auth can-i delete nodes와 같이 사용할 수 있으며, 명령어에 대한 결과로 부여된 권한에 따라 yes/no가 출력된다.관리자 계정으로는 각 사용자들이 특정 리소스에 권한이 있는지도 확인할 수 있다. 위 명령어에 --as &lt;사용자 계정&gt;을 덧붙여서 확인할 수 있다. 예를 들어, kubectl auth can-i create deployments --as dev-user 또는 kubectl auth can-i delete nodes --as dev-user와 같이 사용할 수 있으며, 이에 대한 결과도 부여된 권한에 따라 yes/no가 출력된다. 더 나아가 특정 namespace 하에서의 권한을 확인하고자 한다면 --namespace &lt;네임스페이스의 이름&gt;의 옵션을 추가하여 확인할 수도 있다.참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스" }, { "title": "(K8S) 쿠버네티스 인가(Authorization)의 기초 개념", "url": "/posts/Authorization-basic/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Security, Authorization", "date": "2022-08-23 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.인가(Authorization)의 개념인증(authentication) 과정을 통해 누가 클러스터에 접근할 수 있을지를 결정했다면, 어떤 일을 수행할 수 있는지 권한에 대한 정의가 필요한데, 이를 인가(authorization)이라고 한다.위의 상황과 같이, admin 계정, developer 계정, 그리고 bot이 존재한다고 예를 들어 보자. 이때 bot은 모니터링 애플리케이션이나 Jenkins와 같은 지속적 배포 도구 등으로 생각하자. 이 경우, 모든 계정에게 동일한 권한을 주면 위험할 수 있다. 관리자인 admin 계정은 모든 권한을 가질 수 있겠으나, 개발자인 developer 계정이 노드를 삭제한다는 등 자신의 권한을 넘어서는 행동들은 제한되어야 한다. 즉, authorization이 필요하다.쿠버네티스에서 authorization을 부여하는 메커니즘은 다양하게 존재한다. 대표적으로 Node Authorization, Attribute-based Authorization(ABAC), Role-based Authorization(RBAC), 그리고 Webhook이 있다. 추가적으로 AlwaysAllow 및 AlwaysDeny 모드 또한 존재한다.Node Authorizerkubelet은 현재 노드의 상태와 같은 정보들을 kube-apiserver에 전송하는데, 이때의 요청을 처리하는 authorizer가 바로 Node Authorizer이다. 간단하게, Node Authorization은 kubelet의 API 요청을 인증하는 목적으로 사용되는 특수한 authorization이라고 보고 넘어가자.ABAC(Attribute-based Access Control)ABAC는 사용자의 속성(user attribute) 기반의 authorization으로, 사용자 개인이나 사용자 그룹에 permission을 부여하는 데 사용된다. 예를 들어, 어떤 개발자A의 계정에 view PODs, create PODs, delete PODs를 할 수 있는 권한을 부여한다고 하면, {\"kind\": \"policy\", \"spec\": {\"user\": \"dev-user\", \"namespace\": \"*\", \"resource\": \"pods\", \"apiGroup\": \"*\"}}과 같이 JSON 형식으로 policy file을 정의한 후, 해당 policy file을 API server에 전달함으로써 권한을 부여할 수 있다. 같은 방식으로 개발자B, 개발자C 등에 대해서도 일일이 policy file을 정의할 수 있다.그러나 이러한 방식은 permission 부여에 변화가 있을 때마다 매번 policy file을 직접 수정해야 하며, API server를 재실행해주어야 한다. 즉, 관리가 번거로운 단점이 있다.RBAC(Role-based Access Control)ABAC 방식의 단점을 보완할 수 있는 RBAC는 사용자나 그룹에 직접 하나하나 permission을 정의하는 방식이 아닌, 사용자나 그룹의 역할에 따라 permission을 정의하는 방식이다. 예를 들어, 개발자 계정들에 대해서는 view PODs, create PODs, delete PODs에 대한 permission을 한꺼번에 부여해주고, security 관련 계정에게는 view CSR, approve CSR에 대한 permission을 한꺼번에 부여해주는 식으로 관리한다.RBAC는 쿠버네티스에서 access를 관리하는 방식의 표준이며, 이와 관련해서는 추후에 더욱 깊이 다룬다.Webhook쿠버네티스 상에 built-in 되어있는 authorization 메커니즘이 아니라, 서드파티와 같은 외부로부터 authorization 방식을 아웃소싱하고 싶을 때 활용되는 것이 webhook 방식이다.AlwaysAllow &amp; AlwaysDeny이름에서 직관적으로 알 수 있듯이, AlwaysAllow는 항상 permission을 허용하는 방식이며, AlwaysDeny는 항상 permission을 거부하는 방식이다.Authorization Mode의 설정Node Authorization, Attribute-based Authorization(ABAC), Role-based Authorization(RBAC), Webhook, AlwaysAllow 및 AlwaysDeny 모드의 설정은 kube-apiserver의 authorization mode에서 설정할 수 있다. 모드가 여러 개로 설정되어 있는 경우, 순차적으로 각 모드를 적용해보았을 때, permission이 허용되는 모드가 작동되며, 그 이외의 모드는 작동되지 않는다.참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스" }, { "title": "(K8S) TLS 보안 기초 개념 정리", "url": "/posts/Security-Basics/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Security, Encryption, Certificate", "date": "2022-08-21 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.본 글은 쿠버네티스의 보안(Security)을 이해하기에 앞서 필요한, 기초적인 Transport Layer Security(TLS) 보안 내용을 정리하는 글이다.대칭 키 암호(Symmetric Encryption)사용자가 서버에 접근할 때는 위와 같이 아이디와 비밀번호와 같은 비밀 정보를 전송하여 사용자 인증을 받는다. 이때, 사용자의 비밀 정보는 암호화(파란색 박스 부분)되어 서버에 전송된다. 서버에서 암호화된 정보를 복호화하기 위해서는 암호화에 사용되었던 key를 이용해야 하므로, key 또한 서버에 함께 전송된다. 서버는 이 key를 이용하여 암호화된 사용자 정보를 복호화하여 사용자를 인증한다.이러한 방식은 암호화와 복호화 과정에서 동일한 key를 사용하는 암호화 방식을 대칭 키 암호(symmetric encryption)라고 부른다. symmetric encryption 방식은 암호화와 복호화 과정이 빠르다는 장점이 있다. 그러나 비밀 정보와 key를 네트워크를 통해 전송하는 과정에서 악의적인 목적을 가진 해커가 네트워크 상에서 전송되고 있는 암호화된 정보와 key를 해킹할 수 있다는 문제가 있다. 해커는 비밀 정보를 key를 통해서 해석할 수 있다.비대칭 키 암호(Asymmetric Encryption)symmetric encryption과 같이 암호화와 복호화에 동일한 key를 사용하는 경우 정보 해킹의 문제가 있기 때문에, 비대칭 키 암호(asymmetric encryption) 방식을 사용할 수 있다. asymmetric encryption에서는 하나의 key만을 사용하는 symmetric encryption과는 달리, private key와 public key를 구분해서 사용한다. 이 예시에서는 public key를 이용하여 정보를 암호화 할 것이기 때문에, 개념적으로 public lock이라는 표현의 더 어울리기에, public lock이라고 부르겠다. 즉, 어떠한 정보를 누구나 접근할 수 있는 public lock을 통해서 암호화 할 수 있지만, 이를 복호화 하기 위해서는 사용자만이 보유할 수 있는 private key가 필요한 것이다.예를 들어보자. symmetric encryption의 예제처럼 아이디와 비밀번호를 전송하면 정보 해킹 위험의 소지가 있었다. 그대신 ssh-keygen 명령어를 통해서 private key에 해당하는 id_rsa와 public key(lock)에 해당하는 id_rsa.pub 파일을 생성해서 사용할 수 있다. public lock인 id_rsa.pub 파일을 서버에 설정하고, private key인 id_rsa 정보를 ssh 접속 시 함께 전달해주면, 안전하게 서버에 접근할 수 있는 것이다. 위 그림과 같이 여러 user가 동일한 서버에 접근하는 것도 가능하다. 하나의 서버에 여러 entry를 허용하되, 각 entry에 각각의 public lock을 설정하고, 접근할 때 자신의 private key를 ssh 사용 시 입력해주면 된다.위와 같이 SSH를 이용해도 좋지만, OpenSSL을 이용할 수도 있다. OpenSSL은 네트워크를 통한 데이터 통신에 쓰이는 프로토콜인 TLS와 SSL의 오픈 소스 구현판이다. 예를 들어, openssl genrsa -out example.key 1024 명령과 openssl rsa -in example.key -pubout &gt; example.pem 명령으로 private key인 example.key 파일 및 public key(lock)인 example.pem을 생성할 수 있다.대칭 키 방식과 비대칭 키 방식을 함께 활용한 암호화와 복호화먼저, 사용자가 https를 통해 웹 서버에 접근하면, 사용자는 서버로부터 서버의 public key(lock)를 전송받는다. 그러고 나면, 사용자의 브라우저는 서버의 public key(lock)를 이용하여 사용자의 symmetric key를 암호화한다. 이 과정은 위 그림에서 파란색 박스에 해당한다.이후, 서버로 암호화된 symmetric key를 전송할 수 있다. 항상 그렇듯, 해커는 매 순간 트래픽을 보며 정보를 해킹하는데, 이번에는 암호화된 symmetric key가 해킹된다. 그러나 이 경우, 해커는 서버의 private key를 보유하지 못하므로 암호화된 symmetric key를 복호화 할 수 없다. 즉, 사용자의 비밀 정보를 열어볼 방법이 없는 것이다. 반면, 암호화되어 안전하게 서버에 전송된 symmetric key는 서버의 private key에 의해 복호화되고, 사용자의 암호화된 비밀 정보들을 무사히 복호화 할 수 있게 된다.관행적으로 public key는 *.crt 또는 *.pem 확장자를 사용한다. 또한 private key는 *.key 또는 *-key.pem의 확장자를 쓴다.그러나 위와 같이 해커가 자신의 서버로 가짜 웹을 호스팅하여 사용자에게 진짜 웹인 것처럼 속인다면, 사용자는 자신의 symmetric key를 해커 서버의 public key(lock)으로 암호화하여 해커의 서버로 전송할 위험이 있다. 이러한 문제를 막기 위해서 인증서(certificate)가 필요하다.인증서의 개념사실 사용자로부터 https 접근이 있을 때, 서버는 public key(lock)만을 전송하지 않고, certificate 또한 함께 보낸다. 사용자의 웹 브라우저에는 기본적으로 서버로부터 전송받은 certificate가 유효한지를 검증하는 메커니즘이 존재한다. 유효하지 않은 것으로 보이는 certificate가 발견되면 브라우저에서 Not secure 경고를 보내게 된다. 그렇다면, 어떻게 certificate가 유효한지 인증 받을 수 있을까?암호학에서는 디지털 인증서를 발급하는 곳으로서 Certificate Authority(CA, 인증 기관)라고 불리우는 기관이 있는데, 이들에 의해서 유효함을 인증 받을 수 있다. 대표적인 CA로는 Comodo, Semantec, DigiCert 등 여러 곳이 있다.certificate의 유효함을 인증하기 위해서 Certificate Signing Request(CSR)를 요청하면, CA가 CSR을 요청한 곳의 세부 사항을 검증한 후, certificate에 sign을 한다. 이때 세부 사항 검증 과정에서 해커가 발행한 certificate인지를 확인하게 되고, 해커의 경우 CA에 의해 sign이 거절될 수 있다.한편, 사용자의 브라우저에는 기본적으로 CA의 public key들이 존재한다. 따라서 CA 자체가 가짜인지는 브라우저에서 구별될 수 있다.쿠버네티스에서의 TLSCA에서 사용하는 public key(lock)와 private key를 Root Certificates 라고 하며, 클라이언트와 서버의 것들을 각각 Client Certificates, Server Certificates 라고 한다. 이러한 개념들이 쿠버네티스 클러스터에서 어떻게 적용되는지 살펴보겠다.쿠버네티스 클러스터는 복수의 노드, 즉, 마스터 노드와 워커 노드들로 구성되어 있다. 이 노드들 간의 통신 또한 보안이 되어야 하며, 암호화되어 처리돼야 한다. 예를 들어, kubectl을 통하여 클러스터에 접근하거나 kube-apiserver에 직접 접근하는 경우 모두 TLS 보안 연결이 설정되어야 한다. 또한 쿠버네티스 클러스터 내 모든 컴포넌트들 간의 통신에도 TLS 보안 연결이 설정되어야 한다.쿠버네티스에서의 Server Certificatesserver certificates는 어느 곳에서 필요할까? 쿠버네티스 아키텍처에서 요청을 받아들이는 역할이 있는 곳들인 kube-apiserver와 ETCD server, kubelet server에서 각각 존재할 것이다.쿠버네티스에서의 Client Certificates또한, client cetificates의 경우는 다른 컴포넌트로 요청을 받아들이는 역할이 있는 곳들에 존재한다. kube-apiserver의 인증이 필요한 관리자(admin user), 파드 스케줄링을 위해 kube-apiserver와 통신해야 하는 kube-scheduler 컴포넌트, 그리고 기타 kube-apiserver와 통신하는 kube-controller manager 컴포넌트나 kube-proxy 등도 모두 client certificates가 되어야 한다. 한편 ETCD server나 kubelet server의 관점에서는 kube-apiserver가 요청을 보내는 입장으로서 클라이언트가 되므로, client certificates를 별도로 갖추어야 한다.참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스" }, { "title": "(K8S) 쿠버네티스 인증(Authentication) 기초 개념", "url": "/posts/Authenticate-basic/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Security, Authentication", "date": "2022-08-21 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.본 글에서는 쿠버네티스의 인증(Authentication) 매커니즘의 가장 기초적인 방법을 단순히 공부 목적으로 정리한다. 따라서 실전에서 추천되는 방법은 아니며, 기본적인 개념 정도만 잡고 가면 좋을 것 같다.인증(Authenticate)인증(Authentication)이란, 사용자가 누구인지를 식별하는 행위로, 우리가 흔히 사용하는 로그인 기능도 일종의 인증 과정이라고 생각할 수 있다.쿠버네티스에서는 사용자 계정(User Account)과 서비스 계정(Service Account)에 대해 인증한다.사용자 계정에 대한 인증은 우리가 일반적으로 생각하는 사용자를 인증하는 개념이며, 서비스 계정에 대한 인증은 클라이언트나 기타 컴포넌트가 kube-apiserver를 호출하는 등 쿠버네티스에서의 통신에 있어 시스템(e.g., Bot)을 인증하는 개념이다.쿠버네티스는 근본적으로 사용자 계정을 직접적으로 관리하는 시스템이 존재하지 않기 때문에, kubectl create user {사용자 이름}과 같은 명령어 또한 존재하지 않는다.따라서 근본적으로 사용자를 직접 관리할 수 없는 쿠버네티스에서는 사용자 정보 상세가 적혀있는 파일이나 certificates, 또는 OAuth나 Webhook과 같은 별도의 외부 계정 연동 시스템을 사용해야 한다.한편, 서비스 계정은 이처럼 관리할 수는 있다.기초적인 방식 : 사용자 정보 상세 파일을 이용사용자를 인증하기 위한 예시로, 가장 기초적인 방식인 사용자 정보 상세가 적혀있는 파일의 경우를 살펴보겠다. 실제 운영 시에는 적합하지 않으므로 개념만 잡고 가도 좋을 것이다.아래의 예시는 그중에서도 패스워드를 이용하는 static password file을 적용하는 사례인데, 이외에도 토큰을 활용하는 static token file을 적용할 수도 있다.위와 같이 사용자의 패스워드, 사용자 이름, 사용자 아이디(네번째 열에 그룹 추가 가능)가 적혀있는 user-details.csv 파일을 생성한 이후, kube-apiserver.service에 --basic-auth-file=user-details.csv를 입력하여 설정할 수 있다. 이후, kube-apiserver를 재실행하면 사용자 인증이 적용된다.kubeadm 툴을 이용한다면, 위와 같이 설정해주면 되는데, 이 파일이 업데이트되면 자동으로 kube-apiserver가 재실행되어 반영된다.사용자 인증 설정이 완료되면, 다음과 같이 사용자 정보와 패스워드를 입력하여 kube-apiserver에 접근할 수 있게 된다.참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스[3] 조대협 님의 블로그 : 쿠버네티스 #16 - 보안 (1/4) 계정 인증과 권한 인가" }, { "title": "(K8S) 쿠버네티스 API groups", "url": "/posts/API-Groups/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Security, API groups, Certificate", "date": "2022-08-21 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.쿠버네티스를 사용하면, kubectl 명령을 통해서 접근하든, 직접 접근하든 간에 kube-apiserver를 통해 접근해야만 한다. 예를 들어, 버전을 체크하는 명령을 수행한다고 해보자. curl https://kube-master:6443/version 과 같이 master 노드의 주소와 기본 포트번호 6443으로 apiserver에 접근할 수 있으며, API /version 통해 버전을 체크할 수 있다.유사한 방식으로, 파드의 리스트를 보고자 한다면, curl https://kube-master:6443/api/v1/pods 와 같이 master 노드의 주소와 기본 포트번호 6443으로 접근하되, API /api/v1/pods를 씀으로써 접근할 수 있다. 그렇다면, 버전을 볼 때는 왜 /version 으로 접근하고, 파드를 볼 때는 /api 로 접근하는 것일까?쿠버네티스 API의 다양한 그룹들위 예시 이외에도, 쿠버네티스의 API는 목적에 따라서 다양한 그룹들이 존재한다. 그 종류는 다음과 같다. /metric : 클러스터의 상태를 모니터링하기 위한 API /healthz : 클러스터의 상태를 모니터링하기 위한 API /version : 클러스터의 버전을 확인하기 위한 API /api : 클러스터의 기능과 관련한 API (core group) /apis : 클러스터의 기능과 관련한 API (named group) /logs : 서드 파티 로깅 애플리케이션을 통합하여 사용하기 위한 API이들 중 /api와 /apis를 살펴보고자 하는데, 전자인 /api는 core group으로, 핵심 기능들이 하위에 존재하며, 그 예로는 아래와 같다.한편 후자인 /apis는 named group으로, 아래와 같이 좀더 계층적으로 구조화 되어 있다./apis 하위에는 /apps , /extensions , /networking.k8s.io , /storage.k8s.io , /authentication.k8s.io , /certificates.k8s.io 등으로 구성되어 있는 API Groups가 존재하며, 그 하위에는 Resources가, 그리고 Resource의 하위에는 각 Resource가 취할 수 있는 행동인 Verbs가 존재한다.쿠버네티스에서도 위 구조들을 간단한 명령어로 확인할 수 있는데, curl http://localhost:6443 -k 와 같이 추가적인 path 없이 kube-apiserver에 접근하면 사용 가능한 API groups들을 확인할 수 있다. 또한 curl http://localhost:6443/apis -k | grep \"name\" 과 같은 명령어로 named group 중 사용 가능한 API group들을 확인해볼 수 있다.쿠버네티스 API와 인증curl http://localhost:6443 -k 명령어로 직접 kube-apiserver에 접근을 시도할 경우, 별도로 인증 메커니즘을 지정하지 않으면 접근이 제한될 수 있다. 이 경우, API에 인증서 파일(certificate file)을 명시함으로써 인증을 받을 수 있다. 그 예는 다음과 같다. curl http://localhost:6443 -k --key admin.key --cert admin.crt --cacert ca.crt또 다른 방법으로는 kubectl proxy 명령을 통해서 proxy service를 local에서 포트번호 8001번으로 실행하고, kubeconfig 파일에 정의된 certificate를 이용하여 클러스터에 접근할 수 있다. 즉, curl http://localhost:8001 처럼 proxy service에 접근하면, proxy가 kubeconfig로부터 certificate를 이용해서 요청을 kube-apiserver에 전달해주는 것이다.참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스" }, { "title": "(K8S) Drain과 Cordon", "url": "/posts/Drain-and-Cordon/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Drain, Cordon", "date": "2022-08-20 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.Drain과 Cordon의 필요성소프트웨어 업그레이드라든지 패치 적용, 혹은 하드웨어 관리 등 유지보수를 목적으로 클러스터 내의 일부 노드를 중단시켜야 할 때, 쿠버네티스가 어떻게 작동할까?노드가 중단된 경우의 예시그림 (위)와 같이 마스터 노드와 워커 노드가 구성되어 있으며, 파란색 파드는 레플리카셋에 의해 관리되고 있다고 가정해보자. 그림 (아래)와 같이 어떤 이유에서든 워커 노드 중 하나가 중단되게 되면, 그 워커 노드 내에 있던 파드는 이용할 수 없게 된다.워커 노드 01이 중단된다 하더라도 파란색 파드의 경우는 다행이 이용할 수 있다. 왜냐하면, 파란색 파드의 레플리카가 다른 워커 노드에도 존재하기 때문에 쿠버네티스가 다른 워커 노드에 있는 파란색 파드를 이용할 수 있도록 스케줄링해주기 때문이다. 한편, 워커 노드 01의 중단으로 인해 다른 노드에 레플리카가 존재하지 않는 초록색 파드는 아예 이용할 수 없게 된다.이와 같이 노드의 중단 상태가 발생하게 되었다고 하더라도 금방 노드가 살아난다면, kubelet이 다시 작동하게 될 것이고, 순간적으로 멈추었던 파드들도 다시 작동하게 된다. 그런데, 노드의 중단 상태가 5초 이상 지속되면, 노드 내의 파드는 아예 종료가 되고, 쿠버네티스는 해당 노드가 ‘죽었다’고 판단하게 될 것이다. 쿠버네티스에서는 이처럼 파드가 다시 되살아나는지 지켜보기 위해 기다려주는 시간을 pod eviction timeout 이라고 부르고, 컨트롤러 매니저에 기본 값으로 설정된 pod eviction timeout은 5초이다.pod eviction timeout이 지나고 나면, 중단되었던 워커 노드 01은 다시 되살아 날 것이다. 이 경우, 레플리카셋에 의해 관리되는 파란색 파드는 워커 노드 01이 중단되었다 하더라도 워커 노드 02에 새롭게 레플리카가 만들어졌을 것이다. 그러나 레플리카셋에 의해 관리되지 않는 초록색 파드의 경우, 워커 노드 01이 다시 되살아난다고 하더라도 노드 중단 시에 사라져버려서 더이상 사용할 수 없게 된다.위 예제에서 알 수 있듯이, 만약 우리가 pod eviction timeout의 시간 동안 중단되었던 노드가 확실하게 다시 살아날 수 있다는 것을 알거나, 혹은 레플리카셋 덕에 다른 노드에서 파드가 실행될 수 있는 경우에는 재빠르게 노드를 유지보수 한 후 재부팅하여 유지보수를 하면 된다. 그런데 pod eviction timeout 시간 동안 노드가 확실히 다시 살아날 수 있다는 가정은 꽤나 위험한 가정이다.노드 Drain 하기따라서 더욱 안전한 방법으로 업그레이드를 수행할 수 있다. kubectl drain {노드 이름} 명령어를 입력하면, 노드 내의 파드들이 다른 노드로 옮겨지는 것과 같은 효과를 볼 수 있다. 실제로 옮겨지는 것은 아니고, 파드가 실행되던 원래의 노드에서 파드의 컨테이너들이 '우아하게 종료(gracefully terminate)'되며, 다른 노드에서 새롭게 파드가 실행되는 것이다. 공식 도큐먼테이션에는 drain 명령어에 대해 다음과 같이 설명한다. When kubectl drain returns successfully, that indicates that all of the pods have been safely evicted.Cordon으로 특정 노드에 스케줄링 제한하기유지보수 하고자하는 노드를 drain 하고 나면, 해당 노드에 대해서 kubectl cordon {노드 이름} 명령으로 cordon 상태를 적용할 수 있다. cordon은 특정 노드를 선택하여 스케줄링 대상에서 제외시키는 방법으로, cordon을 적용한 제한을 uncordon 명령으로 해제하기 전까지는 파드들이 해당 노드에 스케줄링 될 수 없다.이제 유지보수 하려는 워커 노드 01 내에 있던 파드들이 다른 노드들로 안전하게 옮겨졌으니, 워커 노드 01에 대해 유지보수 할 수 있다. 자유롭게 재부팅해도 상관 없다. 그런데, 유지보수가 완료되고 재부팅한다 하더라도 여전히 cordon 상태이므로, 파드들이 워커 노드 01에는 스케줄링 될 수 없다. kubectl uncordon {노드 이름} 명령어를 통해서 해당 노드에도 스케줄링을 허용해주어야 한다.참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스" }, { "title": "(K8S) 멀티 컨테이너 파드(Multi Container Pods)", "url": "/posts/Multi-Container-Pods/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Pod, Multi Container Pods", "date": "2022-08-19 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.멀티 컨테이너 파드Monolithic 구조와 MicroService 구조 개념대규모 monolithic 애플리케이션을 microservice로 불리우는 subcomponent들로 분리할 수 있다는 아이디어 덕에, 각각 독립적이며 작고 재사용 가능한 코드들을 개발하고 배포할 수 있게 되었다.이러한 microservice 구조를 이용하면, 수정 사항이 있을 때 애플리케이션 전체를 수정해야하는 monolithic 구조와 달리 각각의 작은 서비스들을 수정할 수 있으며, 손쉬운 scale up 또는 scale down이 가능해진다.예를 들어서, 하나의 파드 내에 logging을 담당하는 서비스와 웹 서버 서비스가 함께 작동해야 한다고 해보자. 이 두 서비스는 각각의 역할이 분명히 정해져 있기 때문에, logging 서비스와 웹 서버 각 컨테이너가 따로 개발되고 배포되어야 한다. 다만, 각 서비스들은 반드시 함께 작동되어야 한다.이처럼 각각 독립적이지만 반드시 함께 작동해야 하는 서비스들이 한 데 묶여 함께 생성되기도 하고(scale up) 삭제되기도 하면서(scale down) 동일한 라이프 사이클을 가져야 하기 때문에 멀티 컨테이너 파드(Multi-container Pods)가 필요하다.멀티 컨테이너 파드의 개념멀티 컨테이너 파드 안에 있는 각 서비스(컨테이너)들은 동일한 네트워크를 공유하기 때문에 localhost로 서로 간 통신될 수 있으며, 동일한 스토리지 볼륨을 사용하므로 모두가 동일하게 접근할 수 있다.멀티 컨테이너 파드의 정의멀티 컨테이너 파드를 정의하는 방법은 매우 간단하다. 파드 생성 YAML 파일에서 컨테이너 정보를 입력하는 spec 부분은 리스트 형태로 되어 있는데, 단순히 리스트의 원소로 컨테이너의 정보를 입력하며 나열해주면 된다.# pod-definition.yamlapiVersion: v1kind: Podmetadata: name: simple-webapp labels: name: simple-webappspec: containers: # 아래 부분에서 컨테이너 정보들을 '-'를 사용하여 리스트 형태로 나열한다. - name: simple-webapp image: simple-webapp ports: - containerPort: 8080 - name: log-agent image: log-agent참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스" }, { "title": "(K8S) 쿠버네티스 환경변수 설정, 컨피그맵(ConfigMap)과 시크릿(Secret)", "url": "/posts/Configure-Environment-Variables/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Docker, Configure, ConfigMap, Secret", "date": "2022-08-19 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.쿠버네티스 환경변수 설정우리가 개발한 애플리케이션은 대부분 여러가지 환경변수(설정값)들을 정의해야 한다.간단한 예를 들어보면, 로깅 레벨을 정의할 때 LOG_LEVEL=INFO처럼 단순히 키-값 형태의 설정값이 되든지, 아니면 Nginx 웹 서버가 사용하는 nginx.conf처럼 완전한 하나의 설정 파일 형태가 되든지 환경변수를 정의해야 한다.이러한 환경변수를 우리의 애플리케이션에 전달하는 가장 확실하고 직관적인 방법은 도커 이미지 내부에 설정값 또는 설정 파일을 정적으로 저장해두는 것이다.그러나 이러한 방식은 단점이 있는데, 도커 이미지는 한번 빌드가 완료되면 불변의 상태이기 때문에 설정 옵션을 유연하게 변경할 수 없다.파드 정의 YAML 파일을 활용한 환경변수 설정쿠버네티스에서는 다음과 같이 파드 정의 YAML 파일에서 env를 통해 컨테이너에 환경변수를 직접 하드 코딩 방식으로 전달할 수 있다.# pod-definition.yamlapiVersion: v1kind: Podmetadata: name: simple-webapp-colorspec: containers: - name: simple-webapp-color image: simple-webapp-color ports: - containerPort: 8080 # 아래 env 부분에서 환경 변수를 설정한다. env: - name: APP_COLOR # 컨테이너가 사용할 수 있는 환경 변수의 이름 value: pink # 환경 변수의 값이와 같은 방식을 Plain Key Value라고 부른다. 나쁜 방식은 아니지만, 상황에 따라서 환경변수의 값만 다르고 내용은 동일한 YAML 파일을 여러 개 사용해야 하는 경우도 있다.이 경우, 파드 정의 YAML 파일에서 환경변수만을 분리해서 관리하면 한결 편리할 것이다.쿠버네티스는 YAML 파일과 환경변수를 분리할 수 있는 방식으로 컨피그맵(ConfigMap)과 시크릿(Secret) 오브젝트를 제공한다.컨피그맵(ConfigMap)앞서 파드 정의 YAML 파일에서 환경 변수를 정의하는 방식을 살펴보았다. 그런데, YAML 파일이 많아지면, 다양한 파일들에 정의되어 있는 환경변수들 또한 관리하기 어려워진다.따라서 파드 정의 YAML 파일 밖에서 환경변수들을 관리하는 방식인 컨피그맵(ConfigMap)이 필요하다.컨피그맵은 환경변수 데이터를 키-값(key-value)의 쌍으로 전달하기 위해 사용된다. 컨피그맵은 파드가 생성될 때 파드에 주입되고, 이렇게 주입된 키-값 쌍의 환경변수들은 파드 내 컨테이너에서 호스트되는 애플리케이션에서 접근할 수 있게 된다.즉, 다음 두 단계를 거치는 것이다. 컨피그맵 생성하기 파드에 컨피그맵 주입하기컨피그맵 생성하기컨피그맵은 다른 쿠버네티스 오브젝트들과 마찬가지로 명령형(imperative) 방식과 선언형(declarative) 방식으로 생성할 수 있다.컨피그맵 생성하기 : 명령형(imperative) 방식 kubectl create configmap {컨피그맵 이름} --from-literal={키}={값} 예) kubectl create configmap app-config --from-literal=APP_COLOR=blue --from-literal=APP_MODE=prod 위와 같이 --from-literal 옵션을 사용하여 컨피그맵에 환경변수를 키-값 형태로 전달할 수 있다. 또한, --from-literal 옵션을 여러 번 사용하여 여러 개의 요소들을 한번에 입력할 수도 있다. kubectl create configmap {컨피그맵 이름} --from-file={파일의 경로} 예) kubectl create configmap app-config --from-file=app_config.properties 위와 같이 파일의 경로를 지정해주는 방식도 가능하다.참고로, 파일로 사용한 app_config.properties는 아래와 같이 구성할 수 있다.# app_config.propertiesAPP_COLOR=blueAPP_MODE=prod컨피그맵 생성하기 : 선언형(declarative) 방식# config-map.yamlapiVersion: v1kind: ConfigMap # kind는 ConfigMap으로 설정한다.metadata: name: app-configdata: # 아래 부분에 ConfigMap 내용을 적어준다. APP_COLOR: blue APP_MODE: prod이후 kubectl create -f config-map.yaml 명령어를 입력한다.kubectl get configmaps 또는 kubectl describe configmaps 명령어를 통해 현재의 ConfigMap을 확인할 수 있다.파드에 컨피그맵 주입하기컨피그맵을 생성했다면, 생성된 컨피그맵을 파드에 주입해야 우리가 따로 설정한 환경변수를 활용할 수 있다.# pod-definition.yamlapiVersion: v1kind: Podmetadata: name: simple-webapp-colorspec: containers: - name: simple-webapp-color image: simple-webapp-color ports: - containerPort: 8080 # 아래 envFrom 부분을 통해 생성된 ConfigMap을 파드에 주입(설정)한다. envFrom: - configMapRef: name: app-config # ConfigMap 정의 YAML 파일의 metadata 이름을 적는다.이후 kubectl create -f pod-definition.yaml 명령어를 통해 파드를 생성하면, 컨피그맵을 통해 환경변수 설정이 주입된 파드가 실행될 것이다.이러한 방식 외에도 컨피그맵을 주입하는 방식은 아래와 같이 몇 가지 더 있다.파드에 컨피그맵을 주입하는 여러 방법# 위에서 살펴본, 기본적인 방식envFrom: - configMapRef: name: app-config # ConfigMap 정의 YAML 파일의 metadata 이름을 적는다.# 하나의 키 값만 가져오는 경우env: - name: APP_COLOR valueFrom: configMapKeyRef: name: app-config # ConfigMap 정의 YAML 파일의 metadata 이름을 적는다. key: APP_COLOR # 가져오고자 하는 키 값을 입력한다.# 볼륨에서 전체 데이터를 파일로 가져오는 경우volumes:- name: app-config-volume configMap: name: app-config # ConfigMap 정의 YAML 파일의 metadata 이름을 적는다.시크릿(Secret)지금까지 쿠버네티스에서 컨테이너의 환경변수를 관리하기 위해 컨피그맵을 생성하고 이를 파드에 주입하는 것을 살펴보았다.그런데, 환경변수에는 사용자의 비밀번호와 같이 민감한 정보들이 있을 수 있다. 예를 들어보자.컨피그맵의 한계, 그리고 시크릿의 필요성# app.pyimport osfrom flask import Flaskapp == Flask(__name__)@app.route(\"/\")def main(): mysql.connector.connect(host='mysql', database='mysql', user='root', password='123') return render_template('hello.html', color=fetchcolor())if __name__==\"__main__\": app.run(host=\"0.0.0.0\", port=\"8080\")위와 같은 app.py 파일이 있다고 해보자. mysql 데이터베이스에 접근하는 코드를 살펴보면, user=’root’, password=’123’ 같은 민감한 정보들이 있다.이러한 변수들을 단순히 컨피그맵을 통해서 표현하면 다음과 같이 매우 노골적으로 민감한 정보들이 표현된다.# config-map.yamlapiVersion: v1kind: ConfigMapmetadata: name: app-configdata: DB_Host: mysql DB_User: root DB_Password: passwrd이러한 문제를 해결하기 위해서 시크릿(Secret)이 활용된다.먼저, 시크릿의 생김새부터 간단히 살펴보면 다음과 같이 사람이 알아볼 수 없는 hashed format으로 값들이 표현되어 있는 것을 알 수 있다.# SecretDB_Host: bXlzcWw=DB_User: cm9vdA==DB_Password: cGFzd3JKConfigMap과 마찬가지로 Secret 또한 다음 두 단계를 거친다. 시크릿 생성하기 파드에 시크릿 주입하기시크릿 생성하기컨피그맵과 마찬가지로 명령형(imperative) 방식과 선언형(declarative)방식으로 시크릿을 생성할 수 있다.시크릿 생성하기 : 명령형(imperative) 방식 kubectl create secret generic {시크릿 이름} --from-literal={키}={값} 예) kubectl create secret generic app-secret --from-literal=DB_Host=mysql --from-literal=DB_User=root --from-literal=DB_Password=passwrd 컨피그맵과 마찬가지로, 위와 같이 --from-literal 옵션을 사용하여 시크릿에 환경변수를 키-값 형태로 전달할 수 있다. 또한, --from-literal 옵션을 여러 번 사용하여 여러 개의 요소들을 한번에 입력할 수도 있다. kubectl create secret generic {시크릿 이름} --from-file={파일의 경로} 예) kubectl create secret generic app-secret --from-file=app_secret.properties 컨피그맵과 마찬가지로, 위와 같이 파일의 경로를 지정해주는 방식도 가능하다.시크릿 생성하기 : 선언형(declarative) 방식# secret-data.yamlapiVersion: v1kind: Secretmetadata: name: app-secretdata: DB_Host: bXlzcWw= # 참고 : echo -n 'mysql' | base64 DB_User: cm9vdA== # 참고 : echo -n 'root' | base64 DB_Password: cGFzd3Jk # 참고 : echo -n 'passwrd' | base64kubectl get secrets 또는 kubectl describe secrets 명령어를 통해 생성된 시크릿을 확인할 수 있다.kubectl get secret app-secret -o yaml 명령어를 통해 YAML 형식으로도 확인할 수 있다.파드에 시크릿 주입하기위의 방식대로 시크릿을 생성했다고 하면, 생성된 시크릿을 파드에 주입해야 한다.# pod-definition.yamlapiVersion: v1kind: Podmetadata: name: simple-webapp-colorspec: containers: - name: simple-webapp-color image: simple-webapp-color ports: - containerPort: 8080 # 아래 envFrom 부분을 통해 생성된 Secret을 파드에 주입(설정)한다. envFrom: - secretMapRef: name: app-secret # Secret 정의 YAML 파일에 설정한 metadata 이름을 적는다.이후 kubectl create -f pod-definition.yaml 명령어를 통해 파드를 생성하면, 시크릿을 통해 환경변수 설정이 주입된 파드가 실행될 것이다.이러한 방식 외에도 시크릿을 주입하는 방식은 아래와 같이 몇 가지 더 있다.파드에 시크릿을 주입하는 여러 방법# 위에서 살펴본, 기본적인 방법envFrom: - secretMapRef: name: app-secret # Secret 정의 YAML 파일에 설정한 metadata 이름을 적는다.# 또는 하나의 키 값만 가져오는 경우env: - name: DB_Password valueFrom: SecretKeyRef: name: app-secret # Secret 정의 YAML 파일에 설정한 metadata 이름을 적는다. key: DB_Password # 가져오고자 하는 키 값을 입력한다.# 또는 볼륨에서 전체 데이터를 파일로 가져오는 경우volumes:- name: app-secret-volume secret: name: app-secret # Secret 정의 YAML 파일에 설정한 metadata 이름을 적는다.참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스[3] 쿠버네티스 공식 documentation : ConfigMaps[4] 쿠버네티스 공식 documentation : Secrets" }, { "title": "(K8S) 도커와 쿠버네티스의 매개변수 받는 방법", "url": "/posts/Commands-and-Arguments/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Docker, Argument, Command", "date": "2022-08-19 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.[Docker] 간단히 살펴보는 Dockerfile의 CMD프로세스가 종료되면 함께 종료되는 컨테이너docker를 이용해서 우분투 이미지를 실행하면, 위와 같이 곧바로 exit(종료) 상태로 변경되어 버린다. 왜 그런 것일까?컨테이너는 운영체제를 호스트 하지는 않고, 단지 웹 서버나, 데이터베이스와 같은 특정 프로세스들을 실행할 수 있게 한다. 또한 이러한 내부 프로세스들이 살아있는 동안에만 컨테이너도 살아있기 때문에, 내부 프로세스들이 종료되면 컨테이너도 종료된다.컨테이너가 생성될 때 실행될 명령을 정의하는 CMD그렇다면, 컨테이너 내부에 있는 프로세스는 어디에서 실행되도록 정의되어 있을까? 정답은 도커 파일(Dockerfile)이다. 보통 도커 파일을 열어보면, 다음과 같이 생겼다.nginx를 설치하고 실행하는 이 도커 파일을 보면, 마지막 CMD 명령어 부분에 컨테이너 내부에서 실행될 프로그램 명령이 적혀있는 것을 알 수 있다. 이것이 실행되면 컨테이너 내부에서 해당 명령에 대한 프로세스가 실행되는 것이다.앞서 우분투를 실행하기 위해 사용했던 우분투의 도커 파일을 열어보면, CMD 명령어 부분이 bash라고 되어 있는 것을 알 수 있다. bash는 nginx 웹 서버나 mysql 데이터베이스 같은 프로그램이 아닌, shell 이다. shell은 터미널로부터 input을 기다리고 있다가, 터미널을 찾지 못하면 종료된다.앞서 실행했듯이, 우분투 컨테이너를 run하면, 도커는 우분투 이미지로부터 컨테이너를 만들고 bash program을 실행한다. 그런데 도커는 기본적으로 컨테이너가 실행될 때 컨테이너에 터미널을 붙이지 않는다. 따라서 bash program이 터미널을 찾지 못해서 종료되는 것이다. (컨테이너가 생성될 때 만들어졌던 프로세스가 종료되면, 컨테이너도 종료되는 것 또한 유사한 원리다.)[Docker] ubuntu sleep 명령 예제를 통해 살펴보는 CMD와 ENTRYPOINT도커 파일의 CMDdocker run ubuntu sleep 5 명령을 입력하면, 실행 즉시 5초 동안 sleep 한 후 종료되는 우분투 컨테이너가 실행된다. 위와 같은 명령어는 command line에 파라미터를 이용해서 단 한번만 단편적으로 실행되도록 한다.이러한 sleep 명령을 다음과 같이 아예 도커 파일에 정의하면, 매번 이미지를 실행할 때마다 5초간 sleep 후 종료되는 컨테이너를 만들 수 있다.FROM UbuntuCMD sleep 5# 혹은 CMD [\"sleep\", \"5\"]이러한 도커 파일을 ubuntu-sleeper라는 이름으로 이미지를 빌드하고 실행하면, 5초간 sleep 후 종료되는 우분투 컨테이너가 실행되는 것이다. 이처럼 도커 파일에 CMD를 활용하여 sleep 명령과 sleep 시간을 정의하면, docker run ubuntu-sleeper sleep {원하는 시간}과 같이{원하는 시간}을 파라미터로 줌으로써 sleep 시간을 오버라이드한 명령을 수행할 수도 있다. 즉, 핵심은 docker run 명령 시 CMD에 정의한 스크립트가 오버라이드 될 수 있다는 것이다.도커 파일의 ENTRYPOINT반드시 실행되어야 할 명령어를 지정한다.그런데 docker run ubuntu-sleeper sleep {원하는 시간}처럼 {원하는 시간}을 오버라이드 할 수는 있지만, sleep이라는 CMD 명령어를 입력해야 하는 불편함이 있다.이 경우, ENTRYPOINT를 이용할 수 있다. ENTRYPOINT는 CMD와 비슷한데, docker run 명령으로 컨테이너가 시작되는 시점에 ENTRYPOINT의 명령어가 반드시 실행된다. 예제를 살펴보자.FROM UbuntuENTRYPOINT [\"sleep\"]위와 같이 명령어를 입력한 후, 마찬가지로 ubuntu-sleeper라는 이름으로 이미지를 빌드한 후, docker run ubuntu-sleeper {원하는 시간} 명령을 실행하면, ENTRYPOINT에 정의된 sleep 명령어가 반드시 실행되므로, 숫자 {원하는 시간}만이 매개변수로 작용하여 해당 시간만큼 sleep하게 된다.CMD와 ENTRYPOINT의 조합ENTRYPOINT로 Command를 지정하고, 매개변수의 기본값은 CMD로 정의한다.FROM UbuntuENTRYPOINT [\"sleep\"]CMD [\"5\"]도커 파일을 구성할 때, ENTRYPOINT와 CMD를 함께 사용하면, 이미지를 실행할 때 ENTRYPOINT를 반드시 사용하고, default 값으로는 CMD에서 정의된 값이 자동으로 사용된다.또한 docker run ubuntu-sleeper {원하는 시간} 명령을 실행하여 매개변수로 원하는 값을 입력함으로써 CMD에 정의되어 있는 default 값을 오버라이딩 할 수도 있다.[Kubernetes] 컨테이너의 매개변수를 받는 방법앞서 살펴본 ubuntu-sleeper 예제를 쿠버네티스에서 배포하면 매개변수를 어떻게 처리해야 하는지 살펴보자.args를 활용하여 매개변수 받기# pod-definition.yamlapiVersion: v1kind: Podmetadata: name: ubuntu-sleeper-podspec: containers: - name: ubuntu-sleeper image: ubuntu-sleeperubuntu-sleeper 도커 파일을 빌드하여 이미지를 생성하면, 위와 같이 파드를 정의하는 YAML 파일을 만들어볼 수 있다. 그런데, 앞서 도커 컨테이너를 이용한 예제에서는 매개변수로 sleep 시간을 command line에 추가로 넣어줄 수 있었다. 파드 생성 시에는 어떻게 해야 할까?# pod-definition.yamlapiVersion: v1kind: Podmetadata: name: ubuntu-sleeper-podspec: containers: - name: ubuntu-sleeper image: ubuntu-sleeper args: [\"10\"] # 추가된 부분! 파드에서는 이와 같이 매개변수를 입력한다.위 YAML을 보면, 마지막 줄에 args를 통해 매개변수를 입력할 수 있다. 도커 파일과 함께 보면 더욱 이해하기 쉽다.FROM UbuntuENTRYPOINT [\"sleep\"]CMD [\"5\"]YAML 파일의 args는 위와 같은 도커 파일의 CMD 부분을 오버라이드 하는 것이다. kubectl create -f pod-definition.yaml 명령을 입력하면 도커 파일의 CMD 부분이 오버라이드된 파드가 생성된다.쿠버네티스에서 Dockerfile의 ENTRYPOINT 오버라이드 하기만약, 도커 파일의 ENTRYPOINT를 오버라이드 하고 싶다면 어떻게 해야할까?참고로 도커 명령어로는 docker run --name ubuntu-sleeper --entrypoint sleep2.0 ubuntu-sleeper 10과 같은 방식으로 ENTRYPOINT를 컨테이너 실행 시 오버라이드 할 수 있다.그렇다면, 파드로는 어떻게 할까? 이는 파드 정의 YAML의 command에 대응된다.# pod-definition.yamlapiVersion: v1kind: Podmetadata: name: ubuntu-sleeper-podspec: containers: - name: ubuntu-sleeper image: ubuntu-sleeper command: [\"sleep2.0\"] # 도커 파일의 ENTRYPOINT는 파드 생성 시 'command'에 대응된다. args: [\"10\"]참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스" }, { "title": "(K8S) 스태틱 파드(Static Pods)", "url": "/posts/Static-Pods/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Scheduling, StaticPods", "date": "2022-08-18 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.마스터 노드(컨트롤 플레인)가 없는 상황 가정어떤 파드를 어떤 노드에 배포할지 kube-scheduler가 결정하면, 각각의 워커 노드에 존재하는 kubelet은 kubeapi-server로부터 자신의 노드에서 어떤 파드를 어떻게 처리해야 하는지에 대한 명령을 듣고 실행한다.만약 마스터 노드(컨트롤 플레인)의 컴포넌트들인 kube-apiserver, kube-scheduler, ETCD cluster, controller manager 등이 존재하지 않는다면 어떻게 될까?노드를 ‘배’라고 비유하면 ‘선장’으로 비유되는 kubelet은 독립적으로 자신이 위치한 노드를 잘 관리할 수 있을까? 이 경우, 파드는 어떻게 생성되고 관리되는 것일까?Kubelet이 스스로 직접 관리하는 스태틱 파드스태틱 파드(Static Pods)는 컨트롤 플레인 컴포넌트인 kube-apiserver의 도움 없이, 특정 노드의 kubelet 데몬에 의해 직접 생성 및 관리되는 파드다.kubelet은 쿠버네티스 클러스터를 이루는 다른 컴포넌트들 없이, 독자적으로 노드를 관리할 수 있다.파드 정의 YAML 파일과 같은 정보가 주어지면, 스스로 파드도 생성할 수 있다.물론 컨테이너를 실행할 수 있는 도커가 설치되어 있는 상황에서 말이다.그런데 마스터 노드가 없다는 가정에서는 kube-apiserver가 존재하지 않으므로, 어떤 파드를 만들지 등에 대한 정보를 제공받을 수 없는 상황이다.그러나, 사실 이렇게 kube-apiserver가 없는 상황에서도 어떤 파드를 만들지에 대한 정보를 제공해주면, kubelet 스스로 문제 없이 독자적으로 파드를 생성할 수 있다.즉, kubelet이 읽을 수 있는 특정 directory 경로에 파드 정의 YAML 파일을 두면, kubelet이 주기적으로 해당 경로를 체크하여 파드를 생성할 수 있다. 심지어 파드 생성 뿐만 아니라, 파드가 죽지 않고 살아있도록 보장까지 해주며, 파드 정의 YAML 파일에 변화가 있으면 파드를 재생성 해주기도 한다. 또한 파일이 사라지면, 파드를 제거하기도 한다.이처럼, kube-apiserver 등과 같은 다른 쿠버네티스 컴포넌트 없이 kubelet만이 독자적으로 만들어내고 관리하는 파드를 스태틱 파드라고 부른다.스태틱 파드가 생성되고 나면, docker ps 명령을 통해 컨테이너가 정상적으로 실행되고 있다는 것을 확인할 수 있다.그러나 kubectl 명령어로는 확인할 수 없다. 왜나하면 kubectl 명령을 처리하기 위해서는 kube-apiserver가 필요하기 때문이다.Kubelet은 파드만 생성 및 관리할 수 있다.kubelet이 관리할 수 있는 오브젝트는 파드 뿐이고, 레플리카셋이나 디플로이먼트, 서비스 등 다른 쿠버네티스 오브젝트들은 kubelet이 읽을 수 있는 특정 directory 경로에 오브젝트 정의 YAML 파일을 두더라도 생성되지 않는다.이들은 컨트롤 플레인의 컴포넌트들을 반드시 필요로 하여 전체적인 쿠버네티스 아키텍처가 있어야만 관리될 수 있기 때문이다.Kubelet이 읽을 수 있는 매니페스트 폴더파드 정의 YAML 파일을 kubelet이 읽어들일 수 있는 매니페스트(minifest) 폴더 (기본)경로인 /etc/kubernetes/manifests에 위치시킨다.예를 들어, /etc/kubernetes/manifests/static-pod-example.yaml와 같이 배치한다.해당 경로에 파일을 배치해 놓으면 알아서 실행된다.쿠버네티스 아키텍처가 갖추어진 상황에서의 스태틱 파드그렇다면, 쿠버네티스 아키텍처가 모두 갖춰진 상황에서도 스태틱 파드는 kube-apiserver의 명령에 의해 만들어지는 다른 파드들과 함께 생성될 수 있을까? 가능하다.이 경우, kube-apiserver는 스태틱 파드가 kubelet에 의해서 만들어졌다는 사실도 알고 있다. kubectl get pods 명령을 입력하면 다른 파드들과 마찬가지로 스태틱 파드 또한 나타난다. 파드의 이름을 보면 (예)static-web-node01과 같이 마지막에 node01이라는 노드 이름 또한 자동으로 붙는다.스태틱 파드가 생성되었을 때, kubelet은 각각의 스태틱 파드에 대하여 kube-apiserver에서 미러 파드(mirror pod)를 생성하려고 자동으로 시도한다.(참고로, 미러 파드는 kubelet의 스태틱 파드를 추적하는 kube-apiserver 내부의 오브젝트다.)즉, 노드에서 구동되는 스태틱 파드는 kube-apiserver에 의해서 볼 수 있지만 제어될 수는 없는 읽기 전용 파드인 셈이다.스태틱 파드 사용의 예대표적인 스태틱 파드 사용 예가 바로 컨트롤 플레인 컴포넌트를 노드에 직접 배포할 때이다.컨트롤 플레인 컴포넌트 오브젝트들을 정의하는 YAML 파일만 매니페스트 폴더에 넣어두면, kubelet이 스태틱 파드를 실행하여 해당 노드를 마스터 노드로 만들 수 있다.즉, 스태틱 파드는 컨트롤 플레인과 독립적으로 작동되므로, controller-manager.yaml, apiserver.yaml, etcd.yaml과 같은 파일을 지정된 메니페스트 폴더에 넣음으로써 컨트롤 플레인의 컴포넌트들을 노드에 직접 배포할 수 있는 것이다. 이들 중 어떠한 스태틱 파드에 충돌이 난다 하더라도, kubelet이 다시 restart 해줌으로써 안정적으로 실행될 수 있다.kubeadm 툴은 이와 같은 방법으로 쿠버네티스 클러스터를 구성한다. kubectl get pods -n kube-system 명령을 통해서 kube-system의 namespace에서 작동하고 있는 파드를 확인하면, 컨트롤 플레인의 컴포넌트들을 확인할 수 있듯이 말이다.스태틱 파드와 데몬셋의 공통점 및 차이점 공통점 스태틱 파드와 데몬셋 모두 kube-scheduler에 의해서 만들어지지 않는다는 공통점이 있다. 차이점 스태틱 파드는 kube-apiserver 없이, kubelet에 의해서만 생성되는 반면, 데몬셋은 kube-apiserver에 의해 생성된다. 스태틱 파드는 컨트롤 플레인 컴포넌트를 노드에 직접 배포하기 위해서 사용되는 반면, 데몬셋은 모니터링이나 로깅을 위한 에이전트를 배포하기 위해 사용된다. 참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스[3] 쿠버네티스 공식 documentation : Create static Pods" }, { "title": "(K8S) 롤링 업데이트(Rolling Update)", "url": "/posts/RollingUpdates/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, RollingUpdate", "date": "2022-08-18 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.디플로이먼트 롤아웃과 리비전앞서, 디플로이먼트는 레플리카셋의 변경 사항을 저장하는 리비전(revision)을 남기며, 문제가 발생할 경우 이를 이용하여 롤백(rollback)을 할 수 있다는 장점을 살펴보았다.이 과정을 그림으로 간단하게 예를 들면 아래와 같다.최초에 디플로이먼트를 생성하면, 롤아웃(rollout)이 시작되는데, 이 롤아웃은 위 그림과 같이 nginx:1.7.0 버전들로 이루어진 디플로이먼트 revision 1을 만들어낸다고 하자.또한 시간이 지나서 애플리케이션(즉, 컨테이너)이 업그레이드 될 때도 롤아웃이 진행되는데, 이 롤아웃은 nginx:1.7.1 버전들로 이루어진 디플로이먼트 revision 2를 만들어낸다고 하자.이처럼 리비전을 통해 변화들이 추적되기 때문에, 필요에 따라 이전 디플로이먼트 버전으로 롤백 할 수 있다.롤아웃 명령어(Rollout Command) kubectl rollout status deployment/&lt;deployment 이름&gt; 명령어를 통해서 해당 deployment의 rollout 상태를 확인할 수 있다. kubectl rollout history deployment/&lt;deployment 이름&gt; 명령어를 통해서 해당 deployment의 revision history 정보를 알 수 있다.디플로이먼트 전략(Deployment Strategy)디플로이먼트의 업데이트 전략은 두 가지, 즉, 롤링 업데이트(Rolling Update)와 재생성(Recreate)가 있다..spec.strategy.type에서 전략을 명시할 수 있으며, 디플로이먼트의 특별한 배포 전략을 설정하지 않으면, 롤링 업데이트가 기본값이다.재생성(Recreate)재생성(Recreate) 전략은 애플리케이션의 모든 이전 버전의 인스턴스들을 한번에 다운시킨 후 한꺼번에 업데이트를 진행하는 방식이다.즉, 업데이트 전에 파드 종료를 보장할 수 있다. 그러나 이전 버전의 모든 인스턴스들이 다운되었을 때 애플리케이션이 다운되어 사용자들이 접근할 수 없게 되는 문제가 있다.롤링 업데이트(Rolling Update)롤링 업데이트(Rolling Update)는 이전 버전의 인스턴스를 하나씩 번갈아가면서 업데이트 하는 방식이다. 롤링 업데이트 전략은 모든 인스턴스가 동시에 다운되지 않기 때문에 애플리케이션이 다운되는 문제를 해결할 수 있다.롤링 업데이트 및 롤백 방법롤링 업데이트롤링 업데이트의 가장 쉬운 방법은 디플로이먼트 정의 YAML 파일 내 상세 정보를 원하는 버전에 맞게 변경한 후, kubectl apply -f &lt;deployment 이름&gt;.yaml 명령어를 입력하여 수행할 수 있다.YAML 파일을 이용하지 않고서도 변경할 수는 있다. 예를 들어서, 디플로이먼트 이름을 myapp-deployment라고 한다면, kubectl set image deployment/myapp-deployment nginx=nginx:1.9.1와 같이 kubectl set 명령어를 사용하고 nginx:1.9.1과 같이 직접 특정 버전을 기입함으로써 원하는 버전으로 명령어만을 이용하여 롤링 업데이트 할 수 있다.다만, 이 경우에는 디플로이먼트 정의 YAML 파일의 내용은 변경되지 않으므로, 미래에 해당 YAML을 다시 사용할 경우 버전 착오에 유의해야 한다.롤백롤링 업데이트 이전 상태로 되돌리고 싶다면, kubectl rollout undo deployment/ 명령어를 실행하여 rollback 할 수 있다.롤링 업데이트가 진행되는 모습의 예디플로이먼트는 롤링 업데이트를 위해서 레플리카셋을 하나 더 생성하고, 기존 레플리카셋 내에 있는 파드를 하나씩 삭제함과 동시에 새로운 레플리카셋 내에서 파드를 하나씩 업데이트 하는 방식으로 롤링 업데이트를 진행한다.위와 같이 kubectl get replicasets명령어를 통해서 두 개의 레플리카셋이 활용되는 모습을 확인할 수 있다.참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스" }, { "title": "(K8S) 데몬셋(DaemonSet)", "url": "/posts/DaemonSet/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Scheduling, DaemonSet", "date": "2022-08-18 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.데몬셋(DaemonSet)이란?데몬셋(DaemonSet)은 클러스터 내의 모든 노드에 파드 복제본을 단 하나씩 존재하도록 보장한다.여러 개의 파드 복제본을 클러스터 내의 여러 노드에 배포한다는 점에서 레플리카셋과 유사하지만, 데몬셋은 각 노드마다 단 하나의 파드만을 배포한다는 차이가 있다.클러스터 내 새로운 노드가 생겨나면, 데몬셋은 해당 노드에도 파드를 자동으로 배포한다.마찬가지로 클러스터 내에 존재하던 노드가 사라지면, 그 노드에 데몬셋에 의해 배포되어 있던 파드를 자동적으로 제거(garbage collected)한다.데몬셋의 활용데몬셋의 전형적인 활용 예로는 모든 노드에서의 클러스터 스토리지 데몬(daemon), 로그 수집 데몬, 노드 모니터링 데몬을 예로 들 수 있다.이외에도 모든 워커 노드에 반드시 존재해야 하는 kube-proxy나 네트워킹 솔루션인 weave-net 등 역시 데몬셋의 중요한 활용 예시다.데몬셋을 생성하는 방법데몬셋은 레플리카셋과 생성하는 방식이 매우 비슷하다.# daemon-set-definition.yamlapiVersion: apps/v1kind: DaemonSet # 사실상 이 부분만 ReplicaSet과 다르며, 나머지는 동일하다.metadata: name: monitoring-daemonspec: selector: matchLabels: app: monitoring-agent template: metadata: labels: app: monitoring-agent spec: containers: - name: monitoring-agent image: monitoring-agent이후 kubectl create -f daemon-set-definition.yaml 명령을 통해서 생성할 수 있고, kubectl get demonsets 명령과 kubectl describe daemonsets &lt;daemonset의 이름&gt;을 통해서 생성된 데몬셋의 정보를 확인할 수 있다.참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스" }, { "title": "(K8S) 파드에 필요한 리소스 설정하기", "url": "/posts/Resource-Requirements-and-Limits/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Scheduling, Resource", "date": "2022-08-17 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.쿠버네티스의 스케줄러(scheduler)는 어떤 파드를 어떤 노드에 배치할지 결정한다. 즉, 해당 파드가 필요로하는 자원의 정도를 살펴보고, 이를 지원할 수 있는 적합한 노드에 파드를 배치한다.가용 자원으로 파드를 실행할 수 없는 상태인 노드는 피하고, 가용 자원이 적당한 노드에 파드를 배포하는 것이다.만약, 그 어떠한 노드도 파드를 실행할 수 없는 상태라면, 쿠버네티스는 스케줄링을 중단하고 파드 배포를 pending한다.pending 상태의 event를 예를 들면, FailedScheduling No nodes are available that match all of the following predicates:: Insufficient cpu (3).과 같은 에러 메시지를 볼 수 있다.이번 글은 파드를 실행하는 데 있어서 필요한 자원을 명시적으로 설정하는 방법을 다룬다.파드 생성 시 Resource Request다음과 같이 파드 정의 YAML 파일을 통해 파드를 구동하기 위해 필요한 리소스를 명시적으로 설정할 수 있다.# pod-definition.yamlapiVersion: v1kind: Podmetadata: name: simple-webapp-color labels: name: simple-webapp-colorspec: containers: - name: simple-webapp-color image: simple-webapp-color ports: - containerPort: 8080 resources: # 아래 부분을 설정함으로써 파드 실행에 필요한 노드의 자원을 정할 수 있다. requests: memory: \"1Gi\" cpu: 1 limits: # default 제한 값이 싫은 경우, 아래에 설정할 수 있다. memory: \"2Gi\" # default는 512Mi이다. cpu: 2 # default는 1(vCPU)이다.컨테이너 자체적으로는 노드에서 얼마나 많은 리소스를 사용할지 결정할 수 없다.그래서 자신이 써도 되는 수준의 리소스보다 더욱 많이 사용하게 될 수 있고, 이는 결국 다른 컨테이너나 노드에 영향을 주게 된다.따라서 파드에서 컨테이너에 대한 자원을 설정해서 제한하는 방법을 사용해야 한다.별다른 설정을 명시적으로 하지 않으면, 쿠버네티스는 컨테이너들에 default로 자원을 제한하여 할당하는데, CPU의 경우는 1 vCPU 만큼, 메모리의 경우 512Mi 만큼을 할당한다.default 제한 값이 마음에 들지 않을 경우, limits를 명시적으로 기재하여 설정할 수 있다.클러스터가 제한된 CPU 값을 초과하려 하면, 쿠버네티스가 이를 throttle하여 막는다. 즉, 제한값을 초과하지 못하는 것이다. 반면에 메모리 사용의 경우는 컨테이너의 자원 사용이 제한된 값을 넘을 수는 있는데, 이때는 파드가 terminate 되고 만다.리소스의 단위CPU 단위CPU의 단위는 m으로도 사용할 수 있는데, 이때 m은 milli, 즉, CPU 1개의 1/1000을 의미한다. 예를 들어, CPU 0.1은 100m으로 표기될 수 있다. 최소 1m까지 값을 가질 수 있다.1 CPU는 1 vCPU(가상 CPU 코어)와 동일하다. 이는 1 AWS vCPU, 1 GCP Core, 1 Azure Core 등과 동일한 수준이다.메모리 단위메모리의 단위는 보통 Mi를 사용하는데, 이는 MiB(메비바이트)를 의미한다. 참고로, 엄밀하게는 MiB와 MB는 다르지만, 정교한 SW가 아니라면 동일한 의미로 사용해도 무방하다. 참고 1 G(Gigabyte) = 1,000,000,000 bytes 1 M(Megabyte) = 1,000,000 bytes 1 K(Kilobyte) = 1,000 bytes 1 Gi(Gibibyte) = 1,073,741,824 bytes 1 Mi(Mebibyte) = 1,048,576 bytes 1 Ki(Kibibyte) = 1,024 bytes 참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스" }, { "title": "(K8S) 테인트와 톨러레이션 vs 노드 어피니티", "url": "/posts/Taints-and-Tolerations-vs-Node-Affinity/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Scheduling, Taint, Toleration, NodeAffinity", "date": "2022-08-16 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.이번 글에서는 파드를 적합한 노드에 배포하기 위해 테인트와 톨러레이션과 노드 어피니티를 조합하여 사용하는 방법을 정리한다.문제의 정의다음과 같이 쿠버네티스 클러스터를 다른 팀과 함께 공유해서 사용한다고 가정해보자.최종 목표로, 우리 팀 파드인 파드 A, 파드 B, 파드 C는 색깔에 맞게 적합한 노드에 배치하고, 타 팀의 파드는 우리 팀의 노드에 배치되지 않도록 설정하고자 한다.테인트와 톨러레이션만 사용하는 경우다음과 같이 테인트와 톨러레이션을 사용하면 우리 팀의 파드를 적합한 노드에 배치하는 것이 가능하다. 이는 이상적인 경우다.테인트와 톨러레이션만을 사용하는 예 - 이상적인 경우그런데 문제는 테인트와 톨러레이션만을 이용하면, 다음과 같이 테인트되지 않은 다른 팀의 노드에 우리 팀의 파드가 스케줄링 될 수 있다.테인트와 톨러레이션만을 사용하는 예 - 문제가 발생한 경우노드 어피니티만 사용하는 경우노드 어피니티를 사용하면, 우리 팀의 파드를 우리 팀 소유의 특정 노드에만 배치될 수 있도록 제한할 수 있다. 이 또한 이상적인 경우다.노드 어피니티만을 사용하는 예 - 이상적인 경우그런데 문제는, 노드 어피니티만을 사용한다면, 다음과 같이 타 팀의 파드가 우리 팀 소유의 노드에 배치되는 것을 막을 수 없다.노드 어피니티만을 사용하는 예 - 문제가 발생한 경우테인트와 톨러레이션, 그리고 노드 어피니티를 함께 사용하는 경우따라서 테인트와 톨러레이션, 그리고 node affinity를 동시에 사용해야 목표를 달성할 수 있다.테인트와 톨러레이션, 그리고 노드 어피니티를 함께 사용하는 경우참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스" }, { "title": "(K8S) 노드 셀렉터와 노드 어피니티", "url": "/posts/Node-Selector-and-Node-Affinity/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Scheduling, NodeSelector, NodeAffinity", "date": "2022-08-15 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.이번 글에서는 파드를 노드에 배치하는 방법으로 노드 셀렉터(nodeSelector)와 노드 어피니티(Node Affinity)를 정리한다.nodeName을 이용하는 매뉴얼 스케쥴링 및 테인트와 톨러레이션을 함께 참고하면 좋겠다.파드 배치의 필요성위와 같이 클러스터 내에서 노드들의 리소스는 각각 다를 수 있다. 예를 들어, 어떤 노드는 다른 노드보다 더욱 고성능의 하드웨어 리소스를 보유할 수 있는 것이다. 이러한 상황에서 default 세팅으로 파드를 배치하면 다음과 같은 문제가 발생하게 된다.즉, 파드B와 같이 많은 하드웨어 리소스를 소요하는 파드가 노드02와 같이 저성능 노드에 배치되어 파드를 실행하기 위한 하드웨어 자원이 부족해지는 현상이 발생하는 것이다.이외에도 하드웨어의 리소스를 고려하여 특정 파드를 특정 노드에서 실행되도록 해야 하는 상황은 다양하게 있을 수 있다.예를 들면, 어떤 파드는 반드시 SSD에 연결된 노드에 배포해야 하는 경우가 있다.이러한 경우에 어떻게 특정 파드를 특정 노드에 배포할 수 있는지 살펴보자.노드 셀렉터(nodeSelector)노드 셀렉터(nodeSelector)는 파드가 특정 노드에서 실행되도록 하는 가장 쉬운 방법 중 하나로, nodeSelector는 파드 정의 YAML 파일과 노드에서 사용되는 일종의 label이다.사용법 step 01 : 파드 정의 YAML 파일에 nodeSelector 레이블을 설정함# pod-definition.yamlkind: Podmetadata: name: myapp-podspec: containers: - name: data-processor image: data-processor nodeSelector: # 이 부분을 통해서 특정 노드에서만 파드가 실행되도록 한다. size: Large # 사실, 이 size: Large는 노드에 부여되는 '레이블'이다. # 스케줄러는 size: Large라고 assign된 레이블이 match되는 노드에 이 파드를 배치한다. # 따라서 이 파드를 배치하기 전에 노드에 size: Large라는 레이블이 먼저 부여되어 있어야 한다.사용법 step 02 : 파드가 실행될 노드에 동일하게 레이블을 설정함파드에 설정된 nodeSelector는 단지 레이블일 뿐이기 때문에, 노드에도 레이블을 달아주어야 한다.노드에 있는 레이블과 일치하는 경우에 이 파드를 해당 노드에 배치할 수 있다.kubectl label nodes &lt;노드 이름&gt; &lt;레이블-키 값&gt;=&lt;레이블-밸류 값&gt;의 형태로 노드에 레이블을 달 수 있다.예를 들면, kubectl label nodes node-1 size=Large처럼 말이다.이후 kubectl create -f pod-definition.yaml 명령어를 통해 파드를 생성하면, 자동으로 레이블이 matching되는 노드에서 파드가 실행된다.노드 셀렉터의 문제점노드 셀렉터를 이용하는 것은 위 예제에서 살펴보았듯 size: Large와 같이 단 하나의 레이블만 사용할 수 있다.만약, 더 복잡한 조건으로 노드를 선택해야 한다면 어떨까? 예를 들어, size: 크거나 중간과 같은 복잡한 조건이 들어가는 경우 말이다.이땐 nodeSelector 레이블만으로 노드를 선택할 수는 없다. 즉, 노드 어피니티가 필요하다.노드 어피니티(Node Affinity)노드 어피니티(Node Affinity)는 앞서 살펴보았던 노드 셀렉터와 유사하게, 파드가 특정 노드에서만 실행될 수 있도록 설정하는 방법이다.하지만 노드 어피니티는 nodeSelector 레이블과는 달리, 레이블 선택에 있어서 ‘or’ 조건이라든지 ‘not’ 조건과 같이 복잡한 조건도 처리할 수 있다.사용법# pod-definition.yamlkind: Podmetadata: name: myapp-podspec: containers: - name: data-processor image: data-processor # nodeSelector ... 노드 셀렉터와의 차이점 # - size: Large ... 노드 셀렉터와의 차이점 affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: # 노드 어피니티의 속성 - matchExpressions: - key: size operator: In # NotIn, Exsists 등도 가능 values: - Large # 추가적으로 다양한 밸류값 가능 - Medium - ...노드 어피니티의 특징을 관찰해보자. 파드가 특정 노드에서 실행되도록 한다는 점에서 개념적으로는 노드 셀렉터와 동일한 기능이지만, 노드 셀렉터보다 훨씬 복잡하게 정의되어야 한다.복잡하지만, 노드 어피니티는 operator 부분을 다양하게 설정하여 복잡한 조건들을 반영하면서 노드를 선택할 수 있게 한다.심지어 values 값을 모를 때는 Exists라는 operator를 사용하고 values를 생략할 수도 있다.참고로, values 값에는 더욱 다양하게 값들을 여러 개를 나열할 수 있다.노드 어피니티의 속성 : matchExpression에 대응되는 노드가 없는 경우만약, 노드 어피니티를 위해 파드 정의 YAML 파일에서 설정한 matchExpression에 대응되는 노드가 없다면 어떻게 될까? 또는, 미래에 누군가가 노드의 레이블을 바꾸어버린다면, 위와 같은 설정으로 만들어진 파드는 계속해서 해당 노드에서 실행될까? 이러한 이슈는 requiredDuringSchedulingIgnoredDuringExecution처럼 긴 속성으로 해결할 수 있다.현재 지원되는 노드 어피니티의 속성 값은 아래와 같다. requiredDuringSchedulingIgnoredDuringExecution preferredDuringSchedulingIgnoredDuringExecutionDuringSchedulingDuringScheduling이란, 아직 파드가 존재하지 않는 상태이며, 처음으로 파드가 생성되는 시점을 의미한다.속성이 required로 설정되어 있다면, 파드를 노드에 배치함에 있어 어피니티 규칙(affinity rule)에 의한 matching이 필수인 경우를 의미한다.즉, 스케줄러는 파드가 처음 생성될 때 어피니티 규칙에 따라 노드에 배치되도록 지시하는데, 만약 어피니티 규칙에 따라 matching되는 노드가 없으면, 파드는 스케줄링되지 않는다.이는 파드가 특정 노드에 배치되도록 설정하는 것이 매우 중요한 상황에서 사용된다.속성이 preferred로 설정되어 있다면, 파드를 노드에 배치함에 있어 우선적으로 어피니티 규칙을 고려하되, 어피니티 규칙에 matching되는 노드가 없는 경우에는 아무 노드에 배치될 수 있다. 이는 파드가 특정 노드에 배치되도록 설정하는 것이 선호되기는 하지만 필수는 아닌 상황에서 사용된다.DuringExecutionDuringExecution이란, 파드가 이미 만들어져 있고 특정 노드 상에서 실행 중에 있는데, 노드의 레이블이 변경되는 상황과 같이 노드 어피니티에 영향을 주는 변화가 있는 때를 의미한다.예를 들어, 실행 중인 파드는 어피니티 규칙에 의해 size:Large로 레이블된 노드에서 실행되고 있는데, 노드의 레이블이 바뀌면 파드는 계속 실행될 수 있는 것인지를 이 부분에서 설정한다.속성이 Ignored로 설정되어 있기 때문에 노드 어피니티에 영향을 주는 변화가 있어도 파드는 이를 무시하고 계속해서 실행된다.(참고로, 현재까지 쿠버네티스에서 지원되는 속성들은 모두 Ignored이지만, 추후 Required 등도 지원될 예정이다. requiredDuringSchedulingRequiredDuringExecution)참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스[3] 쿠버네티스 공식 documentation : Assigning Pods to Nodes" }, { "title": "(K8S) 테인트와 톨러레이션", "url": "/posts/K8S_Taints-and-Tolerations/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Scheduling, Taint, Toleration", "date": "2022-08-14 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.이번 글에서는 어떤 파드를 어떤 노드에 배치하는지, 즉 파드와 노드 간의 관계를 다룬다.사람에게 들러붙으려는 벌레로 살펴보는 예테인트(taint)와 톨러레이션(toleration)의 관계는 처음 접할 때 다소 복잡할 수 있다. 따라서 사람에게 접근하는 벌레의 예를 들어서 설명하고자 한다. 벌레가 사람에게 오는 것을 막기 위해서 사람들은 스프레이를 뿌리는데, 이 스프레이를 테인트라고 생각하자. 벌레 A는 스프레이 냄새를 굉장히 싫어하기 때문에, 사람에게 접근하면 스프레이(즉, 테인트) 냄새를 맡고 도망가게 된다. 한편 벌레 B는 스프레이 냄새를 버틸 수(tolerant) 있기 때문에 사람에게 접근할 수 있다.위 예에서 보듯, 벌레가 사람에게 들러붙을 수 있으려면 두 가지가 만족되어야 한다.1) 사람에게 스프레이(즉, 테인트)가 얼마나 뿌려져 있는가?2) 벌레는 얼마나 스프레이(즉, 테인트) 냄새를 버틸 수 있는가? (toleration)쿠버네티스에 적용해보면, 사람 = 노드이며, 벌레 = 파드로 비유할 수 있다. 또한, 클러스터 내에서 테인트 = security와 톨러레이션 = intrusion이라고 비유할 수 있다.💡 테인트와 톨러레이션은 클러스터 내에서 어떤 파드(벌레)가 특정 노드(사람)에 스케줄링 될 수 있도록 제한하는 역할을 한다.노드와 파드에서의 테인트와 톨러레이션테인트와 톨러레이션의 예위 그림과 같이 노드01에 테인트가 적용되어 있다면, 해당 테인트에 톨러레이션이 있는 파드D가 아니고서야 노드 01에 스케줄링 될 수 없다.테인트와 톨러레이션을 적용한 후, 스케줄링된 결과의 예시1특히 주의해야 할 점은, 파드 D가 반드시 톨러레이션이 있다고 해서 반드시 해당 노드에 배치되어야만 하는 것은 아니다. 즉, 아래와 같은 배치가 가능하다는 말이다.테인트와 톨러레이션을 적용한 후, 스케줄링된 결과의 예시2💡 테인트와 톨러레이션은 특정 파드가 반드시 특정 노드에 위치해야만 한다고 지정하는 것은 아니다.명령어로 설정하는 테인트kubectl taint nodes &lt;노드의 이름&gt; &lt;키 값&gt;=&lt;밸류 값&gt;:&lt;테인트 효과&gt; 명령어를 통해 설정할 수 있다.테인트효과는 아래의 값을 가질 수 있다. NoSchedule : 톨러레이션 설정이 없으면 파드를 스케줄링 하지 않는다. 기존에 실행되던 파드에는 적용되지 않는다. PreferNoSchedule : 톨러레이션 설정이 없으면 파드를 스케줄링하지 않는다. 하지만 클러스터 안 자원이 부족하면 테인트를 설정한 노드에서도 파드를 스케줄링 할 수 있다. 즉, 해당 노드에 톨러레이션이 없는 파드가 항상 스케줄링되는 것을 보장하지는 않는다. NoExecute : 톨러레이션 설정이 없으면 파드를 스케줄링하지 않는다. 특히, 기존 파드도 톨러레이션 설정이 없으면 종료시킨다.$ kubectl taint nodes node01 app=grey:NoScedule이때, app=grey이 일치하는 톨러레이션이 없으면 파드를 node01에 스케줄링 할 수 없다.또한 테인트 적용 취소 시는 ‘-’ 명령을 추가한다.$ kubectl taint nodes node01 app=grey:NoScedule-파드 정의 YAML로 설정하는 톨러레이션# pod-definition.yamlapiVersion: v1kind: Podmetadata: name: myapp-podspec: containers: - name: nginx-container image: nginx tolerations: # 톨러레이션이 정의되는 부분 - key: \"app\" # 테인트에서의 key 값 operator: \"Equal\" # 테인트에서의 \"=\"에 대응됨 value: \"grey\" # 테인트에서의 value 값 effect: \"NoSchedule\" # 테인트 효과마스터 노드에 파드가 배치되지 않는 이유마스터 노드에 파드가 배치되지 않는 이유도 사실은 테인트 때문이다. 마스터 노드는 쿠버네티스가 처음 설치될 때 자동적으로 테인트가 적용된다.kubectl describe node kubemaster | grep Taint 명령을 치면, 마스터 노드에 테인트가 적용되어 있는 것을 확인할 수 있다.참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스[3] 김징어의 Devlog : [k8s] 노드 스케쥴링 - Taints와 Toleratioin(테인트와 톨러레이션)" }, { "title": "(K8S) 매뉴얼 스케줄링", "url": "/posts/K8S_Scheduling-manual/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Scheduling", "date": "2022-08-10 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.nodeName으로 직접 노드를 지정하여 스케줄링쿠버네티스에서는 파드 정의 YAML 파일에서 nodeName을 직접 기입하여 파드가 실행될 노드를 지정할 수 있다.이는 추후 정리할 nodeSelector나 nodeAffinity에 비해 직관적이지고 단순한 방식으로, 일반적으로는 잘 사용하지 않는 방법이다.우선, 파드 정의 YAML 파일을 보면서 nodeName을 직접 지정해보자.# pod-definition.yamlapiVersion: v1kind: Podmetadata: name: nginx labels: name: nginxspec: containers: - name: nginx image: nginx ports: - containerPort: 8080 nodeName: node02 # 아래 설명을 참고할 것위와 같이 nodeName field가 “node02”처럼 직접 명시되어 있는 파드는 스케줄러(scheduler)가 해당 파드를 스케줄링 하지 않으며, nodeName에 명시된 노드(e.g., node02)의 kubelet이 해당 파드를 해당 노드에서 실행한다.스케줄러는 nodeName이 설정되지 않은 파드를 발견하면, scheduling 알고리즘을 실행하여 파드를 위한 적합한 노드를 확인하고 스케줄링 한다.스케줄러가 없다면 어떻게 될까?파드의 STATUS가 지속적으로 Pending 상태로 남아있게 된다. 스케줄러가 없다면 우리가 수동으로 직접 파드를 노드에 assign 해야한다. 따라서 위와 같은 방식으로 파드 정의 YAML 파일에서 nodeName 필드를 직접 채워 넣어야만 하고, ‘파드가 생성된 때에만’ 노드에 assign 될 수 있다.파드가 이미 만들어져 있는 경우라면?쿠버네티스가 파드의 nodeName을 바꾸지는 않는다. 이 경우에는 이미 있는 파드를 특정 노드로 assign하기 위해 새로운 방법을 쓰는데, Binding이라는 오브젝트를 만들어서 파드 binding API로 POST request를 보내는 방법이 있다. 스케줄러가 하는 것을 비스무레 따라하는 것이다.매뉴얼 스케줄링의 문제nodeName에 명시된 노드가 없는 경우, 파드는 실행되지 않고 자동으로 지워질 수 있다. 또한 nodeName에 명시된 노드에 파드가 실행될 리소스가 충분하지 않다면, 파드 실행이 실패할 것이다. 마지막으로, 클라우드 환경에서 nodeName 자체가 항상 동일하지 않으므로 안정적이지 않다.참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스[3] 쿠버네티스 공식 documentation : Assigning Pods to Nodes" }, { "title": "(K8S) 네임스페이스", "url": "/posts/K8S_Namespaces/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Namespace", "date": "2022-08-09 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.네임스페이스(Namespacce) : 리소스를 논리적으로 구분하는 장벽쿠버네티스에서는 리소스를 논리적으로 구분하기 위해 네임스페이스(Namespace)라는 오브젝트를 제공한다.간단히 생각해서 네임스페이스는 파드, 레플리카셋, 디플로이먼트, 서비스 등과 같은 쿠버네티스 리소스들이 묶여 있는 하나의 가상 공간 또는 그룹이라고 이해할 수 있다.예를 들어, 모니터링을 위한 모든 리소스들은 monitoring이라는 이름의 네임스페이스에서 생성할 수 있고, 테스트를 위한 리소스들은 tested라는 네임스페이스에서 생성할 수 있다. 또는 여러 개발 조직이 하나의 쿠버네티스 클러스터를 공유해 사용해야 한다면, 조직별로 네임스페이스를 사용하도록 구성할 수도 있다.이처럼 여러 개의 네임스페이스를 사용하면 마치 하나의 클러스터에서 여러 개의 가상 클러스터를 동시에 사용하는 것처럼 할 수 있다.기본적인 네임스페이스네임스페이스는 직접 생성하지 않았더라도 기본적으로 default 네임스페이스, kube-public 네임스페이스, kube-system 네임스페이스가 있다.default 네임스페이스클러스터가 처음 구축되면, 자동으로 default 네임스페이스가 생성된다.kubectl 명령어는 기본적으로 별도로 --namespace 옵션을 명시하지 않으면 default 네임스페이스를 사용한다.kube-system 네임스페이스kube-system는 DNS service와 같은 네트워킹 솔루션 등 일반 사용자들에 의해 함부로 변경되면 안 되는 필수 컴포넌트들과 설정 값들이 위치한 네임스페이스이다.kube-system 네임스페이스는 쿠버네티스에 대한 충분한 이해 없이는 건드리지 않는 것이 좋다.kube-public 네임스페이스모든 사용자로부터 사용 가능한 리소스가 만들어지는 곳이다.네임스페이스가 왜 필요할까?작은 규모의 쿠버네티스 운영 환경에서는 default 네임스페이스만으로도 운영할 수 있을 것이다. 그런데 쿠버네티스 클러스터가 점차 커져서 production 목적으로 이용하게 되면, 네임스페이스 관리가 필요해진다.예를 들어, 개발 목적의 Dev 네임스페이스와 제품레벨에서 배포 목적의 Prod 네임스페이스를 분리해서 사용할 수 있다. 이러한 방법으로 개발단에서 실수로 배포 네임스페이스 상의 리소스를 변경하는 일을 차단할 수 있다.또한 각각의 네임스페이스에서는 각각 적용할 수 있는 규칙을 정할 수 있다. 예컨대, 리소스 사용에 대한 한계, 즉 resource limits도 네임스페이스에 따라 설정할 수 있다.예를 들어 Resource Quata라고 하는 오브젝트를 이용해서 특정 네임스페이스에서 생성되는 파드의 자원 사용량을 제한할 수 있다.네임스페이스 사용 방법파드 생성 시 네임스페이스를 지정하는 방법kubectl create -f pod-definition.yml --namespace=&lt;네임스페이스 이름&gt;으로 지정하거나, 혹은 파드 정의 YAML 파일의 metadata 섹션에서 namespace: &lt;네임스페이스 이름&gt;으로 지정할 수 있다.직접 네임스페이스를 만드는 방법# namespace-dev.yamlapiVersion: v1kind: Namespacemetadata: name: dev네임스페이스 정의 YAML 파일을 생성한 후 kubectl create -f namespace-dev.yaml 명령으로 생성할 수 있다.네임스페이스 설정 방법kubectl config set-context --current --namespace=&lt;네임스페이스 이름&gt; 명령으로 네임스페이스를 설정한다.네임스페이스에서 Resource Quota를 통해 파드 자원 사용량을 제한하는 방법# compute-quota.yamlapiVersion: v1kind: ResourceQuotametadata: name: compute-quota namespace: devspec: hard: pods: \"10\" requests.cpu: \"4\" requests.memory: 5Gi limits.cpu: \"10\" limits.memory: 10Gikubectl create -f compute-quota.yaml 명령으로 적용한다.참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스" }, { "title": "(K8S) 명령형과 선언형", "url": "/posts/K8S_Imperative-vs-Declarative/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Imperative, Declarative", "date": "2022-08-09 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.명령형(Imperative)과 선언형(Declarative)명령형 (specify what to do and how to do)도커는 컨테이너를 다룰 때 docker run 명령과 같이 특정 명령을 처리하는 주체와 통신해서 작업을 수행한 후, 작업에 대한 결과를 반환 받는 방식으로 작동한다.이를 명령형(Imperative)라고 부른다. 물론 쿠버네티스에서도 kubectl run --image=nginx nginx와 같이 명령형 방식으로 작동할 수 있다.선언형 (specify what to do, not how to do)반면, 쿠버네티스는 최종적으로 만들고자 하는 바람직한 상태(Desired State)를 YAML로 정의한 후 kubectl apply -f {YAML파일} 명령으로 실행할 수도 있다.이처럼 최종적으로 달성해야 하는 상태를 정의하여 실행하는 방식을 선언형(Declarative)이라고 부른다.명령형과 선언형의 예명령형의 예Create Objects kubectl run --image=nginx nginx kubectl create deployment --image=nginx nginx kubectl expose deployment nginx --port 80YAML 없이도 가능하지만, 복잡한 기능을 추가할 수 없으며, 복잡한 환경에서 활용하기 어렵다.Update Obejcts kubectl edit deployment nginx kubectl scale deployment nginx --replicas=5 kubectl set image deployment nginx nginx=nginx:1.18 kubectl create -f nginx.yaml kubectl replace -f nginx.yaml kubectl delete -f nginx.yaml명령형 방식을 사용한다면, 관리자가 반드시 현재의 모든 configuration을 알고 있어야 하며, 컴포넌트들에 변경을 주고 싶다면, 그전에 에러가 나지 않도록 모든 조치를 취해야 한다. 예를 들어, 기존에 있던 파드를 또 생성한다고 하면 AlreadyExists 에러가 난다.선언형의 예YAML을 미리 생성한 후, kubectl apply -f nginx.yaml를 실행한다. configuration에 변경이 있어도 에러가 나지 않는다.참고 : CKA 시험에서의 팁명령형 방식이 시간 단축에는 효과적일 것이다. 반면, 복잡한 문제는 multiple containers, 환경변수, init container 등등 configuration을 많이 건드려야 할텐데, 그땐 선언형 방식이 나을 것이다.참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스" }, { "title": "(K8S) 서비스(Service) 타입 - NodePort & LoadBalancer", "url": "/posts/K8S_Service-NodePort,-LoadBalancer/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Service", "date": "2022-08-08 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.앞서 쿠버네티스 환경에서 서비스(Service)의 개요와 종류를 간단히 살펴보았다.이번에는 서비스의 종류 중 NodePort 및 LoadBalancer 타입의 서비스를 살펴보고자 한다.ClusterIP에 대한 포스트는 여기를 참고하자.NodePort 서비스란?NodePort 서비스 타입은 ‘노드 포트’라는 명칭대로, 노드의 특정 포트(그림에서 30008)를 개방해 서비스에 접근하는 방식이다.NodePort 서비스 타입은 서비스를 중심으로 총 3개의 포트를 사용한다. Port : 서비스의 포트(즉, cluster IP의 포트) Node Port : 노드의 포트 별도로 지정하지 않으면 30000 ~ 32767번 사이의 포트가 자동으로 지정된다. Target Port : 최종 목적지인 파드의 포트 별도로 지정하지 않으면 Port와 같은 값으로 지정된다. NodePort 정의하기# service-definition.yamlapiVersion: v1kind: Servicemetadata: name: myapp-servicespec: # 가장 중요한 부분 type: NodePort # 어떤 타입인지, NodePort, ClusterIP, LoadBalancer ports: # 서비스의 포트 관점에서 - targetPort: 80 port: 80 nodePort: 30008위의 예제에서는 targetPort를 정의하긴 했으나, 어떤 파드의 포트가 targetPort인지는 지정하지 않았다.웹 서비스를 하면 80포트를 사용하는 파드가 수백개가 될 수도 있는데, 어떤 것을 의미하는 것일까?특정 파드의 포트라는 것을 지정하기 위해서, ReplicaSet에서 했던 방식처럼 selector를 사용한다!service-definition.yamlapiVersion: v1kind: Servicemetadata: name: myapp-servicespec: # 가장 중요한 부분 type: NodePort # 어떤 타입인지, NodePort, ClusterIP, LoadBalancer ports: # 서비스의 포트 관점에서 - targetPort: 80 port: 80 nodePort: 30008 selector: # 파드 생성 시, metadata의 labels로 정의했던 내용들을 아래에 써준다. app: myapp type: front-end이 경우, 파드 생성 시 metadata 내 labels에 기입했던 정보를 selector에 써준다. 그러면 수많은 파드 중 해당 파드가 targetPort로 지정되는 것이다.이후 , kubectl create -f service-definition.yaml 명령으로 서비스를 생성하며, kubectl get services로 서비스를 확인할 수 있다.위와 같이 포트를 노출해준 후 서비스를 생성해주면, 클러스터 외부에서 노드의 특정 포트(e.g., 30008)를 경유하여 내부 파드로 접근할 수 있게 된다. 예를 들어, curl http://192.168.1.2:30008와 같이 확인해볼 수 있다.selector를 사용해도 동일한 내용의 파드가 여러 개 존재한다면?위와 같이 selector 섹션에서 파드의 labels를 지정하여 특정 파드의 포트와 매핑하였지만, 이러한 파드 자체가 여러 개 존재한다면, 어떤 파드에 load를 부여할지 어떻게 선택할까? (Case1) 하나의 노드에 있는 labels가 동일한 파드들이라면, random 알고리즘으로 그냥 무작위로 파드를 선택해서 연결한다. (Case2) 여러 개의 노드에 있는 labels가 동일한 파드들이라면, 쿠버네티스는 여러 노드에 걸쳐있는 서비스를 하나 생성한다. 그리고 그 서비스는 클러스터 내 각 노드에 있는 모든 targetPort(e.g., 80)들과 각 노드의 동일한 포트, 즉 nodePort(e.g., 30008)를 연결한다. 아래의 경우가 모두 작동하게 될 것이다. curl http://192.168.1.2:30008 curl http://192.168.1.3:30008 curl http://192.168.1.4:30008 LoadBalancer 서비스란?LoadBalancer 타입의 서비스는 서비스 생성과 동시에 로드밸런서를 새롭게 생성해 파드와 연결한다.NodePort를 사용할 때는 각 노드의 IP를 알아야만 파드에 접근할 수 있었으나, LoadBalancer 타입의 서비스는 클라우드 플랫폼(GCP, AWS, Azure)으로부터 도메인 이름과 IP를 할당받기 때문에 NodePort보다 더욱 쉽게 파드에 접근할 수 있다.단, LoadBalancer 타입의 서비스는 로드 밸런서를 동적으로 생성하는 기능을 제공하는 환경만 사용할 수 있다. 일반적으로 AWS, GCP, Azure 등과 같은 클라우드 플랫폼 환경에서만 사용할 수 있으며, 가상 머신이나 온프레미스 환경에서는 사용하기 어려울 수 있다.참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스" }, { "title": "(K8S) 서비스(Service) 타입 - ClusterIP", "url": "/posts/K8S_Service-ClusterIP/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Service", "date": "2022-08-08 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.앞서 쿠버네티스 환경에서 서비스(Service)의 개요와 종류를 간단히 살펴보았다.이번에는 서비스의 종류 중 ClusterIP 서비스를 살펴보고자 한다.ClusterIP 서비스란?ClusterIP 타입은 쿠버네티스가 지원하는 기본 형태의 서비스로, 파드들이 클러스터 내부의 다른 리소스들과 통신할 수 있게 하는 가상의 클러스터 전용 IP다.ClusterIP는 클러스터 내에서만 사용되는 IP이므로 외부에서는 접근할 수 없다는 점을 유의해야 한다. 클러스터 내부에서만 사용하는 파드라면 상관 없겠으나, 외부에 노출되어야 한다면 NodePort나 LoadBalancer 타입의 서비스를 사용해야 한다.ClusterIP 서비스 사용의 예풀스택 웹 애플리케이션을 예로 들어보면, 애플리케이션의 각 부분, 즉 프론트엔드 서버, 백엔드 서버, 그리고 인메모리 key-value 스토어인 Redis나 RDB MySQL 같은 데이터베이스 등이 서로 다른 파드들로 구성되어 있다.이러한 구조에서 애플리케이션들은 ClusterIP를 통해 통신할 수 있다.위와 같은 구조를 예로 들면, ClusterIP는 각 tier에 있는 파드들을 하나로 그룹핑하고, 다른 tier의 파드 그룹과 소통할 수 있도록 하나의 통합된 interface(예를 들어, 그림에서 back-end 파드들에 접근하기 위한 서비스)를 제공한다.이때 각 서비스는 고유한 IP 주소인 ClusterIP를 가진다.이러한 방식은 쿠버네티스 클러스터 상에서 마이크로서비스 기반 애플리케이션을 효과적으로 배포할 수 있게 한다.그덕에 각 레이어에 있는 파드들은 다양한 서비스를 통해 통신되므로, 커뮤니케이션에 지장을 주지 않으면서 스케일링 될 수 있는 것이다.ClusterIP 정의하기# service-definition.ymlapiVersion: v1kind: Servicemetadata: name: back-endspec: type: ClusterIP ports: - targetPort: 80 port: 80 # nodePort 항목이 없음을 주의! 클러스터 내부에서만 사용되며 외부로 노출되기 않기 때문임 selector: # pod 생성 시 labels에 정의되어 있던 내용 app: myapp type: back-endkubectl create -f service-definition.yaml 명령으로 생성하며, kubectl get services 명령으로 확인한다.참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스" }, { "title": "(K8S) 서비스(Service)의 개요", "url": "/posts/K8S_Service/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Service", "date": "2022-08-07 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.서비스(Service)의 필요성디플로이먼트(Deployment)를 통해 생성된 파드에 어떻게 접근할 수 있을까?로컬 개발 환경이나 쿠버네티스 클러스터 내부에서는 kubectl describe pods 명령을 통해 파드의 내부IP를 확인한 뒤 접근할 수는 있다.그러나 파드는 생성될 때마다 새로운 내부 IP가 할당되므로 IP가 가변적이기 때문에, 파드의 내부 IP만으로는 클러스터 내/외부와 통신을 지속하기 어렵다.따라서 특별한 접근 방식이 필요하다.도커에서는 docker run -p 옵션을 통해서 컨테이너를 외부로 노출하여 외부에서 사용자들이 컨테이너 내부로 접근할 수 있었다.한편, 쿠버네티스에서는 컨테이너의 포트를 외부로 노출하여 사용자들이 파드로 접근할 수 있도록 하기 위해서는, 그리고 다른 파드들이 파드 내부로 접근할 수 있도록 하기 위해서는 별도의 고정된 IP를 가진 서비스(Service)라는 오브젝트를 이용해야 한다.서비스(Service)의 정의쿠버네티스 환경에서 서비스(Service)는 클러스터 내/외부에서 내부에 있는 여러 파드들에 접근할 수 있도록 단일 네트워크 진입점을 부여하여, 파드들을 통해 실행되고 있는 애플리케이션을 네트워크에 노출시키는 가상의 컴포넌트다.internal networking에서의 서비스 사용 예예를 들어, 우리가 사용하는 애플리케이션이 프론트엔드 / 백엔드 / 외부 데이터 스소 각 그룹별로 파드가 실행되고 있다고 해보자.이 그룹들 간 파드를 연결해주는 것이 바로 서비스다.external networking에서의 서비스 사용 예웹 애플리케이션 파드를 배포했다고 하면, 어떻게 외부 유저가 웹 페이지에 접근할 수 있을까? 다음과 같은 상황을 가정해보자. 컴퓨터들의 IP 내 랩탑 IP : 192.168.1.10 쿠버네티스 노드의 IP : 192.168.1.2 쿠버네티스 노드 내에서 파드 네트워크의 내부 대역 : 10.244.0.0 접근하고자 하는 파드의 IP : 10.244.0.2 (즉, 웹 페이지가 동작하고 있는 파드의 IP) 위와 같은 상황이라면, 랩탑 네트워크와 파드 네트워크는 분리되어 있으므로, 랩탑 IP에서 파드 IP에 접근(ping)을 할 수 없다.직관적인 방법으로는, 쿠버네티스 노드(192.168.1.2)로 ssh를 통해 접속한 후, 그 노드에서 접근하고자 하는 웹 페이지가 동작하는 파드에 curl http://10.244.0.2를 통해 접근할 수 있다.그런데 이러한 방식은 ssh를 통해 강제로 접근하는 방식으로 매우 비효율적이다.따라서 ssh로 강제 접근하지 않고, 나의 랩탑과 쿠버네티스 노드 내에 있는 파드 간에 연결을 위해서는 아래와 같이 서비스가 필요하다.NodePort 타입의 Service 구조위 그림은 NodePort 타입의 서비스를 보여준다. 이는 쿠버네티스 노드 내에 있는 특정 포트를 listen하고 있다가, 요청이 오면 해당 요청을 웹 애플리케이션을 운영하고 있는 파드의 포트로 전송해주는 역할을 한다.서비스의 종류서비스는 ClusterIP, NodePort, LoadBalancer, ExternalName 타입이 존재하며, 이들 중 ExternalName 타입은 제외하여 정리하고자 한다.다음 포스트에서 계속참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스" }, { "title": "(K8S) 디플로이먼트", "url": "/posts/K8S_Deployment/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Deployment", "date": "2022-08-07 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.앞서 레플리케이션 컨트롤러와 레플리카셋에 대해서 살펴보았다.그리고 최근에는 이들 중 레플리카셋을 사용한다는 것도 살펴보았다. 그러나 실제 쿠버네티스 운영 환경에서는 YAML 파일을 이용해서 레플리카셋을 사용하는 경우는 매우 드물다.대부분 레플리카셋과 파드의 정보를 정의하는 디플로이먼트(deployment)를 YAML 파일로 정의하여 사용한다.Deployment디플로이먼트(deployment)는 레플리카셋의 상위 개념인 오브젝트이다. 따라서 디플로이먼트를 생성하면 해당 디플로이먼트에 정의된 레플리카셋도 함께 생성된다. 즉, 별도로 레플리카셋을 생성할 필요가 없어진다.Deployment의 YAML디플로이먼트의 YAML 파일은 레플리카셋의 YAML 파일과 매우 비슷하다. 단지 kind 및 metadata 섹션만 Deployment로 바꾸면 된다.# deployment-definition.yamlapiVersion: apps/v1 # Replication Controller와 다른 점을 주의하자! apps/를 붙여야한다!kind: Deployment # Replication Set과 다른 부분! 이것만 바꾸면 된다.metadata: name: myapp-deployment labels: app: myapp type: front-endspec: # replica set를 위해서 필요한 spec template: # 이곳에는 replica set에 의해서 사용될 파드의 템플릿을 기입한다. # 파드 생성에 필요했던 YAML파일에서 apiVersion과 kind 빼고 복사 붙여넣기 해온다. metadata: name: myapp-pod labels: app: myapp type: front-end spec: # pod에 대한 spec containers: - name: nginx-container image: nginx replicas: 3 # how many replicas # Replication Controller와 다른 점 selector: # The selector section helps the replica set identify what pods fall under it. matchLabels: type: front-end디플로이먼트 정의 YAML 파일 작성이 완료되면, kubectl create -f deployment-definition.yaml 명령을 통해서 생성한다.kubectl get deployments 및 kubectl get replicaset으로 디플로이먼트 및 레플리카셋 정보를 확인할 수 있다.특히 레플리카셋 정보를 확인해보면, myapp-deployment-6795844b58과 같이 deployment이름으로 replicaset이 구동됨을 알 수 있다.kubectl get all 명령을 통해 디플로이먼트, 레플리카셋, 파드 정보를 한번에 확인할 수 있다.Deployment를 사용하는 이유쿠버네티스는 왜 레플리카셋을 굳이 상위 개념인 디플로이먼트를 통해서 사용하는 것일까?디플로이먼트를 사용하는 주된 이유는 애플리케이션의 업데이트와 배포를 효과적으로 진행하기 위해서다.디플로이먼트는 무중단 서비스를 위해 파드의 롤링 업데이트(rolling update)를 지원한다.또한 업데이트될 때 레플리카셋의 변경 사항을 저장하는 리비전(revision)을 남기며, 업데이트 중 예상치 못한 장애가 발생했을 때는 리비전을 통해 롤백이 가능하도록 지원한다.이러한 장점으로 인해 쿠버네티스에서도 공식적으로 디플로이먼트를 사용할 것을 권장한다.참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스" }, { "title": "(K8S) 레플리케이션 컨트롤러와 레플리카셋", "url": "/posts/K8S_ReplicaSet/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Replicaset", "date": "2022-08-04 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.Replication Controllerreplication controller는 쿠버네티스의 가장 기본적인 컨트롤러로, 파드가 항상 지정된 갯수만큼 클러스터 내에서 실행될 수 있도록 보장하는 역할을 한다.예를 들어, 클러스터 내 파드가 2개 실행되어야 한다고 정의했는데, 그 중 하나가 장애로 인해 다운되어 1개만 실행된다고 가정해보자.replication controller는 2개의 파드가 실행되어야 한다는 정의에 따라 재빨리 1개의 파드를 재실행하여 복구함으로써 2개의 파드가 실행되도록 보장해준다.즉, replication controller는 쿠버네티스 클러스터 상에서 multiple instance를 재생할 수 있게 해줌으로써 고가용성(High Availability)이 가능하도록 지원하는 것이다.Replication Controller의 YAML# rc-definition.yamlapiVersion: v1kind: ReplicationControllermetadata: name: myapp-rc labels: app: myapp type: front-endspec: # replication controller를 위해서 필요한 spec template: # 이곳에는 replication controller에 의해서 사용될 파드의 템플릿을 기입한다. # 파드 정의 YAML파일에서 apiVersion과 kind 빼고 복사 붙여넣기 해온다. metadata: name: myapp-pod labels: app: myapp type: front-end spec: # pod에 대한 spec containers: - name: nginx-container image: nginx replicas: 3 # how many replicasreplication controller 정의 YAML 파일을 위와 같이 작성한 후, kubectl create -f rc-definition.yaml 명령을 통해 생성할 수 있다.또한 kubectl get replicationcontroller 명령을 통해 DESIRED 파드의 갯수, CURRENT 파드의 갯수, READY 상태 파드의 갯수 등을 확인할 수 있다.Replica Set사실상 replication controller 보다는 더욱 최신 기능인 replica set을 더욱 많이 사용한다.replica set은 replication controller와 거의 동일한 역할을 하되, 집합 기반(set-based)의 다양한 셀렉터 기능을 지원한다.예를 들어, replica set의 셀렉터는 in, notin, exists와 같은 연산자를 지원한다.Replica Set의 YAML# replicaset-definition.yamlapiVersion: apps/v1 # Replication Controller와 다른 점을 주의하자! apps/를 붙여야한다!kind: ReplicaSetmetadata: name: myapp-replicaset labels: app: myapp type: front-endspec: # replica set을 위해서 필요한 spec template: # 이곳에는 replica set에 의해서 사용될 파드의 템플릿을 기입한다. # 파드 생성에 필요했던 YAML파일에서 apiVersion과 kind 빼고 복사 붙여넣기 해온다. metadata: name: myapp-pod labels: app: myapp type: front-end spec: # pod에 대한 spec containers: - name: nginx-container image: nginx replicas: 3 # how many replicas # Replication Controller와 다른 점 selector: # The selector section helps the replica set identify what pods fall under it. matchLabels: type: front-endreplica controller와 달리, replica set은 selector를 사용하는 것을 기억하자. 참고로, 아래와 같이 matchExpressions를 통해서 복잡한 selector 기능을 사용할수도 있다....spec: replicas: 3 selector: matchExpressions: - {key: app, operator: In, values: [soaktestrs, soaktestrs, soaktest]} - {key: teir, operator: NotIn, values: [production]} template: metadata:...replica set 정의 YAML 파일을 위와 같이 작성한 후, kubectl create -f replicaset-definition.yaml 명령어로 생성할 수 있으며, kubectl get replicaset로 확인할 수 있다.Replicas의 숫자 변경하기배포된 replica set의 replicas 숫자를 변경하는 방법은 아래와 같다. 방법 1 : YAML 파일에서 replicas 숫자를 바꾼 후 kubectl replace -f replicaset-definition.yaml 명령을 입력함 방법 2 YAML을 이용하는 경우 : kubectl scale --replicas=&lt;바꾸고 싶은 숫자, 예를 들어 6&gt; -f replicaset-definition.yaml 명령어를 이용하는 경우 : kubectl scale --replicas=&lt;바꾸고 싶은 숫자, 예를 들어 6&gt; replicaset &lt;metadata에 적은 type 이름, 예를 들어 myapp-replicaset&gt; 이 경우 YAML 파일에 있는 내용이 바뀌는 것은 아니라는 점을 주의할 것 참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스" }, { "title": "(K8S) 파드", "url": "/posts/K8S_Pod/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Pod", "date": "2022-08-04 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.파드란?파드(pod)는 컨테이너를 다루는 기본 단위이다. 파드는 1개 이상의 컨테이너로 구성된 컨테이너의 집합을 의미한다. 즉, 여러 개의 컨테이너로 하나의 파드를 구성할 수도 있다.파드 하나는 완전한 애플리케이션이다. 예를 들어, Nginx 컨테이너 1개만으로 파드를 구성할 수 있다. 왜냐하면 Nginx 컨테이너 그 자체만으로도 완전한 애플리케이션이기 때문이다. 즉, 2개의 Nginx 컨테이너가 하나의 파드로 정의되는 것은 바람직하지 않다.한편, Nginx의 설정 파일의 변경 사항을 갱신해주는 reloader 프로세스나 로그 수집 프로세스 등 Nginx와 함께 실행되어야 하는 기능 확장 컨테이너의 경우 Nginx와 함께 하나의 파드로 구성할 수 있다. 이렇게 추가 기능을 위해 부가적으로 정의된 컨테이너를 사이드카(sidecar) 컨테이너라고 한다.YAML을 이용한 파드 생성 (기초)쿠버네티스는 YAML 파일을 이용해서 파드, 레플리카, 디플로이먼트, 서비스 등을 생성한다. 모두 비슷하게 생긴 구조를 갖추고 있다. YAML의 root level property apiVersion: v1 # 오브젝트를 만들기 위해 우리가 쓰는 쿠버네티스 API버전 kind: Pod # 오브젝트의 타입을 명시한다 metadata: # 오브젝트에 대한 데이터, 즉, name, labels, etc ... name: myapp-pod # dictionary 형태이므로 indent 주의 labels: app: myapp # 이 위까지는 어떤 컨테이너나 어떤 이미지로 파드를 구성할지 지정하지 않았다. # 아래부터 세부 사항(specification, i.e., spec)을 지정한다. spec: containers: # List 형태다. 즉, 하나의 파드에 여러 컨테이너가 들어갈 수 있다. - name: nginx-container # '-'를 붙인 것은 이것이 리스트의 첫 아이템임을 의미하는 것! image: nginx apiVersion kind version POD v1 Service v1 ReplicaSet apps/v1 Deployment apps/v1 labels 추후 labels에 정의한 레이블을 통해서 오브젝트를 구분할 수 있다. 예를 들어서, 수백개의 프론트엔드 파드와 수백개의 백엔드 파드가 배포되었다고 해보자. 한번 배포되고 나면 종류에 따라 파드들을 그룹핑하기 쉽지 않다. 이러한 파드들에 대해서 프론트엔드 레이블, 백엔드 레이블 이런 식으로 레이블해두면 추후 구분하기 용이하다. YAML 파일이 준비되었으면 kubectl create -f pod-definition.yaml 명령어로 파드를 생성할 수 있다.kubectl get pods로 실행중인 파드를 볼 수 있고, kubectl describe pods &lt;파드의 이름&gt;으로 구체적인 정보를 볼 수 있다.참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스" }, { "title": "(K8S) 노드 컴포넌트", "url": "/posts/K8S_Node-Components/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Architecture", "date": "2022-08-03 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.Kubelet이란?쿠버네티스의 각 노드를 배로 비유한다면, kubelet은 배의 선장이라고 비유할 수 있다. kubelet은 클러스터의 각 노드에서 실행되는 에이전트로서 노드에서 컨테이너가 동작하도록 관리하는 핵심 요소라고 할 수 있다.각 노드에서 컨트롤 플레인에 있는 kube-apiserver와 통신하며, 요청이 있을 때 노드에서 파드를 생성 혹은 변경하는 역할을 담당한다.예를 들어, 파드 정의 YAML 파일은 kubectl 명령어를 통해서 적용되는데, 이 YAML의 내용이 kube-apiserver를 통해 kubelet에 전달되며, kubelet이 YAML의 내용대로 파드를 관리한다.참고로, kubelet은 쿠버네티스를 통해서 생성된 컨테이너가 아니라면 관리하지 않는다.Kube-proxy란?쿠버네티스 클러스터 내부에는 별도의 가상 네트워크들이 존재한다. kube-proxy는 이러한 가상 네트워크가 동작할 수 있도록 하는 네트워크 프록시로, 쿠버네티스의 service 개념의 구현부이다.쿠버네티스에서 네트워크는 매우 복잡하지만, 간단하게 살펴보자. 쿠버네티스 내부에 위치한 특정 파드로 요청을 보내기 위해서는 해당 파드의 IP를 정확히 알아야 하지만, 쿠버네티스에서 파드의 IP는 배포될 때마다 매번 변경된다.파드의 IP가 매번 바뀌더라도 정확하게 특정 파드로 요청이 전달되도록 관리하는 컴포넌트가 바로 kube-proxy다.Container Runtime이란?container runtime은 실제로 컨테이너를 실행시키는 역할을 수행하는 애플리케이션을 의미한다. 가장 유명한 container runtime은 도커(docker)가 있으며, 이외에도 컨테이너디(containerd), 크라이오(CRI-O) 등이 존재한다.쿠버네티스는 컨테이너를 관리하기 위해서 특정 애플리케이션을 사용할 것을 강제하지는 않으며, 단지 쿠버네티스가 컨테이너를 제어하기 위해 제공하는 표준 규약인 Container Runtime Interface(CRI)를 준수할 것을 요구한다.참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스[3] Samsung SDS 블로그 : 쿠버네티스 알아보기 3편: 쿠버네티스를 이루고 있는 여러 가지 구성 요소[4] 쿠버네티스 공식 documentation : 쿠버네티스 컴포넌트" }, { "title": "(K8S) 컨트롤 플레인 컴포넌트", "url": "/posts/K8S_Control-Plane-Components/", "categories": "Kubernetes", "tags": "Kubernetes, K8S, Architecture", "date": "2022-08-02 00:00:00 +0900", "snippet": "이 글은 Mumshad Mannambeth가 강의한 Udemy의 Certified Kubernetes Administrator (CKA) with Practice Tests 강의 커리큘럼을 토대로 공부한 내용을 정리하였음을 밝힙니다.Kube-API Server란?kube-apiserver는 쿠버네티스 API를 노출하는 컴포넌트로, 쿠버네티스에서 가장 중요한 역할을 담당한다.kube-apiserver는 클러스터로 요청이 왔을 때 해당 요청이 유효한지 검증하고, RESTful API를 이용하여 적절한 컴포넌트에서 요청을 처리할 수 있도록 전달하는 등 모든 과정의 중심 역할을 한다.kube-api server는 kubectl 명령어가 들어왔을 때 다음을 관장한다. Authenticate User 유저에 대한 인증 Validate Request 요청에 대한 유효성 검증 Retrieve Data ETCD로부터 요청에 대한 데이터를 가져옴 Update ETCD 데이터 변경 건에 대해서 ETCD를 업데이트 시켜줌 Scheduler와의 통신 scheduler가 어떤 worker node에서 요청을 처리할지(예를 들어, 어디에 파드를 생성할지 등)를 결정하면 kube-apiserver에게 그 정보를 전송함 Kubelet과의 통신 kube-api server는 적합한 worker node에 있는 kubelet에게 요청 처리에 대한 정보를 전송하면, kubelet이 요청을 해당 노드에서 처리함 ETCD란?ETCD(엣시디)는 분산형 key-value 저장소로, 쿠버네티스의 기본 데이터 저장소다.모든 쿠버네티스 클러스터 상태를 저장하는 일종의 데이터베이스인 것이다.예를 들어, ETCD 데이터 저장소는 노드, 파드, configs, secrets, accounts, roles, bindings 등 클러스터에 관한 전반적인 정보를 저장한다.따라서 쿠버네티스에서 어떤 노드를 추가한다거나, 파드 또는 레플리카셋을 배포하는 등 클러스터에서 발생하는 모든 변화들에 따라 ETCD의 상태가 변화된다.ETCD에 저장된 데이터는 반드시 kube-apiserver를 통해서만 접근할 수 있다.예를 들어, kubectl get pods와 같은 명령어를 실행하면, kube-apiserver에 요청이 전달되고, kube-apiserver가 ETCD 데이터를 읽어와 kubectl 사용자에게 결과를 반환하게 된다.ETCD 설치 : 클러스터를 처음부터 구축하는 경우ETCD binaries를 master node에 직접 다운로드 받고, binaries를 설치하고 설정을 하는 등 밑바닥부터 ETCD를 구축해야 한다.etcd.service를 살펴보면 --advertise-client-urls https://${INTERNAL_IP}:2379$\\\\ 라인이 있는데, 2379는 ETCD의 default port이다. 여기서의 URL은 kube-apiserver에 설정되어야 하는데, 그래야만 클러스터의 오케스트레이션을 최종적으로 담당하는 kube-apiserver가 ETCD 서버에 접근할 수 있다.ETCD 설치 : 클러스터를 kubeadm tool을 통해서 구축하는 경우kubeadm으로 클러스터를 구축하는 경우, kubeadm이 알아서 ETCD 서버를 파드(pod)의 형태로 kube-system 네임스페이스에 배포해준다. 이 파드 안에 있는 etcdctl utility를 이용하면 ETCD 데이터베이스를 직접 둘러볼수도 있다.kubectl get pods -n kube-systemNAMESPACE NAME READY STATUS RESTART AGE... 생략 ...kube-system etcd-master 1/1 Running 0 1h... 생략 ...고가용 환경에서는 master node 자체가 여러 개일 것이다. 이때는 ETCD 인스턴스가 여러 master node에 골고루 존재할 것이다. 이 경우, ETCD service configuration을 통해서 적합한 파라미터를 세팅함으로써 ETCD 인스턴스가 서로를 알 수 있도록 해야한다.예를 들어, --initial-cluster controller-0=https://${CONTROLLER0_IP}:2380,controller-1=https://${CONTROLLER1_IP}:2380와 같이 설정해야 한다.Kube-Controller-Manager란?kube-controller-manager는 쿠버네티스에 있는 다양한 컨트롤러(controller)들을 관리하는 컴포넌트다.컨트롤러는 클러스터의 상태를 지속적으로 관찰하며 현재의 상태를 원하는(desired) 상태로 변경시키는 역할을 한다.대표적으로 노드 컨트롤러, 레플리케이션 컨트롤러가 있다.예를 들어, 노드 컨트롤러의 경우, kube-apiserver를 통해서 매 5초마다 노드를 모니터링하며, 애플리케이션이 계속 실행될 수 있도록 조치를 취한다. 즉, 노드로부터 마치 심장박동(heartbeat)같은 상태 정보를 받는데, 상태 정보가 끊기면 UNREACHABLE 표기를 한다. UNREACHABLE 상태가 수 초간 유지되면 해당 노드의 파드를 제거하고 건강한 노드에 provision 한다.레플리케이션 컨트롤러의 경우, replicaset을 모니터링하여 원하는 수량 만큼의 파드가 잘 실행되고 있는지를 보장한다. 만약 파드가 죽으면 복구해낸다.이외에도 컨트롤러는 엔드포인트 컨트롤러, 서비스 어카운트 &amp; 토큰 컨트롤러 등 다양하게 존재한다.kube-controller-manager는 위와 같은 컨트롤러들을 실행하고 관리한다.Kube Scheduler란?쿠버네티스 클러스터는 여러 노드로 구성되어 있다. kube-scheduler는 새로운 파드들이 만들어질 때, 현재 클러스터 내에서 자원 할당이 가능한 최적의 노드에 파드가 배포되도록 스케줄링하는 역할을 수행한다.kube-scheduler는 스케줄링을 위해 특정한 CPU나 메모리 리소스에 대한 요구사항이라든지 각종 제약사항을 종합적으로 판단한다.참고 문헌[1] Mumshad Mannambeth의 강의 : Certified Kubernetes Administrator (CKA) with Practice Tests[2] 시작하세요! 도커/쿠버네티스 (용찬호 지음) : 시작하세요! 도커/쿠버네티스[3] 아리수 님의 블로그 : 쿠버네티스(kubernetes) 구성요소[4] Samsung SDS 블로그 : 쿠버네티스 알아보기 3편: 쿠버네티스를 이루고 있는 여러 가지 구성 요소[5] 쿠버네티스 공식 documentation : 쿠버네티스 컴포넌트" }, { "title": "(Speech Recognition) Wav2Vec2.0 리뷰 및 설명", "url": "/posts/Wav2Vec2/", "categories": "Speech Recognition", "tags": "Speech AI, Wav2Vec, Feature Extraction, Paper Review", "date": "2022-07-31 00:00:00 +0900", "snippet": "이 포스트는 개인적으로 공부한 내용을 정리하고 필요한 분들에게 지식을 공유하기 위해 작성되었습니다. 지적하실 내용이 있다면, 언제든 댓글 또는 메일로 알려주시기를 바랍니다.00. 들어가며2020년, Facebook에서 Wav2Vec 2.0을 발표했다. 앞서 살펴보았던 Wav2Vec 및 VQ-Wav2Vec과 마찬가지로, Wav2Vec 2.0 역시 음성 신호가 전사되어있는 labeled data가 부족하다는 이슈에 대해 self-supervised learning 기법으로 pre-training 하는 방법론을 제시한다. pre-training이 완료된 Wav2Vec 2.0은 이후 Connectionist Temporal Classification(CTC) loss를 활용해서 적은 양의 labeld data로 fine-tuning 하여 활용할 수 있다.놀라운 것은 Wav2Vec 2.0으로 pre-training된 모델이 단지 10분 분량의 labeled data만으로 fine-tuning 되었을 때 Librispeech 데이터셋 기준으로 Word Error Rate(WER)이 깨끗한 음성에 대해서는 4.8을, 이외의 음성에 대해서는 8.2를 기록했다는 점이다. 즉, 매우 적은 양의 데이터만 있으면 어느 정도 동작하는 음성 인식기를 쉽게 만들 수 있게 되었다는 점에서 큰 의의가 있는 것이다.[그림01] 학습 시간에 따른 Wav2Vec2.0의 성능한편, TIMIT phoneme recognition 문제 등에서 SOTA를 달성했으며, labeled data를 더욱 줄여서 오로지 1시간의 labeled data만으로 fine-tuning 했음에도 100배 많은 labeled data로 학습한 기존의 SOTA self-training 방식 모델보다 더욱 나은 성능을 보였다. 게다가 960 시간의 모든 Libreespeech의 labeled data를 활용했을 때는 깨끗한 음성의 경우 WER이 1.8, 그 이외에 대해서는 3.3을 달성하였다.세상에는 다양한 방언 뿐만 아니라 7,000 여 개나 되는 언어가 존재한다. Wav2Vec 2.0은 이렇게 다양한 언어에 대해서도 매우 적은 양의 데이터만 있으면 높은 정확도를 보이는 음성 인식 모델을 구축할 수 있는 세상을 열었다. 그렇다면, 과연 어떻게 작동하는지 Wav2Vec 2.0을 살펴보겠다.01. 모델[그림02] pre-training 과정에서의 Wav2Vec 2.0 모델 아키텍처[그림02]은 pre-training 과정에서의 Wav2Vec 2.0 모델 아키텍처를 보여준다.Feature Encoder기존 Wav2Vec 모델들과 마찬가지로 feature encoder 네트워크 $f:\\mathcal{X} \\mapsto \\mathcal{Z}$가 존재한다. multi-layer CNN으로 구성된 이 네트워크는 원시 음성 신호 sequence 입력값인 $\\mathcal{X}$를 입력 받아서 매 $T$ 시점마다 latent speech representation인 $\\mathbf{z}_1, … , \\mathbf{z}_T$를 출력한다.이후 latent speech representation $\\mathbf{z}_1$, … , $\\mathbf{z}_T$는 두 모듈에 각각 나뉘어서 입력값으로 흘러간다.Contexualized Representations with Transformerslatent speech representation이 입력되는 한 모듈은 contextulized representation을 위한 transformer 모듈 $g:\\mathcal{Z} \\mapsto \\mathcal{C}$이다. 즉, $\\mathbf{z}_1, … , \\mathbf{z}_T$ sequence가 입력되면, transformer 블록(transformer encoder 블록)에 의해 sequence 내 모든 맥락 정보가 파악된 $\\mathbf{c}_1, … , \\mathbf{c}_T$ sequence가 출력된다.특징으로는, transformer 블록에서는 기본적인 absolute positional embedding을 사용하지 않고, convolution 연산을 통해서 relative positional embedding과 유사한 효과를 주었다고 한다.Quantization Module[그림03] G개의 codebook, V개의 code words를 활용한 Wav2Vec 2.0의 quantization 모듈latent speech representation $\\mathbf{z}$가 입력되는 또 다른 모듈은 quantization 모듈 $\\mathcal{Z} \\mapsto \\mathcal{Q}$ 이다. vector quantization의 개념이 헷갈리면 [여기]를 참고하면 좋을 것이다. [그림03]의 중앙을 보면 codebook 행렬 $e \\in \\mathbb{R}^{V \\times d / G}$이 $G$개 존재하여 $G \\times V$ 크기의 multiple codebooks를 이루고 있다. 즉, 하나의 codebook은 [그림03] 중앙에서 보여지는 $V$개의 code word 벡터(작은 네모 한 개) sequence 한 행에 대응된다. 이들은 모두 학습 가능한 파라미터로 구현된다. 즉, codebook을 embedding matrix로, code word를 embedding 벡터로 생각하자. (참고로 저자는 $G=2$, $V=320$을 사용했다.)이러한 세팅 하에서 quantization 모듈에서 일어나는 일들을 설명해보겠다. encoding 된 $z_t$가 주어졌을 때, $z_t$는 레이어를 통과하여 logit으로 변환되고, gumbel softmax(참고) 및 argmax를 통해 one-hot encoding 된 후(즉, 이산화 과정), 마치 NLP에서 embedding matrix에서 특정 단어에 해당하는 embedding 벡터를 뽑아내듯, 각 codebook 내에서 하나의 code word 벡터를 골라낸다. code word 벡터는 $G$개의 codebook 행렬에서 각각 하나씩 추출됨에 따라 총 $G$개의 $e_{1}, …, e_{G} \\in \\mathbb{R}^{d / G}$ 벡터들로 추출될 것이다. 이후, $G$개의 벡터 모두를 concatenate 하여 $e_{t} \\in \\mathbb{R}^{d}$를 만든다([그림03]에서의 세번째 과정). 여기서 linear transformation $\\mathbb{R}^{d} \\mapsto \\mathbb{R}^{f}$을 통해서 quantized representation $q_{t} \\in \\mathbb{R}^{f}$를 최종적으로 만들어낸다.([그림03]에서의 마지막 과정)codebook과 code word의 의미복잡하다. 그런데 도대체 codebook과 code word가 의미는 것은 무엇일까? code word는 일종의 음소(phoneme)에 대한 representation이라고 생각하면 될 것 같다. 아무리 언어가 다르더라도 사람이 발음할 수 있는 음소는 사실상 유한하다고 봐도 좋기 때문에, 이를 마치 embedding 벡터로 표현한 것이 code word인 셈이다. 또한 이들이 모여 만들어진 행렬이 codebook인 셈이다. 즉, $V$개의 음소 중 현 시점에 음성 encoding 벡터 $z_t$와 가장 대응될 음소 벡터를 이산화 과정을 통해 골라낸 것이 $q_t$라고 할 수 있다.수식으로 표현한 gumbel softmax원 논문에 나와 있는 수식으로 다시 살펴보겠다. encoder를 거쳐 나온 $\\mathbf{z}$는 레이어를 통과하여 로짓으로 $\\mathbf{l} \\in \\mathbb{R}^{G \\times V}$ 변환된다. 이때 $G$개의 multiple codebook을 사용하므로, $g$번째 codebook에서 $v$번째 code word 벡터가 선택될 확률을 gumbel softmax로 표현하면 다음과 같다.$p_{g, v} = \\cfrac{\\exp(l_{g, v} + n_v) / \\tau }{\\sum_{k=1}^{V} \\exp (l_{g, k} + n_k) / \\tau}$이때 $\\tau$는 gumbel softmax의 non-negative temperature, $n=- \\log ( \\log (u) )$이며, $u$는 uniform distribution $\\mathcal{U}(0, 1)$에서 랜덤하게 sampling된 값이다. gumbel softmax의 특징답게, forward pass에서는 확률 값에 대한 argmax를 통해 나온 index에 해당하는 codeword가 선택되지만, backward pass에서는 gumbel softmax에 대한 기울기가 계산되어 학습된다.02. 학습 방식Wav2Vec 2.0은 pre-training 과정에서 BERT와 유사하게 마스킹 기법을 도입한 것이 특징이다. 학습의 목적식은 마스킹된 부분에 해당되는 quantized representation인지, 다른 부분에 해당되는 quantized representation인지를 구분하는 문제로 구성되어 있다. pre-training을 마치면, labeled data로 fine-tuning이 진행된다.마스킹마스킹 기법을 살펴보겠다. 마스킹은 feature encoder의 출력값인 $\\mathbf{z}$를 transformer block인 context network에 입력하기 전에 수행된다. transformer block의 self-attention 효과를 보기 위해 마스킹을 적용하는 것이므로, 당연히 quantization 모듈의 입력값에는 마스킹을 수행하지 않는다.그 과정은 다음과 같다.[그림04] masking 인덱스의 시작점을 선택함[그림05] masking을 진행함우선, [그림04]와 같이 $p=0.065$의 확률로 $\\mathbf{z}$ sequence를 마스킹의 시작점으로 선정한다. 그리고는 [그림05]와 같이 $M=10$ 만큼 연달아 마스킹을 수행한다. 이때, $p$와 $M$은 하이퍼파라미터이다. 시작 지점에 따라서 당연히 마스킹이 겹치는 경우가 생길 수 있다. 마스킹은 trained feature vector로 마스킹되는 부위를 대체하는 방식이며, 모든 마스킹 부위는 동일하게 해당 feature vector를 사용한다.목적식(Loss Function)$\\mathcal{L} = \\mathcal{L}_{m} + \\alpha \\mathcal{L}_d$loss function은 위와 같이 정의된다. $\\mathcal{L}_m$은 다른 Wav2Vec 버전들과 유사하게 pre-training 과정에서 계산되는 contrastive loss term이다. 추가로 $\\mathcal{L}_d$ term이 더해져 있는데, 이는 diversity loss라고 부른다. 이때 $\\alpha$는 하이퍼파라미터이다.Contrastive Loss$\\mathcal{L}_m = - \\log \\cfrac{ \\exp{ (sim(\\mathbf{c}_t , \\mathbf{q}_t)/ \\mathcal{κ}) } }{ \\sum _ {\\tilde{\\mathbf{q}} \\sim \\mathbf{Q}_t} \\exp{(sim(\\mathbf{c}_t , \\tilde{\\mathbf{q}})/\\mathcal{κ})}}$contrastive loss term $\\mathcal{L}_m$은 위와 같다. 수식을 뜯어보자. [그림02]와 함께 보면 좋을 것이다. $t$는 마스킹이 수행된 time step이다. $\\mathbf{c}_t$는 마스킹이 수행된 time step에서 추출된 context representation으로, 해당 시점 기준으로 전체 sequence에 대한 맥락 정보가 반영되어 있다. $\\tilde{\\mathbf{q}} \\in \\mathbf{Q}_t$는 $K$개의 distractor(방해 요소)와 정답 역할을 하는 1개의 $\\mathbf{q}_t$로 구성되어 총 $K+1$개의 candidate quantized representation이다. 이때, $K$개의 distractor는 동일 발화의 다른 마스크 time step으로부터 랜덤하게 추출한 값들이다.$κ$는 학습 과정에서 temperature 역할을 하는 상수값이며, $sim()$ 함수는 cosine similarity 연산이다.따라서, 이를 종합해 볼 때, contrastive loss는 마스킹 $t$시점 context representation $\\mathbf{c} _ t$이 주어졌을 때 정답에 해당하는 $\\mathbf{q} _ t$를 오답 역할을 하는 다른 candidate quantized representation 가운데서 구분해내는 역할을 한다.Diversity Loss$\\mathcal{L}_d = \\cfrac{1}{GV} * (-H(\\bar{p} _ g)) = \\cfrac{1}{GV} \\sum _ {g=1}^G \\sum _ {v=1}^V \\bar{p} _ {g, v} \\log(\\bar{p} _ {g,v})$diversity loss $\\mathcal{L}_d$은 위와 같으며, 일종의 regularization 기법이다. 저자가 사용한 codebook의 수 $G=2$개였으며, 각각의 codebook 내에서 $V=320$개의 code word를 사용했다. 즉, 첫번째 codebook에서 320가지의 quantized representation이 나올 수 있고, 두번째에서도 마찬가지이므로, 총 $320 \\times 320 = 102400$가지의 quantized representation 조합이 나올 수 있다.그런데 우리는 Wav2Vec 2.0이 실제로 이 모든 조합의 확률을 다 고려해서 골고루 quantized representation을 만드는지 알 수 없다. 수많은 code word 선택에 대한 경우의 수가 있는데, 제대로 활용하지 못한다면 codebook을 활용할 이유가 없는 것과 다름 없다.저자는 이러한 이슈를 방지하기 위해서 정보 이론의 엔트로피 개념인 $H(X) = - \\sum_{x} P(x) \\log{(P(x))}$ 를 도입했다. 정보 엔트로피는 균등한 분포 하에서 가장 큰 값을 가진다. 예를 들어서, 앞뒷면의 확률이 모두 동일하게 1/2인 동전을 던질 때의 엔트로피가 앞뒷면의 확률이 불균등한 동전을 던질 때보다 엔트로피가 높다. 요컨대, 저자는 엔트로피를 극대화하기 위한 term을 diversity loss에 포함하여 모든 Wav2vec 2.0 모델이 모든 code word를 균등하게 고려할 수 있게 설계한 것이다.Fine-tuning모델이 pre-training을 마치고 나서, fine-tuning 단계에서는 quantization이 활용되지 않는다. 그대신, 무작위로 초기화된 linear projection layer를 모델의 최상단에 두고, context representation $\\mathbf{c}$를 통과시키는 방식이다. 이 레이어는 풀고자 하는 task의 어휘(vocabulary)의 수를 의미하는 $C$개 class만큼의 차원으로 projection 한다. 그 후, CTC loss 및 SpecAugment 기법 등을 이용해서 labeled data에 대해 fine-tuning 된다. 또한 저자는 fine-tuning 단계에서도 마스킹 기법을 그대로 유지했다고 한다.03. 결론과 느낀 점정리하자면, Wav2Vec 2.0은 기존 Wav2Vec 버전들과 유사하게 self-supervised learning, 그중에서도 contrastive learning을 이용해서 학습했다. 무엇보다 end-to-end로 transformer 블록을 활용했다는 점은 VQ-Wav2Vec과의 차이점이기도 하다. 그리고 multiple codebook을 효과적으로 이용하기 위해 diversity loss를 사용한 것도 독특하다.NLP에서의 언어모델도 대규모 학습 데이터로 pre-training을 하지만, 특정 언어에 종속적인 경우가 많다. Wav2Vec 2.0은 언어모델과는 다르게 특정 언어에 종속되지 않고 다양한 언어 및 방언에 확장될 수 있다는 점이 굉장히 인상 깊다. Wav2Vec 2.0을 시작으로 하여 음성 인식 분야의 진입 장벽이 굉장히 낮아져서 추후 모두가 쉽사리 음성 AI 기술을 구현할 날이 곧 올 것만 같다.04. 참고 문헌[1] 원 논문 : Baevski, Alexei, et al. “wav2vec 2.0: A framework for self-supervised learning of speech representations.” Advances in Neural Information Processing Systems 33 (2020): 12449-12460.[2] Łukasz Sus의 블로그 : https://towardsdatascience.com/wav2vec-2-0-a-framework-for-self-supervised-learning-of-speech-representations-7d3728688cae[3] 정보 엔트로피 : 위키피디아" }, { "title": "Vector Quantization과 Codebook 개념 정리", "url": "/posts/Vector-Quantization/", "categories": "Glossary", "tags": "Terminology, Quantization", "date": "2022-07-30 00:00:00 +0900", "snippet": "이 포스트는 개인적으로 공부한 내용을 정리하고 필요한 분들에게 지식을 공유하기 위해 작성되었습니다. 지적하실 내용이 있다면, 언제든 댓글 또는 메일로 알려주시기를 바랍니다.00. 들어가며음성 인식에서 VQ-Wav2Vec 모델이나, Wav2Vec 2.0 등에서 Vector Quantization 또는 Codebook 등과 같은 용어들이 자주 나온다.Quantization이라는 용어는 Distillation이나 Pruning 기법과 함께 거대 AI 모델을 경량화 하는 기법으로 흔히 알고는 있다.그럼에도 Vector Quantization의 정확한 정의가 정리되지 않고서 논문 등을 읽으려니 헷갈리는 점이 많아서 이참에 관련 용어들을 정리하고자 한다.01. Quantization(양자화)의 사전적 정의*[그림01] Quantization의 예 아날로그양, 즉 단절 없이 연속된 변화량을 일정한 폭 ∆로 불연속적으로 변화하는 유한 개의 레벨로 구분하고, 각 레벨에 대하여 각각 유니크한 값을 부여하는 것. 어떤 특정한 레벨에 속하는 폭 ∆의 범위 내의 모든 아날로그양은 그 레벨에 부여된 특정값으로 대치할 수 있다. 예를 들면, 1.5∼2.5 범위의 모든 아날로그양에는 2라는 값이 주어진다.(전기용어사전)다시 말해, Quantization의 핵심은 연속된 변화량을 유한개의 레벨로 구분하고, 각 레벨에 대해 특정 값을 부여하는 것이라고 한다.02. Quantization의 쉬운 예제[그림02] 사인 함수$y = \\sin (x)$ 그래프는 [그림02]와 같이 [-1, 1] 사이의 무한한 실수로 표현된다.컴퓨터는 무한한 실수 데이터를 표현하기 힘들어 2bit로 데이터를 표현해야 한다고 하면, 총 4개의 데이터로 표현할 수 있다.어떻게 표현해야 4개의 데이터로 $y = \\sin (x)$를 표현할 수 있을까?[그림03] 사인 함수를 {1, 0.9, -0.9, -1}로 표현한 경우[그림03]과 같이 {1, 0.9, -0.9, -1} 데이터로 표현할 수 있겠다. 그런데, 이렇게 하면 각 실수값들을 최대한 표현했다고 보기 어렵고, 정보의 손실이 커 보인다.한편, [그림04]와 같이 {1, 0.5, -0.5, -1} 데이터로 표현한다면, 원래의 $y = \\sin (x)$ 데이터를 더욱 잘 표현하게 된다.이 과정은 결국 [-1, 1] 사이의 연속적인 값을 유한한 4개의 레벨로 구분하고, 각 레벨에 대해 {-1, -0.5, 0.5, 1}이라는 대표값을 부여한 것이라고 할 수 있다.즉, Quantization을 수행한 것이다.03. Vector Quantization 정리 정의 (정보통신기술용어해설) 연속적으로 샘플링된 진폭값들을 그룹핑하여, 이 그룹단위를 몇개의 대표값으로 양자화 일련의 표본들을 특성화시킨 몇개의 대표값(n-tuple,순서쌍)으로 양자화 쉬운 정의 N개의 특징 벡터 집합 $\\mathbf{x}$를 K개의 특징 벡터 집합 $\\mathbf{y}$로 mapping 하는 것 예를 들어, 특징 벡터 집합이 아래와 같다고 하면, $\\mathbf{x}$ = {유재석, G-Idle,이정재 ,싸이, 아이유, 마동석, 강호동} $\\mathbf{y}$ = {가수, 영화배우, 개그맨} 양자화 연산자 $f( * )$를 통해서 $\\mathbf{y} = f(\\mathbf{x})$와 같이 mapping하면 Vector Quantization 결과는 아래와 같음 가수 = {G-Idle, 싸이, 아이유} 영화배우 = {이정재, 마동석} 개그맨 = {유재석, 강호동} 이때 $\\mathbf{y}$의 각 원소(i.e., 특징)들은 Codeword 또는 Cluster라고 불리며, $\\mathbf{y}$를 Codebook 이라고 함 따라서, 음성인식에서의 VQ-Wav2Vec이나 Wav2Vec 2.0에서 행해지는 Vector Quantization이란, 학습 가능한 Embedding Matrix를 Codebook으로 사용하여,Encoder를 거친 특징 벡터 $\\mathbf{z}$를 Gumbel Softmax 또는 K-means 클러스터링 등으로 Codebook 내 Codeword에 mapping시키는 과정이라고 이해할 수 있겠다.04. 참고 문헌[1] 정보통신기술용어해설[2] DATACREW MAGAZINE[3] 페이오스 님의 블로그[4] Machine Learning Glossary" }, { "title": "(Speech Recognition) Conformer 리뷰 및 설명", "url": "/posts/Conformer/", "categories": "Speech Recognition", "tags": "Speech AI, ASR, End to End, Paper Review", "date": "2022-07-28 00:00:00 +0900", "snippet": "이 포스트는 개인적으로 공부한 내용을 정리하고 필요한 분들에게 지식을 공유하기 위해 작성되었습니다. 지적하실 내용이 있다면, 언제든 댓글 또는 메일로 알려주시기를 바랍니다.💡 2020년, 구글에서 발표한 “Conformer : Convolution-augmented Transformer for Speech Recognition” 논문을 설명한 글이다.01. 들어가며기존 end-to-end 자동 음성 인식 접근 방식acoustic model, pronunciation model, language model 등 수많은 컴포넌트들로 이루어져있었던 과거의 음성 인식 아키텍처는 딥러닝 기술이 도입되면서 end-to-end 방식으로 바뀌어왔다. conformer가 발표되었던 2020년까지도 딥러닝을 활용한 end-to-end ASR에 대한 다양한 접근 방식들이 있었다.대표적으로 Recurrent Neural Network(RNN)를 활용한 접근 방식이 있었다. RNN은 음향 신호 sequence에 대한 time step 별 의존성(dependency)을 포착하는 데 탁월하기 때문에 많은 연구들이 RNN을 적용하였다. RNN 기반의 ASR 선행 연구 State-of-the-Art Speech Recognition with Sequence-to-Sequence Models Exploring Architectures, Data and Units For Streaming End-to-End Speech Recognition with RNN-Transducer Streaming End-to-end Speech Recognition For Mobile Devices 한편, 최근 transformer는 self-attention 기법으로 sequence의 거리가 멀어도 맥락 정보들을 잘 파악할 수 있다. 이러한 장점으로 RNN 기반의 NLP 판도를 바꾼 transformer는 컴퓨터비전 뿐만 아니라 end-to-end 음성 인식에도 큰 기여를 했다. transformer 기반의 ASR 선행 연구 Transformer Transducer: A Streamable Speech Recognition Model with Transformer Encoders and RNN-T Loss 그리고, Convolution Neural Network(CNN) 역시 레이어마다 receptive field를 통해 지역적인 맥락 정보를 포착하는 데 효과적이므로 end-to-end 음성 인식에서도 성공적으로 사용되어왔다. CNN 기반의 ASR 선행 연구 Jasper: An End-to-End Convolutional Neural Acoustic Model QuartzNet: Deep Automatic Speech Recognition with 1D Time-Channel Separable Convolutions ContextNet: Improving Convolutional Neural Networks for Automatic Speech Recognition with Global Context 기존 end-to-end 방식의 한계앞서, 최근의 end-to-end 자동 음성 인식 모델로써 transformer와 CNN이 많이 활용된다고 하였으나, 이 두 모델 모두 근본적으로 한계점이 존재한다. transformer의 경우 긴 길이의 context를 global하게 파악할 수 있는 반면, 지역적인 패턴 정보를 섬세하게 파악하는 데는 강점이 있지 않다. 반면, CNN은 지역적인(local) 패턴 정보를 파악하는 데는 탁월하지만, 지역적인 정보를 활용해서 global 패턴 정보를 파악하기 위해서는 아주 많은 레이어와 그에 따른 파라미터가 필요하다.따라서 conformer의 저자들은 transformer의 장점과 CNN의 장점을 한 데 모아 그 효과를 극대화 할 수 있도록 자동 음성 인식 모델에 transformer의 self-attention과 convolution 연산을 합쳐서 사용할 것을 제안한다. 즉, conformer란 CONvolution + transFORMER라는 이름에서도 알 수 있듯이 transformer와 CNN의 장점을 합친 모델이다.02. Conformer 모델conformer는 conformer encoder와 LSTM decoder로 구성되어 있다. LSTM decoder는 단순히 글자들의 sequence를 출력하기 위한 것이므로, 여기서는 conformer encoder 위주로 살펴보겠다. conformer encoder의 전체적인 아키텍처는 [그림01]과 같다.[그림01] conformer의 encoderconformer의 encoder는 ASR 데이터 증강 기법인 SpecAug를 거침으로써 시작된다. 음성 신호는 SpecAug 레이어를 거친 후, Convolution Subsampling 레이어를 통해 특징을 추출하고, Linear 레이어 및 Dropout을 거쳐 Conformer Block을 통과함으로써 encoding된다. 여기서의 핵심은 단연 conformer block이다.Conformer Block[그림02] transformer block을 변형한 (좌)macaron-net과 (우)conformer blockconformer block은 macaron-like한 방식으로 transformer 블록을 변형한다. macaron-like 하다라는 말은 transformer를 numerical ODE solver의 관점에서 해석하고자 했던 연구인 [macaron-net](https://arxiv.org/abs/1906.02762) 방식을 차용했음을 의미한다. 이는 기존의 Multi-Head Self Attention(MHSA) → Position-wise Feed Forward(FFN)로 이어지는 transformer block 구조를 마치 마카롱 모양처럼 FFN → MHSA → FFN 방식으로 변경한 것이다. 이때 FFN에서는 half-step residual weights라는 방식으로 독특하게 residual connection을 구성한다. $\\tilde{x}_i = x_i + \\cfrac{1}{2} \\text{FFN}(x_i)$와 같이 residual connection에 1/2만큼의 weight를 주는 방식이다.macaron-like한 conformer는 FFN → MHSA → Convolution Module → FFN로 이루어져있으며, 아래와 같이 표현할 수 있다.$\\tilde{x}_i = x_i + \\cfrac{1}{2} \\text{FFN}(x_i)$$x’_i = \\tilde{x}_i + \\text{MHSA}(\\tilde{x}_i)$$x’'_i=x’_i + \\text{Conv}(x’_i)$$y_i = \\text{Layernorm}(x’'_i + \\cfrac{1}{2} \\text{FFN}(x’'_i))$$x_i$는 $i$번째 conformer block의 입력값을 의미하고 $y_i$는 encoding된 출력값을 의미한다. 그럼, macaron-like FFN 사이에 있는 각각의 모듈에 대해서 살펴보도록 하겠다.Multi-Head Self-Attention(MHSA) Module[그림03] conformer의 multi-head self-attention 모듈먼저, MHSA 모듈을 살펴보겠다. 기본적인 transformer의 MHSA와는 달리, Transformer-XL의 relative positional embedding 기법을 적용한 MHSA를 사용하였다.다음은 Transformer-XL의 relative positional embedding에 대한 설명이다.저자들에 따르면, relative positional embedding을 적용하면 self-attention 모듈이 길이가 다른 입력값에 대해서도 잘 generalize 할 수 있기 때문에 발화의 길이가 상이하더라도 강건한 encoder가 될 수 있다고 한다. 이처럼 relative positional embedding을 적용하여 MHSA을 수행되고나면 dropout을 거쳐 residual connection 된 후 다음 단계인 Convolution Module로 넘어가게 된다.Convolution Module[그림04] conformer의 convolution 모듈MHSA 모듈을 거친 representation은 Convolution Module로 넘어온다. Convolution Module에서는 Conv 연산을 통해서 음성 신호 representation의 지역적인 정보를 학습한다. Convolution Module로 넘어온 음성 신호 representation은 Layernorm을 거쳐 Pointwise Conv → Glu Activation → 1D DepthwiseConv → BatchNorm → Swish Activation → Pointwise Conv → Dropout을 거친다. 그리고 다시금 FFN module로 흘러간다.Feed Forward Module[그림05] conformer의 feed forward 모듈FFN 모듈에 대한 세부 사항들은 [그림05]와 같다. 다른 모듈에서와 동일하게 Layernorm은 기본적으로 적용한 후, 2회의 Linear Layer 등을 통과하는 구조다.03. Experiments970 시간의 labeled speech dataset인 LibriSpeech를 이용해서 evaluate 하였다. 추가적으로 활용한 언어모델을 학습하기 위해 800M word token text-only corpus를 사용했다고 한다.decoder는 단순히 한 층을 사용한 LSTM decoder를 사용하였으며, 학습한 언어모델은 shallow fusion 방식으로 활용했다. 참고로 shallow fusion의 개념은 [그림06]과 같다.[그림06] shallow fusion 도식$\\mathbf{y}^* = \\arg \\max_{\\mathbf{y}} (\\log P_{e2e}(\\mathbf{y} | \\mathbf{x}) + \\lambda \\log P_{LM}(\\mathbf{y}))$즉, 음성 신호 sequence $\\mathbf{x}$가 주어졌을 때 end-to-end(e2e) 방식으로 글자의 sequence $\\mathbf{y}$를 decoding 하는 모델 $P(\\mathbf{y} | \\mathbf{x})$(여기서는 conformer encoder + LSTM decoder)과 별도로 학습한 언어모델(여기서는 3층짜리 LSTM)을 함께 고려하여 최종 출력될 글자의 확률을 결정하는 기법인 것이다.[표01] conformer 모델 크기별 파라미터conformer도 모델의 크기에 따라서 Conformer(S), Conformer(M), Conformer(L)로 구분할 수 있으며, 각각의 파라미터는 [표01]과 같다.[표02] conformer 모델의 성능 비교표[표02]는 confermer가 공개될 당시의 SOTA model이었던 ContextNet, Transformer Transducer 등과 LibriSpeech 데이터셋을 기준으로 Word Error Rate(WER) 성능을 비교한 결과이다. 언어모델을 사용하지 않은 Conformer(M) 모델로도 기존의 Transformer나 LSTM, 또는 CNN을 기반으로 한 모델보다 우월한 성능을 보임을 알 수 있다. 언어모델을 덧붙여 사용한 conformer 모델들은 가장 낮은 WER을 달성하면서 기존의 SOTA 모델을 뛰어넘었다.04. 정리하며[그림07] 2022년 7월 말 기준 LibriSpeech SOTA 랭킹[그림07]은 현재(2022년 7월 말)를 기준으로 paperswithcode.com에서 발췌한 LibriSpeech test-clean 데이터 기준 음성 인식 SOTA 모델 랭킹이다. 2020년에 제안된 conformer는 그 자체로 아직도 상위 ranking에 있으며, 현재 기준 최고 성능 역시 conformer를 활용한 모델이다. global context를 파악하는 transformer의 장점과 local context를 파악하는 CNN의 장점을 합쳤다는 점이 확실하게 작용한 것 같다.05. 참고 문헌[1] 원 논문 : Gulati, Anmol, et al. “Conformer: Convolution-augmented transformer for speech recognition.” arXiv preprint arXiv:2005.08100 (2020).[2] Macaron-Net : Lu, Yiping, et al. “Understanding and improving transformer from a multi-particle dynamic system point of view.” arXiv preprint arXiv:1906.02762 (2019).[3] Shallow Fusion : Cabrera, Rodrigo, et al. “Language model fusion for streaming end to end speech recognition.” arXiv preprint arXiv:2104.04487 (2021)." }, { "title": "(Speech Recognition) Listen, Attend and Spell (LAS) 리뷰 및 설명", "url": "/posts/Listen,-Attend-and-Spell/", "categories": "Speech Recognition", "tags": "Speech AI, ASR, End to End, Paper Review", "date": "2022-07-26 00:00:00 +0900", "snippet": "이 포스트는 개인적으로 공부한 내용을 정리하고 필요한 분들에게 지식을 공유하기 위해 작성되었습니다. 지적하실 내용이 있다면, 언제든 댓글 또는 메일로 알려주시기를 바랍니다.01. 개요2015년, 구글에서 발표한 Listen, Attend and Spell(LAS)는 전통적인 DNN-HMM 모델과 달리 음성 인식에 사용되는 모든 컴포넌트를 결합하여 한번에 학습할 수 있는 end-to-end 방식을 제시한다.또한 LAS는 당시 유명했던 Connectionist Temporal Classification(CTC) 방법론과 마찬가지로 음성 신호의 sequence $\\mathbf{x}$가 주어졌을 때, 이에 맞는 토큰(참고로 LAS는 글자의 sequence)의 sequence $\\mathbf{y}$ 간의 명시적인 정렬 관계(alignment) 없이도 학습할 수 있다. CTC와의 차이점으로는, CTC는 RNN(등의 sequence를 모델링하는 신경망)의 출력으로 나오는 음소의 sequence가 조건부 독립(conditional independence)임을 가정하는 반면, LAS는 이러한 가정 없앰으로써 더욱 효과적인 decoding이 가능하게 되었다. 예를 들어, CTC는 “triple a”라는 발화에 대해 “aaa”로 교정할 수 없으나, LAS는 조건부 독립 가정을 제거하여 더욱 풍부한 표현(i.e., multiple spelling variants)으로 출력할 수 있게 되었다. 그럼, 마치 NLP의 Seq2Seq 모델을 빼닮은 LAS를 살펴보자.02. 훑어보는 LAS주요 특징 요약 listener : pyramidal RNN으로 음성 신호 정보를 벡터로 encoding하는 encoder를 구현함 (참고) pyramidal RNN 형태가 아니면, 모델 학습이 지나치게 느리게 수렴됨 attention mechanism : decoding 시 음성 신호의 sequence에서 더욱 집중해야 할 곳을 포착할 수 있음 (참고) attention mechanism이 없이는 심각하게 학습 데이터에 과적합됨 speller : character sequence를 출력하여 out-of-vocabulary(OOV) 문제를 해결한 decoder를 구현함 조건부 독립을 제거 : 동일한 음성 sequnece가 주어져도 beam search에 따라 출력 sequence를 다양하게 표현할 수 있음03. 조금 더 들여다보는 LASLAS가 로그-멜 스펙트럼(log-mel filter banks)을 입력으로 받는다고 할때, 입력되는 음성 신호의 sequence를 $\\mathbf{x}=(x_1, x_2, …, x_T)$라고 표기한다.또한 이에 대응되는 글자들의 sequence를 $\\mathbf{y} = (&lt;sos&gt;, y_1, …, y_S, &lt;eos&gt;)$라고 한다.이때 $y_{i} \\in \\{ a, b, c, … , z, 0, … , 9, &lt;space&gt;, &lt;comma&gt;, &lt;period&gt;, &lt;apostrophe&gt;, &lt;unk&gt; \\}$이다.LAS는 음성 신호 $\\mathbf{x}$와 처음부터 이전 시점까지의 글자 출력 결과 $y_{&lt;i}$가 주어졌을 때 글자의 출력 $y_i$가 나올 조건부 확률들을 chain rule을 이용하여 곱함으로써 $p(\\mathbf{y} | \\mathbf{x}) = \\prod_i P(y_i | \\mathbf{x} , y_{&lt;i})$와 같이 입력 sequence와 출력 sequence의 관계를 모델링한다.전반적인 아키텍처LAS는 음향 모델의 encoder 역할을 수행하는 listener와 attention 기반으로 글자들을 출력하는 decoder인 speller로 구성된다. 일종의 Sequence2Sequence(Seq2Seq) 모델의 변형이라고 생각해도 좋을 것 같다. 이들은 $Listen$ 함수와 $AttendAndSpell$ 함수로 구현된다.encoder인 listener는 원시 음성 신호 $\\mathbf{x}$를 high level representation $\\mathbf{h}=(h_1, …, h_U)$로 변환하는 역할을 한다. 이때 $U \\le T$이며, $T$는 $\\mathbf{x}$의 최대 길이를 의미한다. 추후 다룰 pyramidal 구조로 encoding을 하기때문에 이 조건은 당연하게 만족된다. 이는 다음과 같이 $Listen$ 함수로 표현한다.$\\mathbf{h} = Listen(\\mathbf{x})$한편 attention mechanism 기반의 decoder인 speller는 아래와 같이 표현한다.$P(\\mathbf{y} | \\mathbf{x}) = AttendAndSpell( \\mathbf{h}, \\mathbf{y})$이는 encoder를 통해서 encoding된 high level representation $\\mathbf{h}=(h_1, …, h_U)$와 글자의 sequence $\\mathbf{y}$(엄밀하게 말하면 이전 step까지의 글자 sequence $y_{&lt;i}$)를 사용하여 현 시점에 나올 글자의 확률 $y_i$를 예측하는 역할을 한다. 즉, 최종적으로 $P(\\mathbf{y} | \\mathbf{x})$를 예측하는 모듈이라고 보면 되겠다.LAS의 전체적인 아키텍처는 위 그림과 같다. listener는 위와 같이 피라미드 모양으로 쌓은 양방향 LSTM을 사용하며, 음성 신호 sequence $\\mathbf{x}$를 high level feature인 $\\mathbf{h}$로 encoding 한다. speller는 attention을 활용하는 decoder이며, 매 time step마다 $\\mathbf{h}$로부터 글자의 sequence $\\mathbf{z}$를 생성해낸다.Listen 함수$\\mathbf{h} = Listen(\\mathbf{x})$ 함수를 살펴보도록 하자. 그림에서도 알 수 있듯이, listener에서는 음성 신호 sequence $\\mathbf{x}$의 길이보다 더 적은 수의 $h_U$ representation들을 만들기 위해서 pyramidal BLSTM(pBLSTM)을 사용하였다. 왜냐하면, 음성 신호의 입력 값은 수백에서 수천 프레임으로 이루어질수 있기 때문이다. 이렇게 너무 많은 프레임으로 학습을 한다면, 아주 오랜 시간동안(심지어 약 한 달) 학습을 진행해도 모델의 수렴 속도가 너무 느려서 제대로 학습되지 않는 단점이 있다. 이는 $AttendAndSpell$ 함수 파트에서 attention 연산을 할 때, 매우 많은 입력 sequence 내에서 모델이 집중할 중요한 정보들을 파악하는데 많은 소요 시간이 걸리기 때문인 것으로 추정된다. 따라서 pBLSTM으로 $h_U$의 개수를 조절하여 computational complexity를 낮춤으로써 이러한 문제를 해결하고자 한 것이다.pBLSTM을 수식으로 표현하면 $h_i^j =$ pBLSTM$(h_{i-1}^j , \\left[ h_{2i}^{j-1} , h_{2i+1}^{j-1} \\right])$으로 쓸 수 있는데, 이전 레이어의 hidden state를 concatenate($\\left[ h_{2i}^{j-1} , h_{2i+1}^{j-1} \\right]$ 부분)하여 BLSTM의 입력으로 사용함으로써 구현하는 것을 알 수 있다. 참고로 일반적인 BLSTM은 단순히 $h_i^j =$ BLSTM$(h_{i-1}^j , h_{i}^{j-1})$이다.Attend and Spell 함수decoder의 $AttendAndSpell( \\mathbf{h}, \\mathbf{y})$ 함수를 살펴보도록 하자. decoder는 매 time step마다 지금까지 보았던 글자들의 sequence $y_{&lt;i}$ 정보를 토대로 다음 글자가 어떤 글자가 될 것인지 $y_i$에 대한 확률 분포를 생성한다.이때 $y_i$에 대한 확률 분포는 (1) decoder의 state $s_i$와 (2) context vector $c_i$를 이용하여 만들어지며, 아래와 같이 표현할 수 있다.$P(y_i | \\mathbf{x}, y_{&lt;i} = CharacterDistribution(s_i, c_i))$이를 구성하고 있는 요소들을 하나씩 살펴보겠다.decoder statedecoder state $s_i$는 (1) 이전 시점의 state $s_{i-1}$, (2) decoder에 의해 이전 시점에 생성되었던 글자 $y_{i-1}$, 그리고 (3) 이전 시점에 $\\mathbf{h}$와 $s_{i-1}$ 을 활용하여 만들어졌으며 $h_U$ 벡터 중 어디에 더욱 집중할지가 반영된 이전 시점의 context vector $c_{i-1}$를 입력으로 받아 만들어지며, 아래와 같이 RNN 함수로 표현할 수 있다.$s_i =$ RNN$(s_{i-1}, y_{i-1}, c_{i-1})$이러한 decoder의 state $s_i$에는 $s_{i-1}$과 $y_{i-1}$을 사용하므로 지금까지 나왔던 글자들의 sequence 정보가 함축되어 있다고 해석할 수 있다. 또한 이전 시점 context vector $c_{i-1}$을 사용하므로 음성 신호 sequence에 어떤 부분이 집중적으로 고려되고 있는지에 대한 정보가 포함되어 있다고 볼 수 있다.context vectorcontext vector $c_i$는 매 time step $i$마다 attention mechanism인 $AttentionContext$ 함수에 의해 생성되는데, 이는 다음 글자를 생성할 때 ‘음성 신호 부분 중 어느 부분이 특히 중요한지’ 맥락 정보가 반영된 벡터이다.$c_i = AttentionContext(s_i, \\mathbf{h})$이러한 $c_i$를 출력해내는 $AttentionContext$ 함수에서는 어떤 일이 벌어지는지 살펴보도록 하겠다. decoder인 speller는 매 time step $i$마다 decoder state인 $s_i$와 음성 신호 sequence가 encoding된 $h_u \\in \\mathbf{h}$ 간의 scalar energy $e_{i, u}$를 계산한다.$e_{i,u} = &lt;\\phi(s_i) , \\psi(h_u)&gt;$$\\phi$와 $\\psi$는 MLP 레이어이며, $s_i$ 벡터와 $h_u$ 벡터 각각에 대해 MLP 레이어를 통과시킨 후 내적하여 scalar energe $e_{i, u}$를 구할 수 있다. 두 벡터 간 내적은 두 벡터가 유사할수록 큰 값이 되므로, 현 시점 decoder state와 가장 유사한 음성 신호 구간 $u$가 어디인지를 확인하고자 하는 것이다. 이 연산은 현 시점 $i$에서 모든 $u$개의 벡터 $h_u$에 대해 각각 계산된다. 예를 들어, 현재가 $i$=3 시점이라고 하면, $e_{i=3, 1}, e_{i=3, 2} … , e_{i=3, u}$ 와 같이 여러 scalar energy가 나온다.이후, 지금까지 구한 scalar energy 들에 대해서 softmax 함수를 적용한다.$\\alpha_{i,u} = \\cfrac{ \\exp(e_{i,u}) }{ \\sum_u \\exp(e_{i,u}) }$앞선 예시를 계속 이어서 하자면, $e_{i=3, 1}, e_{i=3, 2} … , e_{i=3, u}$ 와 같은 각각의 scalar energy들에 대해 softmax가 적용되는 것으로, 각각의 $e_{i, u}$ 값들은 energy의 크기대로 확률값처럼 변환된 $\\alpha_{i,u}$로 변환된다. 따라서 당연하게도 $\\sum_u \\alpha_{i,u} = 1$이다.$s_i$와 $h_i$의 관계에 대한 energy가 확률값처럼 변환된 $\\alpha_{i,u}$는 time step $i$ 당시에 $u$번째 음성 신호 구간의 representation인 $h_u$가 얼마나 더 집중되어야 하는지에 대한 가중치다. 이제 이 가중치를 이용하여 $h_u$를 가중합 하면, time step i 당시에 u번째 음성 신호 구간 중 어디에 더 집중해야 하는지에 대한 정보가 담긴 맥락정보 $c_i$가 나온다.$c_i = \\sum_u \\alpha_{i, u}h_u$복잡한 과정 끝에 구한 $c_i$는 다음 시점에 decoder state를 구하는 과정에서 RNN의 입력값으로 사용된다. 이 복잡한 과정은 아래의 도식을 통해 정리할 수 있다.학습 테크닉$Listen$으로 구현되는 encoder인 listener 파트와 $AttendAndSpell$로 구현되는 decoder인 speller 파트는 동시에 결합되어(jointly) end-to-end로 학습된다. sequence to sequence 방식은 input 신호 $\\mathbf{x}$와 이전 time step까지의 글자 sequence가 주어졌을 때 현재 글자를 예측하는 방식이므로 아래와 같은 로그 확률(log probability)를 극대화 하는 것을 목표로 한다.$\\max_\\theta \\sum_{i} \\log P(y_{i} | \\mathbf{x}, y_{&lt;i}^{*} ; \\theta )$$y_{&lt;i}^{*}$는 진짜 정답인 ground truth를 의미하는데, 학습을 마치고 실제 추론할 때는 현재 time step $i$ 이전까지의 글자 sequence 값들로 ground truth 값을 사용할 수는 없다. 따라서 추론 환경과 학습 환경 간의 불일치가 일어나게되어 강건하지 못한 성능의 원인이 된다.LAS의 저자들은 이러한 문제를 해결하기 위해서 학습할 때 다음 글자를 예측하기 위해 이전 글자들을 항상 ground truth의 글자 sequence $y_{&lt;i}^{*}$로 사용하는 것이 아니라, sampling 기법을 통해 추출한 $\\tilde{y}_{&lt;i}$를 활용하는 방식을 제시했다.$\\tilde{y}_i \\sim \\text{CharacterDistribution}(s_i, c_i)$$\\max_{\\theta} \\sum_{i} \\log P(y_i | \\mathbf{x}, \\tilde{y}_{&lt;i} ; \\theta)$구체적으로 10%를 sampling rate로 설정함에 따라, 90% 확률로는 ground truth에서 실제 정답을 활용하겠으나, 10%의 확률로는 $\\tilde{y}_{i-1}$ 값을 글자의 분포에서 sampling을 하여 사용한다.decoding and rescoring학습이 완료된 이후의 추론은 음성 신호의 sequence $\\mathbf{x}$가 주어졌을 때 이에 대응되는 가장 적합한 글자의 sequence $\\hat{\\mathbf{y}}$을 찾아야 한다.$\\hat{\\mathbf{y}} = \\arg \\max_{y} \\log P(\\mathbf{y} | \\mathbf{x})$LAS의 저자들은 추론 시 decoding 전략으로 left-to-right beam search 알고리즘을 적용하였다. 여기에 더해 방대한 텍스트 데이터로 학습한 언어모델을 함께 활용하였다. 이때 LAS 모델이 예측하는 단어가 짧을 때 생기는 bias 문제를 해결하기 위해서 글자의 수 $|\\mathbf{y}|_c$ 만큼 normalize를 적용했으며, 언어모델의 출력값을 beam score에 더해서 rescoring 하였다.$s(\\mathbf{y} | \\mathbf{x}) = \\cfrac{ \\log P(\\mathbf{y} | \\mathbf{x})}{|\\mathbf{y}|_c} + \\lambda \\log P_{LM}(\\mathbf{y})$04. 정리하며LAS는 end-to-end 모델이면서도 CTC에서의 조건부 독립 가정 없이 음성 신호 sequence $\\mathbf{x}$와 글자 sequence $\\mathbf{y}$의 관계를 학습하는 데 성공했다. attention mechanism으로 CTC에서 복잡하게 구했던 $\\mathbf{x}$와 $\\mathbf{y}$ 간의 정렬 관계를 포착할 수 있다는 점이 대단히 흥미롭다.05. 참고 문헌Chan, William, et al. “Listen, attend and spell.” arXiv preprint arXiv:1508.01211 (2015).APA" }, { "title": "(Speech Recognition) Connectionist Temporal Classification 리뷰 및 설명", "url": "/posts/Connectionist-Temporal-Classification/", "categories": "Speech Recognition", "tags": "Speech AI, ASR, End to End, Paper Review", "date": "2022-07-25 00:00:00 +0900", "snippet": "이 포스트는 개인적으로 공부한 내용을 정리하고 필요한 분들에게 지식을 공유하기 위해 작성되었습니다. 지적하실 내용이 있다면, 언제든 댓글 또는 메일로 알려주시기를 바랍니다. 상당 부분 ratsgo’s speech book 내용을 참고하였습니다. ratsgo 님께 감사드립니다.01. 개요Recurrent Neural Network(RNN) 또는 Transformer 등은 sequence 데이터를 효과적으로 학습할 수 있는 모델로, 음향 신호 정보를 입력 받아서 음소(단어나 subword라고도 할 수 있겠으나, 여기서는 음소라 하겠다.)의 sequence를 예측하는 task 등에 활용될 수 있다.그런데 현실적으로는 단순히 sequence를 학습하는 모델을 활용한다고 해도 이러한 sequence labelling task를 쉽게 해결하지는 못한다. 왜냐하면, 음향 신호 데이터와 같은 sequence 데이터들은 보통 입력 데이터들이 학습하기 좋게 잘 쪼개져 있지 않다(un-segemented). 즉, 입력 정보와 레이블 간에 명시적인 정렬 관계(alignment)를 정의하기 어렵다. (이는 손글씨 인식이나 제스처 인식 문제도 해당된다.)예를 들어, “안녕하세요”라는 발화에 대해서, 누군가는 “안~녕~하세요~”라고 할수도 있고, 또 다른 누군가는 “~안녕하~세~요”라고 할수도 있다. 그러면, MFCC와 같은 음향 신호 데이터 구간의 어느 시점부터 어느 시점까지가 “안”으로 레이블링 되어야 하는지, 또 어디까지가 “녕”으로 레이블링 되어야 하는지 일일이 구분하기 어려운 문제가 생긴다.이러한 이유로, 입력 음향 신호 데이터는 대게 25ms 정도의 단위로 잘개 쪼개어 피처로써 활용하는데, 그렇다고 쪼개진 각 프레임마다 음소 레이블을 달아주는 것 또한 매우 현실적이지 않다. 사람마다 다르게 발음하는 모든 음성 신호 데이터에 사람이 인지하기도 쉽지 않은 25ms 단위로 레이블을 다는 것은 비용과 정확도 모두 비효율적이기 때문이다.Connectionist Temporal Classification(CTC)는 이러한 문제를 해결하기 위해 독특한 방식을 제안한다. 이는 학습 데이터에 대해서 pre-segmentation 과정을 통해 입력 정보와 레이블 간 명시적인 정렬 관계를 만드는 과정을 거치지 않고도, 곧장 un-segmented sequence에 대해 음소의 sequence를 예측할 수 있는 방식이다. 즉, $p(label | \\mathbf{x})$를 바로 예측할 수 있는 것이다!02. 훑어보는 CTC 알고리즘입력되는 음향 신호 데이터의 sequence는 $X=[x_1, x_2, …, x_T]$라 하고, 이에 대응하는 출력 음소 sequence를 $Y=[y_1, y_2, …, y_U]$라고 하자. CTC 알고리즘은 $X$가 주어졌을 때, $Y$에 대한 확률을 부여할 수 있다. 과연 어떻게 CTC 알고리즘이 $X$와 $Y$간의 정렬 관계를 파악하여 $P(Y|X)$를 모델링할 수 있을까? 그 방식이 바로 CTC 알고리즘의 핵심이다.훑어보는 CTC 알고리즘의 입력 벡터CTC 알고리즘은 일종의 손실(loss)을 구하는 방식이라고 봐도 큰 무리가 없을 것 같다. CTC 알고리즘은 딥러닝 모델(예를 들면 RNN)의 마지막 레이어에서 구현되는데, 시점 $t$마다 출력되는 음소들에 대한 확률 벡터 값들을 CTC 알고리즘의 입력으로 받으며, CTC 알고리즘에 의해 최종적으로 손실(CTC loss)과 기울기를 계산한다.위 그림은 CTC 레이어가 입력으로 확률 벡터 값들을 받는 과정을 보여준다. 음향 신호 sequence가 주어졌다고 해보자. 이는 RNN(또는 Transformer와 같은 sequence 처리 모델)을 통과하여 각 time step에 따라서 ‘음소 개수 + 1(blank token $\\epsilon$)’개 차원의 확률 벡터가 출력될 것이다. 이 확률 벡터가 CTC 레이어의 입력이 되는 것이다. 특별히, 확률 벡터를 구성할 때 음소뿐만 아니라, $\\epsilon$ 이라는 blank token을 추가로 사용한다는 것이 특징이다. 예를 들어, 한국어의 전체 음소 수가 42개라면, CTC 레이어는 42개의 한국어 음소에 1개의 blank token $\\epsilon$을 더해 총 43개의 음소들로 이루어진 43차원의 확률 벡터를 입력으로 받는다.훑어보는 blank token과 정렬(alignment)blank token $\\epsilon$은 왜 필요한 것일까? 만약, 음성 신호 sequence $x_1, x_2, x_3, x_4, x_5, x_6, x_7$가 주어졌고, 이에 대응되는 음소 레이블 sequence $y_1, y_2, y_3, y_4, y_5, y_6, y_7$이 각각 h, h, e, l, l, l, o라고 하면, 최종적으로 이들을 decoding 하는 과정의 출력값은 “hello”가 아닌, “helo”가 되어버린다. 왜냐하면, CTC는 decoding 시 반복되는 문자를 merge 하기 때문이다. blank token $\\epsilon$은 이러한 현상을 막기 위해 도입된 특별한 token이다.위와 같이, 음소 레이블 sequence $Y$가 단어 cat을 표현하려고 한다고 해보자. CTC 알고리즘은 위의 그림과 같은 방식으로 음소와 blank token $\\epsilon$을 적절히 조합하여 음소와 $Y$의 정렬 관계의 다양한 경우들을 표현할 수 있다. 즉, 사람마다 다르게 발음되어 제각각일 수 있는 음향 신호 sequence $X$에 대해서 프레임마다 명시적인 label이 없다고 하더라도 알고리즘 자체적으로 $X$와 $Y$의 정렬 관계를 표현할 수 있는 것이다.아직 구체적으로 어떻게 손실과 기울기를 구한다는 것인지는 다루지 않았으나, CTC 알고리즘이 손실과 기울기를 구함에 있어서 이와 같은 정렬 관계의 다양한 경우들을 고려할 수 있다는 점을 꼭 짚고 가자!훑어보는 CTC 알고리즘의 decoding위 그림은 CTC 알고리즘으로 학습을 마친 모델이 최종적으로 음성 신호 sequence를 decoding 하는 방식을 도식화한 것이다. 우선적으로 반복되는 token을 병합하고, $\\epsilon$ blank token을 제거함으로써 최종 출력 sequence를 완성한다.03. 조금 더 들여다보는 CTC 알고리즘앞서 “훑어보는 blank token과 정렬(alignment)”에서 살펴보았듯, CTC 알고리즘은 음소와 blank token $\\epsilon$의 적절한 조합으로 정렬 관계를 표현한다. 이때 label의 sequence를 $\\mathbf{l}$(e.g., h, e, l, l, o)이라고 하고, label 시작과 끝, 그리고 사이사이에 blank token $\\epsilon$(-로 표기)을 넣은 sequence를 $\\mathbf{l}’$(e.g., -, h, -, e, -, l, -, l, -, o, -)이라고 하겠다.CTC에서의 정렬 관계는 아래와 같은 3가지 특징이 있다. self-loop : 현재 token이 반복해서 나올 수 있다. (e.g., “CAT”의 경우, “CCAAT” 가능) left-to-right : 역방향으로 전이되지 않는다. non-blank token을 두 개 이상 건너뛰어 전이되지도 않는다. (e.g., “CAT”의 경우, “TAC”처럼 전이되지 않으며, “CTA”처럼 전이되지도 않음) blank 관련 : blank에서 non-blank로, 또는 non-blank에서 blank로 전이될 수 있다.CTC 알고리즘의 핵심을 결론부터 말하자면, CTC 알고리즘은 label $\\mathbf{l}$이 sequence로 주어졌을 때, time step에 따라 sequence $\\mathbf{l}’$의 전이 경로가 될 수 있는 각각의 경우들을 그래프로 표현할 수 있고, 이에 대해 Hidden Markov Model에서처럼 forward algorithm 및 backward algorithm을 적용할 수 있다. forward &amp; backward algorithm은 우도($p(label | \\mathbf{x})$, 즉 $p(\\mathbf{l} | \\mathbf{x})$)를 구하는 데 활용되며, 우도에 대해 gradient를 계산하여 backpropagation을 수행함으로써 학습하게 된다.왜 이렇게 forward &amp; backward algorithm까지 쓰면서 복잡하게 우도를 구해야 하는 것일까? 만약, 음향 신호 sequence의 프레임마다 어떤 음소인지 잘 label이 되어있다면, 단순히 cross entropy loss를 최소화하면 된다. 그러나 계속 말하지만, 음향 신호 데이터는 정답 label의 sequence와 명시적인 정렬 관계를 파악하여 label을 다는 행위가 무척 어렵다. 따라서 forward &amp; backward algorithm을 쓰는 것이다.Label to Graphlabel $\\mathbf{l}$이 h, e, l, l, o로 주어졌을 때, $\\mathbf{l}’$(-, h, -, e, -, l, -, l, -, o, -)을 세로축으로, 각 time step을 가로축으로 하여, time step에 따른 가능한 $\\mathbf{l}’$의 token 간 전이를 그래프로 표현하면 위 그림의 왼쪽과 같다. 여기서 언어 조음 규칙상 절대 발음될 수 없는 경우(예컨대, -, -, -, h, e, l, l, o)의 sequence를 제외하면 위 그림의 오른쪽과 같아진다.(이후 오른쪽 그림만을 대상으로 한다.)이때 화살표로 표현되는 각 경로들은 CTC의 decoding 과정을 통해서 label $\\mathbf{l}$(h, e, l, l, o) sequence를 만들어낼 수 있는 $\\mathbf{l}’$ token들의 전이 경로들이다. 예를 들어, 그림을 기준으로 검정색 실선은 -, -, h, e, l, -, l, o의 sequence를 의미하고, 초록색 실선은 h, e, l, -, l, o, -, -의 sequence를 의미한다. 모두 decoding을 한다면 blank token을 제거하고 반복되는 문자를 합침으로써 label $\\mathbf{l}$을 만들 수 있다.$\\pi$는 이와 같이 위 그래프에서 좌측 상단으로부터 우측 하단에 이르는 가능한 경로 가운데 하나를 표기한다. 그리고 각각의 동그라미는 개별 확률값을 의미한다. 예컨대, 그림에서 3번째 행, 2번째 열의 동그라미는 $y_3^2$ 로 표기한다. 혹은 $y_-^2$로 표기할 수 있는데, 이는 $t$=2 시점에 -가 나타날 확률을 의미한다. 즉, CTC 알고리즘의 입력값을 만들어내는 RNN + softmax에서 나온 값이다.CTC 알고리즘에서는 각 상태를 조건부 독립으로 가정한다. 따라서 음향 신호 sequence $\\mathbf{x}$가 주어졌을 때, $\\pi$가 나타날 확률은 다음과 같이 표현할 수 있다.$p(\\pi | \\mathbf{x}) = \\prod_{t=1}^{T}y_{\\pi_t}^t$이는 $t$시점에 경로 $\\pi$ 상의 token인 $\\pi_t$가 나타날 확률값들을 모두 곱한 값으로, 결국 $\\pi$가 나타날 확률이다. 한편, $\\pi$가 될 수 있는 경로는 여러 개가 있으므로(좌상단에서 우하단까지 여러 화살표가 존재하므로), 각 경로가 될 수 있는 확률들을 모두 더해주면 $p(label | \\mathbf{x})$, 즉, $p(\\mathbf{l} | \\mathbf{x})$ 를 구할 수 있다. 이를 수식으로 표현하면 아래와 같다.$p(\\mathbf{l} | \\mathbf{x}) = \\sum_{\\pi \\in \\mathcal{B}^{-1}(\\mathbf{l})}p(\\pi | \\mathbf{x})$이때, $\\mathcal{B}^{-1}(\\mathbf{l})$은 blank token과 중복된 레이블을 제거해서 $\\mathbf{l}$이 될 수 있는 모든 가능한 경로들의 집합을 의미한다. 즉, 가능한 모든 경로들이라고 보면 되겠다. 그러나 이렇게 가능한 모든 경로들에 대해 모든 시점, 모든 상태의 확률값을 계산하는 것은 complexity가 매우 높은 연산이다. 가령 time step이 조금 더 길어지거나, 음소의 개수가 늘어난다면 계산 복잡도가 상당히 증가할 것이다. 다행히, CTC 알고리즘은 이를 쉽게 계산할 수 있는 방법이 있다. 바로 Hidden Markov Model(HMM)에서 활용했던 dynamic programming 기법인 forward &amp; backward algorithm을 이용하는 것이다.Forward &amp; Backward Computation파란색 칸의 전방 확률을 예시로 들어보자. 이 부분은 $\\alpha_3(4)$로 표기할 수 있는데, 이 표기는 $t=3$ 시점에 상태 $s=4$(위에서부터 네번째 행, 즉, e)에 있을 전방 확률 $\\alpha$라는 뜻이다. 이 곳을 지나는 경로는 -he, hhe, h-e, hee 총 4가지의 경우의 수밖에 없으므로, 이들에 대한 확률을 구함으로써 $\\alpha_3(4)$를 구할 수 있다.$\\alpha_3(4)$ = $p$(”-he” | $\\mathbf{x}$) + $p$(”hhe” | $\\mathbf{x}$) + $p$(”h-e” | $\\mathbf{x}$) + $p$(”hee” | $\\mathbf{x}$)$= y^{1}_{−} \\cdot y^{2}_{h} \\cdot y^{3}_{e} + y^{1}_{h} \\cdot y^{2}_{h} \\cdot y^{3}_{e} + y^{1}_{h} \\cdot y^{2}_{−} \\cdot y^{3}_{e}+y^{1}_{h} \\cdot y^{2}_{e} \\cdot y^{3}_{e}$이를 일반화한 식은 계산량이 매우 복잡한데, 그 모습은 아래와 같다.$\\alpha_t(s) = \\sum_{\\pi \\in N^T : \\mathcal{B}(\\pi_{1:t})= \\mathbf{l}_{1:t}} \\prod_{t’=1}^t y_{\\pi_{t’}}^{t’}$따라서 계산량을 줄이기 위해, 중복되어 사용되는 부분은 미리 계산해두고 추후 이용하는 dynamic programming 기법을 이용한다. 예를 들어, 앞서 파란색 박스 영역인 $\\alpha_3(4)$를 구하기 위해 중복 계산되었던 부분은 위 그림에서 초록색 박스 영역에 해당되는 부분($\\alpha_2(2)$, $\\alpha_2(3)$, $\\alpha_2(4)$)이며, 이렇게 중복 사용되는 부분은 미리 계산해두었다가 추후 재사용하면 계산량이 줄어들 수 있다.forward algorithm에서 계산을 일반화 할 수 있는 경우는 아래의 case 01과 case 02가 있다. case 01은 $t$시점 현재의 상태가 blank token $\\epsilon$이거나, $t$시점 현재의 상태가 전전 시점인 $t$-2의 상태와 동일한 경우이며, case 02는 그 이외의 경우이다. 이를 일반화하면 아래와 같다.동일한 원리로 backward algorithm 역시 아래와 같이 일반화된다. (자세한 풀이 과정은 생략하고자 하는데, ratsgo’s speech book을 참조하면 좋을 것이다.)Likelihood Computation앞서 설명했던 전방확률 $\\alpha$와 후방확률 $\\beta$를 이용하면 모든 시점과 상태에 대해서 일일이 곱셈을 통해서 확률들을 구하지 않고서도 효율적으로 확률을 계산할 수 있다. 위 그림에서 파란색 칸($t$=3 시점에서 state h)을 반드시 지나면서 h, e, l, l, o로 decoding 될 수 있는 전이 경로에 대한 확률은 $p$(”–hel-lo”|$\\mathbf{x}$) + $p$(”-hhel-lo”|$\\mathbf{x}$) + $p$(”hhhel-lo”|$\\mathbf{x}$)이다. 이를 전방확률과 후방확률로 표현하면 아래와 같이 간단하게 표현될 수 있다.$\\alpha_{3}(2)$ = $p$(”–h”|$\\mathbf{x}$) + $p$(”-hh”|$\\mathbf{x}$) + $p$(”hhh”|$\\mathbf{x}$) = $y^1_−⋅y^2_−⋅y^3_h + y^1_−⋅y^2_h⋅y^3_h + y^1_h⋅y^2_h⋅y^3_h$$\\beta_{3}(2)$ = $p$(”hel-lo”) = $y^{3}_{h} ⋅ y^{4}_{e} ⋅ y^{5}_{l} ⋅ y^{6}_{−} ⋅ y^{7}_{l} ⋅ y^{8}_{o}$$p$(”–hel-lo”|$\\mathbf{x}$) + $p$(”-hhel-lo”|$\\mathbf{x}$) + $p$(”hhhel-lo”|$\\mathbf{x}$) = $\\cfrac{\\alpha_{3}(2)\\cdot \\beta_{3}(2)}{y_{h}^{3}}$한편, 위와 같이 $t$=3 시점에서 반드시 state h만을 지나야지만 h, e, l, l, o로 decoding 되는 것은 아니다. 아래 그림의 파란색 영역을 지나도 위와 동일하게 h, e, l, l, o로 decoding 될 수 있다.이 또한 전방확률과 후방확률의 곱으로 쉽게 표현될 수 있으며, 이때 계산된 모든 확률들을 모조리 더한 값이 바로 음향 신호 sequence $\\mathbf{x}$가 주어졌을 때 h, e, l, l, o로 decoding 될 수 있는 모든 확률의 합, 즉, 우도(likelihood)가 된다.$p$(”hello” | $\\mathbf{x}$) = $\\cfrac{\\alpha_{3}(2)\\cdot \\beta_{3}(2)}{y_{h}^{3}}$ + $\\cfrac{\\alpha_{3}(-)\\cdot \\beta_{3}(-)}{y_{-}^{3}}$ +$\\cfrac{\\alpha_{3}(e)\\cdot \\beta_{3}(e)}{y_{e}^{3}}$ +$\\cfrac{\\alpha_{3}(-)\\cdot \\beta_{3}(-)}{y_{-}^{3}}$ +$\\cfrac{\\alpha_{3}(l)\\cdot \\beta_{3}(l)}{y_{l}^{3}}$이를 일반화하여, forward &amp; backward algorithm으로 우도를 도출해내는 수식은 아래와 같다.$p(\\mathbf{l} | \\mathbf{x}) = \\sum_{s=1}^{|\\mathbf{l}’|} \\cfrac{\\alpha_{t}(s)\\cdot \\beta_{t}(s)}{y_{\\mathbf{l}’_s}^{t}}$Gradient Computation앞서 전방확률과 후방확률을 이용하여 우도 $p(label | \\mathbf{x})$, 즉, $p(\\mathbf{l} | \\mathbf{x})$를 유도해냈다. 모델을 학습하기 위해서는 우도를 최대화할 수 있는 모델의 파라미터를 찾아야 한다. 이를 위해서는 우도의 기울기를 구하고, 모델 전체 학습 파라미터에 backpropagation을 수행해야 한다. 보통의 방식처럼, 우도 계산을 로그 우도(log-likelihood, $\\ln (p(\\mathbf{l} | \\mathbf{x}))$)로 수행하는데, 이때 $t$번째 시점 $k$번째 음소에 대한 로그 우도의 기울기는 아래와 같다.$\\cfrac {\\partial \\ln (p(\\mathbf{l}| \\mathbf{x})))} {\\partial y_k^t} = \\cfrac{1}{p(\\mathbf{l}|\\mathbf{x})} \\cfrac{\\partial p(\\mathbf{l}|\\mathbf{x})}{\\partial y_k^t} = \\cfrac{1}{p(\\mathbf{l}|\\mathbf{x})} \\left( -\\cfrac {1}{(y_k^t)^2} \\sum_{s \\in lab(\\mathbf{l}, k)} \\alpha_{t}(s) \\cdot \\beta_{t}(s)\\right)$ 합성함수 미분법$f{g(x)} \\prime = f \\prime(g(x)) g\\prime(x)$ 및 $\\ln(x)$를 $x$로 미분하면 1/$x$ 임을 참고하여, $\\ln (p(\\mathbf{l} | \\mathbf{x}))$를 합성함수로 보면 아래가 성립됨 $\\cfrac {\\partial \\ln (p(\\mathbf{l}| \\mathbf{x})))} {\\partial y_k^t} = \\cfrac{1}{p(\\mathbf{l}|\\mathbf{x})} \\cfrac{\\partial p(\\mathbf{l}|\\mathbf{x})}{\\partial y_k^t}$ 상수 $a$에 대해 $a$/$x$를 $x$로 미분하면 $-a$/$x^2$라는 점을 고려하여, 아래가 성립됨 $p(\\mathbf{l} | \\mathbf{x}) = \\sum_{s=1}^{|\\mathbf{l}’|} \\cfrac{\\alpha_{t}(s)\\cdot \\beta_{t}(s)}{y_{\\mathbf{l}’_s}^{t}}$ 이므로, 이때 $lab(\\mathbf{l},k)$는 k라는 음소 레이블이 $\\mathbf{l}’$에서 나타난 위치를 의미함 즉, 복잡하지만 모델 파라미터에 대한 로그 우도의 기울기는 전방확률과 후방확률을 이용한 식으로 계산할 수 있다. 이를 이용하여 backpropagation을 수행하는 것이 CTC 알고리즘의 학습 방식이다.Rescaling한편, CTC 저자에 따르면, 전방확률과 후방확률의 계산 과정에서 그 값이 너무 작아져 underflow 문제가 발생할 수 있다고 한다. 따라서 이를 방지하기 위해 다음과 같이 rescailing을 한다. 전방확률에 대한 rescailing $C_t = \\sum_s \\alpha_t (s)$ $\\hat \\alpha_t(s) = \\cfrac{\\alpha_t (s)}{C_t}$ 후방확률에 대한 rescailing $D_t = \\sum_s \\beta_t (s)$ $\\hat \\beta_t(s) = \\cfrac{\\beta_t (s)}{D_t}$ DecodingCTC 알고리즘은 일종의 손실이라고 했다. 이를 활용하여 학습한 모델은 음향 신호 sequence $\\mathbf{x}$가 주어졌을 때 위와 같이 각 time step마다 ‘음소 개수 + 1(blank token $\\epsilon$)’개 차원의 확률 벡터를 출력한다. 이때, 각 time step마다 가장 높은 확률에 해당하는 음소를 선택하여 decoding 하는 방식을 Best Path Decoding이라고 한다. 이 예에서는 ---B-OO--XXX-__--BBUUNN-NI---&gt; , 즉 BOX_BUNNI로 decoding 된다.반면, 위와 같이 Beam Search를 decoding에 적용하는 것 또한 가능하다. 이는 beam size(가령, beam size=3)를 정해두고, 매 time step마다 beam size만큼 가장 확률이 높은 후보 sequence를 남겨가며 decoding 하는 방식이다.04. 정리하며음향 신호 sequence와 이에 대한 음소의 명시적인 정렬 관계를 정의하지 않고서도 뉴럴 네트워크가 이를 학습할 수 있는 방식인 CTC 알고리즘을 살펴보았다. cross entropy를 손실함수로 쓰지 않기 때문에 우도를 구하는 과정에서 복잡한 forward &amp; backward 알고리즘을 사용했다.CTC 알고리즘은 음향 신호와 음소 간 명시적인 정렬 관계를 만들기 위해 레이블을 만드는 공수는 필요가 없다는 장점이 있다. 그러나, 그만큼 학습이 수렴하는 데 어려움이 있어서 명시적인 정렬 관계와 cross entropy 손실함수를 사용하는 모델 대비 많은 학습 데이터가 필요하다는 단점이 있다고 한다. 또한 언어모델 도움 없이는 decoding 품질이 좋지 않을 수 있다는 단점 또한 존재한다.05. 참고 문헌[1] Graves, Alex, et al. “Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks.” Proceedings of the 23rd international conference on Machine learning. 2006.[2] Sequence Modeling With CTC[3] ratsgo 님의 블로그" }, { "title": "(Speech Recognition) VQ-Wav2Vec 리뷰 및 설명", "url": "/posts/VQWav2Vec/", "categories": "Speech Recognition", "tags": "Speech AI, Wav2Vec, Feature Extraction, Paper Review", "date": "2022-07-22 00:00:00 +0900", "snippet": "이 포스트는 개인적으로 공부한 내용을 정리하고 필요한 분들에게 지식을 공유하기 위해 작성되었습니다. 지적하실 내용이 있다면, 언제든 댓글 또는 메일로 알려주시기를 바랍니다.01. 개요VQ-Wav2Vec의 핵심은 Wav2Vec에 Vector Quantization을 적용하였다는 점이다.VQ-Wav2Vec은 Wav2Vec 방식과 유사한 self-supervised context prediction task를 수행하며 학습되는데, continuous한 음성 신호의 세그먼트(segments)를 quantization(양자화) 함으로써 discrete한 representation으로 학습하는 방식을 제안한다.이러한 discretization은 Gumbel-Softmax와 k-means 클러스터링을 통해서 수행할 수 있다.왜 굳이 discretization을 수행하는 것일까? BERT와 같은 NLP 태스크에서는 입력되는 단어들의 시퀀스가 discrete한데, VQ-Wav2Vec 방식으로 discretization을 수행하면 이산화된 음성 신호를 BERT 같은 모델에 직접 입력값으로 사용할 수 있을 것이라는 아이디어에서 착안된 것이다.실제로 VQ-Wav2Vec 저자들은 실험을 통해서 BERT와 함께 학습하여 TIMIT 음소 분류 문제 및 WSJ 음성 인식 문제에서 새로운 SOTA를 달성했다고 주장한다.02. VQ-Wav2Vec의 학습VQ-Wav2Vec은 기본적으로 Wav2Vec과 동일한 방식으로, negative 오디오 샘플로부터 true 오디오 샘플을 구별해내는 contrastive loss를 최소화하며 학습한다.새롭게 추가된 부분이 있다면, 위 그림 (a)에서 연두색 $q$ 부분이다. 기존 Wav2Vec에서는 encoder network인 $f:\\mathcal{X} \\mapsto \\mathcal{Z}$와 context network인 $g:\\mathcal{\\hat{Z}} \\mapsto \\mathcal{C}$가 컨볼루션 네트워크로 구성되어 있을 뿐이었다.VQ-Wav2Vec에서는 새롭게 quantization module $q:\\mathcal{Z} \\mapsto \\mathcal{\\hat{Z}}$이 추가되었다. 즉, encoder network $f$는 30ms의 원시 음성 신호를 10ms의 dense representation $\\mathbf{z}$로 인코딩하는데, quantizer $q$에 의해 dense representation $\\mathbf{z}$가 discrete한 원 핫 벡터(one-hot vector)로 바뀌게 된다. 최종적으로 이러한 one-hot 벡터를 이용하여 다시금 dense representation $\\mathbf{\\hat{z}}$를 복원해낸다. 이처럼 dense representation $\\mathbf{z}$를 discrete한 one-hot 벡터로 바꾸는 방법은 Gumbel-Softmax를 활용하는 방법과 K-means 클러스터링을 활용하는 방법이 있다. 이후 과정을 Wav2Vec과 동일하게 학습한다.Gumbel-Softmax를 활용한 방법Gumbel-Softmax에 대한 간단한 개념우선 Gumbel-Softmax를 간단하게 살펴보자. 위의 그림 (1)과 같은 일반적인 뉴럴 네트워크 구조에서 $\\mathbf{x}(\\theta)$와 같이 deterministic 하며 미분 가능한 노드에서는 체인 룰에 의해서 backpropagation을 수행할 수 있다. 반면, (2)와 같이 중간에 한 노드에서 softmax - argmax 등을 거쳐 categorical 변수들에 대해 sampling을 수행하는 노드는 stochastic한 요소가 들어가게 되어 backpropagation을 수행할 수 없게된다.이러한 문제를 해결하기 위해 Gumbel-Softmax는 확률적으로 sampling을 할 수 있으면서도 backpropagation이 가능한 방식을 제시한다. 원 논문의 설명은 장황하지만, VQ-Wav2Vec 논문을 참고하여 간단하게 아래와 같이 정리할 수 있다.[수식 1] $p_j=\\cfrac{\\exp{(l_j+v_j)/\\tau}}{\\sum_{k=1}^{V}\\exp{(l_k+v_k)/\\tau}}$각 notation에 대한 설명은 다음과 같다. $l \\in \\mathbb{R}^V$은 encoder network를 거쳐서 나온 dense representation $\\mathbf{z}$에 대해 linear layer와 ReLU, 그리고 또 한번의 linear layer를 통과한 로짓값이다. $u$는 uniform distribution $U(0, 1)$에서 랜덤하게 sampling한 값들이며, 이를 활용하여 log 연산을 취함으로써 다음과 같이 $v = -\\log(-\\log(u))$를 정의한다. 이를 코드로 보면 아래와 같다. import torch import torch.nn as nn import torch.nn.functional as F from torch.autograd import Variable def sample_gumbel(shape, eps=1e-20): U = torch.rand(shape).cuda() return -Variable(torch.log(-torch.log(U + eps) + eps)) $\\tau$는 temperature로 불리는데, 이 값이 0에 가까울수록 one hot 벡터처럼 categorical한 분포를 가지게되며, 값이 클수록 uniform한 분포를 가지게 된다. $p_j$를 코드로 보면 아래와 같다. def gumbel_softmax_sample(logits, temperature): y = logits + sample_gumbel(logits.size()) return F.softmax(y / temperature, dim=-1) 앞서 Gumbel-Softmax의 핵심은 softmax-argmax 등의 stochastic 연산을 뉴럴 네트워크 내 노드에서 수행하여도 backpropagation이 가능해진다고 했다. 이에 대해서는 아래와 같은 트릭이 적용된다. def gumbel_softmax(logits, temperature): \"\"\" input: [*, n_class] return: [*, n_class] an one-hot vector \"\"\" y = gumbel_softmax_sample(logits, temperature) shape = y.size() _, ind = y.max(dim=-1) y_hard = torch.zeros_like(y).view(-1, shape[-1]) y_hard.scatter_(1, ind.view(-1, 1), 1) y_hard = y_hard.view(*shape) return (y_hard - y).detach() + y이 때의 return 값을 주목해보겠다. 순전파 연산에서는 (-y).detach() + y로 y는 소거되고, 결과적으로 softmax 연산을 통해 구한 one-hot 벡터인 y_hard 변수가 return된다. 한편, backpropagation 연산에서는 .detach() 함수가 적용되어 있지 않은 y에 대해서만 gradient가 흘러갈 수 있게된다. 즉, backpropagation이 가능한 것이다!Gumbel-Softmax를 활용한 VQ-Wav2Vec 학습quantizer $q$에 의해서, 10ms로 인코딩된 dense representation $\\mathbf{z}$는 위의 과정을 거쳐 discrete한 one-hot 벡터로 바뀌게 된다. 이제 이 one-hot 벡터는 codebook이라 불리는 임베딩 행렬 $\\mathbf{e} \\in \\mathbb{R}^{V \\times d}$와 곱해짐으로써 $\\mathbf{\\hat{z}}=\\mathbf{e}_i$벡터를 얻게 된다.K-means 클러스터링을 활용한 방법앞서 살펴보았던 Gumbel-Softmax를 활용한 방식은 결국 벡터를 quantization하기 위한 트릭이었다. 이에 대한 대안으로 저자는 K-means 클러스터링을 활용하는 방식도 제안하였는데, 이는 encoder network의 출력인 10ms의 벡터 $\\mathbf{z}$와 임베딩 행렬 내의 벡터 $\\mathbf{e}$들 간 유클리디안 거리를 계산하고, 이와 가장 가까운 벡터를 활용하여 $\\mathbf{\\hat{z}}=\\mathbf{e}_i$벡터를 얻는 방식이다. 이러한 방식도 미분 불가능한 $\\arg \\min$연산을 포함하지만, Gumbel-Softmax 때와 같이 역전파 과정을 섬세히 설계함으로써 backpropagation이 가능하도록 설정할 수 있다.03. VQ-Wav2Vec을 접목한 BERT 사전 학습VQ-Wav2Vec의 학습을 마치고 나면, discretization이 적용된 오디오 데이터 특징을 추출할 수 있다. 이러한 discrete 입력값은 MLM 방식으로 학습하는 BERT의 사전 학습에 활용될 수 있다. 즉, BERT를 이용해서 입력값에 대한 양방향의 맥락을 학습하는 것이다.BERT의 사전 학습을 마치고 나면, discrete 입력값이 BERT에 입력되었을 때, 양방향 맥락이 고려된 representation들이 추출될 수 있는데, 이는 곧 speech recognition 태스크의 음향 모델의 입력값이 될 수 있다.04. 참고 문헌[1] Baevski, Alexei, Steffen Schneider, and Michael Auli. “vq-wav2vec: Self-supervised learning of discrete speech representations.” arXiv preprint arXiv:1910.05453 (2019).[2] ratsgo 님의 블로그[3] 김정희 님의 발표자료" }, { "title": "(Speech Recognition) Wav2Vec(1.0) 리뷰 및 설명", "url": "/posts/Wav2Vec/", "categories": "Speech Recognition", "tags": "Speech AI, Wav2Vec, Feature Extraction, Paper Review", "date": "2022-07-21 00:00:00 +0900", "snippet": "이 포스트는 개인적으로 공부한 내용을 정리하고 필요한 분들에게 지식을 공유하기 위해 작성되었습니다. 지적하실 내용이 있다면, 언제든 댓글 또는 메일로 알려주시기를 바랍니다.00. 들어가며음성 전문가의 도메인 지식과 푸리에 변환 등을 거쳐 추출해내는 음성 신호인Mel-Frequency Cepstral Coefficients(MFCC)와는 달리,최근에는 뉴럴 네트워크(Neural Network) 기반의 음성 신호 특징 추출이 많이 활용되고 있다.MFCC를 활용하여 음성 신호의 특징(feature)을 추출하기 위해서는 매우 복잡한 도메인 지식과 공식들이 적용되는 반면,뉴럴 네트워크 기반의 특징 추출 방식은 많은 음성 도메인 지식을 필요로 하지 않는다는 장점이 있다.본 포스트는 대표적인 뉴럴 네트워크 기반의 음성 신호 특징 추출 방식인 Wav2Vec(1.0)을 톺아보고자 한다.최근에는 Wav2Vec(2.0)까지 공개되었으나, 이 글에서는 우선적으로 Wav2vec(1.0) 버전을 살펴보고자 한다.01. 개요Wav2Vec이 나오기 이전(2019년도 이전), 음성 인식 모델이 좋은 성능을 보이기 위해서는 음성 신호가 텍스트로 전사되어 있는 대량의 데이터가 필요했다. 한편, 컴퓨터 비전이나 자연어처리 분야에서는 대량의 unlabeled 데이터를 이용하여 모델이 pre-training을 통해 대규모 일반 지식을 습득하고, 소규모의 labeled 데이터를 이용하여 downstream task에 fine-tuning 되는 방식이 큰 효과를 보여왔다.음성 인식 task에서는 특히나 음성 오디오 신호가 텍스트 형태로 전사되어 있는 데이터를 구하기 어려운데, 이러한 문제를 해결하기 위해서 Wav2Vec은 unsupervised pre-training을 적용하고자 했다. 즉, 상대적으로 훨씬 수집하기에 수월한 unlabeled 오디오 데이터를 활용하여 pre-training을 수행하겠다는 것이다.이렇게 pre-training된 Wav2Vec 모델은 원시 음성 오디오 신호를 입력받아서 general representation을 출력하게 되는데, 이때의 출력은 speech recognition system의 입력으로 활용된다.목적식으로는 negative 오디오 샘플로부터 true 오디오 샘플을 구별해내는 contrastive loss를 활용한다.02. 모델오디오 데이터 $\\mathcal{X}$로부터 pre-training 되는 과정Wav2Vec은 두 개의 convolution neural network가 쌓여 있는 구조로, 네트워크 $f:\\mathcal{X} \\mapsto \\mathcal{Z}$를 encoder network, $g: \\mathcal{Z} \\mapsto \\mathcal{C}$를 context network라고 부른다.encoder network $f$는 5층짜리 CNN으로 구성되었고, 원시 음성 신호 $\\mathbf{x}_i \\in \\mathcal{X}$를 입력으로 받아서 low frequency feature representation $\\mathbf{z_i} \\in \\mathcal{Z}$로 인코딩한다. 간단히 말해, 오디오 시그널을 latent space $\\mathcal{Z}$로 임베딩했다고 보아도 무방할 것이다.context network $g$는 9층짜리 CNN으로 구성되었고, encoder network로부터 나오는 multiple latent representation $\\mathbf{z}_i, …, \\mathbf{z}_{i-v}$를 single contextualized tensor $\\mathbf{c}_{i}=g(\\mathbf{z}_i, …, \\mathbf{z}_{i-v})$로 변환한다. 이는 인코더로부터 나온 여러 타임 스텝들을 하나로 묶어주는 역할을 수행하는데, 이 과정에서 각 타임 스텝 representation의 맥락이 파악된다.encoder network와 context network 모두 512 채널의 causal convolution network가 적용되었고, group normalization 및 ReLU 등이 적용되었다.참고로, causal convolution이란, 다음 레이어에 미래의 값이 들어가지 않는 형태를 의미한다.03. 목적식[수식01] $\\mathcal{L}_k=- \\sum_{i=1}^{T-k}(\\log \\sigma ({\\mathbf{z}\\top_{i+k}} {h_k(c_i)}) + \\lambda \\mathbb{E}_{\\mathbf{\\tilde{z}} \\sim p_n}[\\log \\sigma (-{\\mathbf{\\tilde{z}}\\top} {h_k}(c_i))])$Wav2Vec은 위의 contrastive loss를 최소화하며 학습한다. Wav2Vec은 학습과정에서 매 스텝 $k=1, …, K$ 마다 true(positive) sample인 $\\mathbf{z}_{i+k}$를 negative sample인 $\\mathbf{\\tilde{z}}$로부터 구별하는 task를 수행한다. $\\sigma$는 시그모이드 함수이며, $\\sigma ({\\mathbf{z}\\top_{i+k}} {h_k(c_i)})$는 true sample의 확률이 된다. 이때 $h_k(c_i)=W_k \\mathbf{c}_i+\\mathbf{b}_k$는 affine transformation이다. 쉽게 말해, FC layer 한개라고 보면 되겠다. 또한 $\\lambda$는 negative sample의 수를 의미한다.한편, $\\mathbf{\\tilde{z}}$는 현재 배치의 다른 음성의 hidden representation들 가운데 랜덤으로 추출하여 만든다.[수식02] $\\mathcal{L}= \\sum_{k=1}^K \\mathcal{L}_k$최종적으로는 매 $k$ 스텝에서 구해진 loss들의 합을 최소화하면서 학습되는데, 그 과정에서 true sample로 이루어진 쌍($\\mathbf{z}_{i+k}$와 $h_k(c_i)$) 관계의 representation은 벡터 공간에서 가까워지고, 네거티브 쌍은 멀어지게 된다. 즉, encoder network와 context network가 입력 음성의 다음 시퀀스가 무엇일지에 관한 정보를 음성 피처에 녹여내는 것이다.04. 기타데이터TIMIT, WSJ, Librispeech 데이터셋을 사용하였으며, 모두 16kH의 sampling rate로 구성된 영어 오디오 데이터이다.디코딩디코딩 과정에서는 4-gram KenLM 언어모델, word-based convolution 언어모델, character-based convolution 언어모델이 활용되었다.코드 예시import torchfrom fairseq.models.wav2vec import Wav2VecModelcp = torch.load('/path/to/wav2vec.pt')model = Wav2VecModel.build_model(cp['args'], task=None)model.load_state_dict(cp['model'])model.eval()wav_input_16khz = torch.randn(1, 10000)z = model.feature_extractor(wav_input_16khz)c = model.feature_aggregator(z)05. 참고 문헌[1] Schneider, Steffen, et al. “wav2vec: Unsupervised pre-training for speech recognition.” arXiv preprint arXiv:1904.05862[2] ratsgo 님의 블로그[3] 김정희 님의 발표자료" }, { "title": "(Speech Recognition) 음성 신호 특징 추출과 MFCC", "url": "/posts/MFCC/", "categories": "Speech Recognition", "tags": "Speech AI, MFCC, Feature Extraction", "date": "2022-07-20 00:00:00 +0900", "snippet": "이 포스트는 개인적으로 공부한 내용을 정리하고 필요한 분들에게 지식을 공유하기 위해 작성되었습니다. 지적하실 내용이 있다면, 언제든 댓글 또는 메일로 알려주시기를 바랍니다.00. 들어가며Wav2Vec과 같이 뉴럴 네트워크 기반의 음성 신호 특징 추출 기법이 개발되기 전에는 음성 도메인 지식과 공식들에 기반하여 음성 신호의 특징을 추출하였다.대표적인 전통적 음성 신호 특징 방법으로는 바로 Mel-Frequency Cepstral Coefficients(MFCC)가 있으며, 이는 뉴럴 네트워크 기반의 특징 추출기와는 달리 deterministic한 방법론이다.본 포스트는 MFCC를 만드는 과정을 톺아보며 전통적인 음성 신호 특징 추출 방식을 정리한다.01. 배경지식 달팽이관 달팽이관은 귀의 가장 안쪽인 내이에 위치하며 듣기를 담당하는 청각기관임 돌돌 말려있는 달팽이관을 펼치면, 달팽이관의 각 부분은 각기 다른 주파수를 감지하고, 사람은 이러한 주파수에 따른 진동수를 기반으로 소리를 인식함 주파수가 낮은 저주파 대역에서는 주파수의 변화를 잘 감지하지만, 주파수가 높은 고주파 대역에서는 주파수의 변화를 잘 감지하지 못하는데, 그 이유는 달팽이관이 고주파 대역을 감지하는 부분으로 갈수록 얇아지기 때문임 따라서 특징벡터를 단순히 주파수를 쓰기 보다는 달팽이관의 특성에 맞추어 스케일링 하는 것이 더욱 효과적인데, 이를 Mel-scale이라고 함 음성 데이터 길이를 음소(현재 내고 있는 발음) 단위로 변환 사람마다 특정 문장을 발음하는 길이는 천차만별이기 때문에, 음성 신호에 대해서 음소 단위로 쪼개어 그 길이를 변환할 필요가 있음 통상적으로 20~40ms면 음소가 해당 시간 내에 바뀔 수 없다는 연구 결과를 바탕으로, MFCC는 음성 데이터를 20~40ms 단위로 쪼개고, 이에 대해서 특징(feature)으로 활용함 02. MFCC 알고리즘 💡 MFCC : Mel-Frequency Cepstral Coefficient의 약자로, ‘음성 데이터’를 ‘특징 벡터’로 변환해주는 알고리즘을 의미함 Pre-emphasis High-pass Filter 사람이 발성할 때 몸의 구조 때문에 실제로 낸 소리에서 고주파 성분이 상당량 줄어들어 나오게 되며, 이러한 경향은 모음을 발음할 때 두드러짐 따라서, 고주파 성분을 강화해주면 음성 인식 모델의 성능을 개선할 수 있으므로, 고주파 성분을 강화하기 위해 high-pass filter를 적용함 효과 고주파 성분을 강화해줌으로써 원시 음성 신호가 전체 주파수 영역대에서 고르게 분포됨 푸리에 변환 시 발생할 수 있는 numerical problem 예방 Signal-to-Noise Ratio(SNR) 개선 방법 $Y_t=X_t-\\alpha X_{t-1}$ $\\alpha$ 는 보통 0.95나 0.97을 많이 씀 Sampling and Windowing fraiming 분석 대상이 지나치게 긴 경우 빠르게 변화하는 신호의 주파수 정보를 정확히 파악하기 어려움 따라서, 앞서 pre-emphasis 과정을 거친 신호에 대해서 신호를 20~40ms 단위로 분할함 프레임 끼리의 연속성을 위해서 분할된 신호를 50% 정도(약 10ms)씩 서로 겹추어 둠 windowing 일반적으로 원시 음성 신호를 짧은 구간 단위로 쪼개는 것은 rectangular window를 적용한 것인데, 이는 프레임의 양 끝에서 신호가 살아 있다가 갑자기 죽는 현상이 발생하며, 이로 인해 푸리에 변환 시 불필요한 고주파 성분이 살아남게 됨 따라서 각각의 프레임에 특정 함수를 적용하여 경계를 스무딩하는 기법을 사용하는데, 대표적으로는 해밍 윈도우(hamming window)라는 함수가 있음 해밍 윈도우 $w[n] = 0.54 - 0.46 \\cos{\\cfrac{(2 \\pi n)}{N-1}}$ $n$은 해밍 윈도우 값 인덱스, $N$은 프레임 길이 Fast Fourier Transform 개념 푸리에 변환은 시간 도메인의 음성 신호를 주파수 도메인으로 바꾸는 과정을 의미함 푸리에 변환을 실제로 적용할 때는 고속 푸리에 변환(Fast Fourier Transform) 기법을 쓰는데, 이는 기존 푸리에 변환에서 중복된 계산량을 줄이는 방법임 numpy의 np.fft.fft 함수를 쓰면 쉽게 구현할 수 있음 Mel Filter Bank 필요성 위의 푸리에 변환 과정까지만 적용한다 하여도 충분히 학습 가능한 피처(특징 벡터)를 추출할 수는 있음 그러나 사람 몸의 구조를 고려한 Mel-scale을 적용한 피처가 보통 더 나은 성능을 보이기 때문에 이 과정을 진행함 개념 각각의 프레임에 대해 얻어낸 주파수들에 대해서 Mel 값을 얻어내기 위한 filter를 적용함 달팽이관의 특성을 고려해서 저주파에서는 작은 삼각형 filter를 만들고, 고주파 대역으로 갈수록 넓은 삼각형 filter를 만듦 그래서 위와 같은 삼각형 필터 N개를 모두 적용한 필터를 Mel-filter bank라고 부르며, 이를 통과한 신호는 Mel-spectrogram 피처가 됨 Log-mel Spectrum 개념 사람의 소리 인식은 로그 스케일에 가깝기 때문에,멜 스펙트로그램에 로그 변환을 수행함 역푸리에 변환으로 만드는 MFCC 필요성 멜 스펙트로그램 또는 로그 멜 스펙트로그램은 태생적으로 피처 내 변수 간 상관관계가 존재함 이는 몇 개의 헤르츠 기준 주파수 영역대 에너지를 한데 모아 보기 때문임 이러한 문제는 변수 간 독립을 가정하고 모델링하는 가우시안 믹스처 모델에 악영향을 줌 개념 로그 멜 스펙트로그램에 역푸리에 변환을 수행하여 변수 간 상관관계를 해소함 03. MFCC vs Mel-Spectrogram 단순 비교 기존의 컴퓨팅 파워가 부족할 때에는 연산량이 적은 MFCC가 무조건적으로 선호되었음 최근에는 학습에 GPU 이용이 가능해짐에 따라 멜 스펙트로그램을 피처로 뽑아서 쓰는 경우도 많고, 실제로 MFCC보다 더 긍정적인 결과를 보인 논문들도 많다고 함 하지만 아직 두 피처 중 어느 것이 확실히 좋다라는 것은 없고, 어떤 모델을 쓰느냐에 따라 다를 수 있음 어떤 태스크에 어떤 피처를 쓸 것인가? 멜 스펙트로그램의 경우 주파수끼리 상관관계가 크기 때문에, 도메인이 한정적인 문제에서 더 좋은 성능을 보임 MFCC는 decorrelate를 통해서 상관관계를 제거하기 때문에 일반적인 상황에서 더 좋은 성능을 보임 04. 참고 문헌[1] ratsgo 님의 블로그[2] sooftware 님의 블로그" }, { "title": "(Speech Recognition) Phonetics", "url": "/posts/Acoustic-Phonetics/", "categories": "Speech Recognition", "tags": "Speech AI, Phonetics", "date": "2022-07-19 00:00:00 +0900", "snippet": "이 포스트는 개인적으로 공부한 내용을 정리하고 필요한 분들에게 지식을 공유하기 위해 작성되었습니다.지적하실 내용이 있다면, 언제든 댓글 또는 메일로 알려주시기를 바랍니다. 본 글은 ratsgo님의 speech book을 공부하고 정리한 글임을 밝힙니다.01. Wave 단순파 웨이브 (simple wave) $x$축은 시간을 의미하며 $y$축은 음압(sound pressure)이 사용됨 음압이란 공기 입자가 진동에 의해 인접 공기 입자를 미는 힘을 의미함 진폭 : 웨이브의 최댓값 주파수(frequency) : 1초에 몇 번 주기가 반복되는지 ⇒ 횟수 주파수 예 : 1초에 3회의 주기가 반복 주기(period) : 한 사이클을 도는 데 걸리는 시간 주기 예 : 1/3 (초) 주기 $T$와 주파수 $f$의 관계 : $T = \\cfrac{1}{f}$ 복합파 단순파의 합으로 복합파의 형태를 나타낼 수 있음 깔끔한 곡선은 아니지만, 사이클이 반복되므로 주파수를 구할 수 있음 02. Digitization 아날로그 형태인 웨이브는 연속적인 값을 가지며, 이러한 신호를 컴퓨터가 처리하기 위해서는 디지털로 바꿔주어야 함sampling 개념 일정한 시간 간격마다 음성 신호를 샘플해서 연속 신호를 이산 신호로 변환하는 과정을 의미함 초당 몇 번 sampling을 수행하는지를 나타내는 지표를 sampling rate라고 함 1초에 4만 4,100번 sampling 한다면, sampling rate $f_s$는 44100, 또는 44.1KHz가 됨 즉, 1초에 해당하는 시간 동안 sampling 된 44,100개의 실수로 구성되어 있음 sampling된 디지털 신호의 아날로그 복원 나이퀴스트(Nyquist) 정리 모든 신호는 그 신호에 포함된 가장 높은 진동수의 2배에 해당하는 빈도로 일정한 간격으로 샘플링하면 원래의 신호를 완벽하게 기록할 수 있다는 이론 인간의 가청 주파수는 20~20000(나이퀴스트 주파수)Hz인데, 40000Hz 이상의 sampling rate로 sampling하면 사람이 들을 수 있는 거의 모든 소리를 복원할 수 있음 Anti-Aliasing 자연의 소리에는 나이퀴스트 주파수보다 높은 주파수 성분이 있을 수 있음 이에 따라 나이퀴스트 정리에 따라 sampling 해도 복원 시 왜곡이 있을 수 있으며, 이를 위해서 Anti-aliasing filter를 적용해야 함 이는, sampling을 적용하기 전, 아날로그 신호에 적용하여 나이퀴스트 주파수보다 높은 주파수 영역대를 미리 없애놓는 처리 방식임 Quantization 양자화(quantization)란 실수 범위의 이산 신호를 정수(integer) 이산 신호로 바꾸는 것을 의미함 8비트 양자화 적용 시 : 실수 범위의 이산 신호가 -128~127 정수로 변환됨 16비트 양자화 적용 시 : 실수 범위의 이산 신호가 -32868~32767 정수로 변환됨 양자화에 따른 음성 정보 손실 양자화 비트 수가 커질수록 음성 정보 손실을 줄일 수 있으나, 저장 공간이 늘어나는 단점도 존재함 이러한 음성 정보 손실을 양자화 잡음(noise)라고 하며, 이를 줄이기 위해 압신(companding, 압축 &amp; 신장) 기법을 사용함 03. Loudness 소리의 크기는 진폭(amplitude)와 직접 관련이 있음 소리 크기의 측정 $N$은 이산 신호의 샘플 수를, $P_0$는 사람이 들을 수 있는 가장 작은 소리를 의미함 $Power = \\cfrac{1}{N}\\sum_{i=1}^{N}x_i^2$ $Intensity=10 log_{10}\\cfrac{1}{NP_0}\\sum_{i=1}^Nx_i^2$ Intensity는 사람이 들을 수 있는 가장 작은 소리 대비 데시벨(dB) 기준으로 power가 얼마나 큰지 나타내는 지표임 사람은 특정 주파수 영역대의 신호는 상대적으로 큰 소리로 인식하므로, loudness가 위의 power 또는 intensity와만 관련있는 것은 아님04. Pitch 음의 높낮이를 의미하며, 주파수와 관련이 있음 구간에 따른 주파수와 pitch의 관계 100Hz~1000Hz : pitch는 주파수와 선형 관계이며, 주파수가 커질수록 pitch 역시 높아짐 1000Hz 이상의 구간 : pitch는 주파수와 로그 관계이며, 주파수가 100배 정도 되어야 높낮이 차이를 2배라고 느끼는 정도임 즉, 인간은 저주파에 대해서 세밀하게 인식하고, 고주파는 세밀하게 인식하지 못함 사람이 인식하는 음의 높낮이 차이가 비슷하도록 주파수 영역대를 구분하여 pitch의 단계를 나눈 것이 멜 스케일(mel scale)임 $m=1127ln(1+\\cfrac{f}{700})$ 05. 인간의 음성 인식lexical access 사람은 음성을 단어 단위로 인식하는데, 그 특성은 아래와 같음 frequency 빈도 높은 단어를 빠르게 인식함 parallelism 여러 단어(예컨대 두 명의 화자가 발화)를 한번에 알아들을 수 있음 cue-based processing 인간의 음성 인식은 다양한 단서(cue)에 기반함 cue-based processing음성적 단서(acoustic cue) 기반의 인식 포만트(formant) 포만트란, 스펙트럼에서 음향 에너지가 몰려 있는 봉우리를 가리키며, 어떤 주파수 영역대에서 형성되어 있는지에 따라 사람이 말소리를 다르게 인지함 성대 진동 개시 시간(voice onset time) 성대 진동 개시 시간은 무성폐쇄음(ㅍ)의 개방 단계 후에 후행하는 모음을 위해 성대가 진동하는 시간 사이의 기간을 의미하며, 말소리에서 유성자음과 무성자음을 식별하는 단서임 어휘적 단서(lexical cue) 기반의 인식 음소 복원 현상(phonemic restoration effect) 단어를 이루는 음소(phenome) 가운데 하나를 기침 소리로 대체하더라도 해당 음소를 들은 것으로 인지한다는 개념으로, 청자가 해당 어휘를 이미 알고 있기 때문임 시각적 단서(visual cue) 기반의 인식 맥거크 효과(McGurk effect) 입모양 또는 기타 다른 감각 정보의 영향으로 실제와는 다른 소리로 지각되는 현상을 의미하며, ‘ga’를 발음하는 영상을 보여주면서 ‘ba’ 소리를 들려주면 ‘da’라고 알아들음 on-line processing 실시간 인식 인간은 단어 세분화(word segmentation), 구문 분석(parsing), 그리고 해당 문장 해석(interpretation)까지 250ms 안에 처리할 수 있는 능력을 가짐 06. 참고 문헌[1] ratsgo 님의 블로그" }, { "title": "(Speech Recognition) 고전적 음성 인식 기술의 개요", "url": "/posts/Traditional-ASR/", "categories": "Speech Recognition", "tags": "ASR, Speech AI, HMM, GMM", "date": "2022-07-18 00:00:00 +0900", "snippet": "이 포스트는 개인적으로 공부한 내용을 정리하고 필요한 분들에게 지식을 공유하기 위해 작성되었습니다.지적하실 내용이 있다면, 언제든 댓글 또는 메일로 알려주시기를 바랍니다.개요딥러닝 이전의 시대에서 음성 인식은 Hidden Markov Model(HMM)과 Gaussian Mixture Model(GMM)의 혼합형 모델이 주를 이루었다. 그 후, HMM과 딥러닝을 혼합한 모형들도 나오며, 아예 HMM을 사용하지 않는 방식으로 발전하기도 했다. 그래도 음성 인식의 맥락을 이해하기 위해서 HMM과 GMM 기반의 아키텍처를 이해할 필요는 있다.베이즈 정리로 살펴보는 문제의 정의음성 인식 모델은 입력 음성 신호 $X(x_1, x_2, …, x_t)$에 대해서 가장 그럴싸한 음소(혹은 단어)의 시퀀스 $W(w_1, w_2, …, w_n)$를 추정하는 문제다.직관적으로 생각할 때, $X$에 대해서 $W$를 바로 추론하는 방식으로 $P(W|X)$를 최대화하는 모델을 구축하면 좋겠으나, 고전적인 방식으로는 이러한 방식이 불가능했다.왜냐하면, 같은 단어라도 사람마다 발음도 다르고 높낮이도 다 다르기 때문이다.따라서 고전적인 방식은 베이즈 정리를 이용하여 이 문제를 우회적으로 푼다.$ W^* = \\arg \\max_W P(W|X) = \\arg \\max_W \\cfrac{P(X|W)P(W)}{P(X)} $베이즈 정리에서 evidence에 해당하는 $P(X)$의 경우, 음소(혹은 단어) 시퀀스 $W$의 모든 경우의 수에 해당하는 음성 신호 $X$의 발생 확률이기 때문에 실제로 구하는 것은 불가능하지만, 다행히 $W$와는 관계가 없는 term 이므로 생략할 수 있다. 따라서 아래와 같은 두 가지 컴포넌트로 구성되는 수식이 도출된다.$ W^* = \\arg \\max_W {P(X|W)P(W)} $우변의 첫째 항 $p(X|W)$은 음향 모델(acoustic model)이라고 하며, 음소(혹은 단어)의 시퀀스가 주어졌을 때 음성 신호 특징 벡터의 시퀀스를 모델링한다. 즉, 음성 신호와 단어 사이의 관계를 표현하는 것이다. 두번째 항인 $p(W)$은 언어 모델(language model)에 해당하며, 단어 시퀀스의 확률을 모델링한다. 즉, 음소(혹은 단어) 시퀀스가 얼마나 확률적으로 자연스러운지를 표현한다.Automatic Speech Recognition고전적 음성 인식 아키텍처에서는 보통 음향 모델 $p(X|W)$을 GMM으로 모델링한다. 즉, 음소(혹은 단어)의 시퀀스 $W$가 HMM의 hidden state로 주어졌을 때 각 음소(혹은 단어)에서 특정 음성 신호 피처 $X$가 나올 방출 확률을 모델링하는 것이다. 한편, 음소(혹은 단어)들의 시퀀스는 HMM의 전이 확률을 통해 모델링된다.참고로, 음성 인식을 처음 공부하며 헷갈렸던 점이 있다. HMM은 얼핏 보면 RNN 기반의 언어모델을 펼쳐놓은 것처럼 생겨서(물론 완전히 다른 개념이지만…) 마치 거대한 모델이 하나만 학습되면, 다양한 인풋을 넣었을 때 그에 맞는 아웃풋을 뱉어낼 것만 같다. 그런데 이와는 달리, 고전적인 음성 인식 아키텍처에서는 하나의 HMM이 아닌, 여러 개의 HMM을 학습하여 사용한다. 왜냐하면 하나의 HMM으로는 모든 발화에 대한 성질을 반영하기 힘들기 때문이다. 이를테면, 단어별로 HMM을 학습하여 사용할 수 있다. 즉, 발화에 대한 특징 벡터가 들어오면, 전부 HMM에 투입해보고, 그 중 가장 확률이 높은 HMM에 대한 단어를 예측 값으로 한다.그러나 이러한 방식은 단어의 종류가 엄청 많기 때문에 HMM 또한 매우 많이 필요하므로 scalable하지 않으며, 사용 비율이 낮은 단어는 HMM이 잘 학습되지 않는 문제가 존재한다. 가장 큰 문제로는 새로운 단어는 절대로 인식하지 못하는 문제가 생긴다. 따라서 기본적으로 음소(phoneme)를 단위로 하여 음소마다 HMM을 만들어 사용하는 것이 일반적이다. 이러한 음향 모델의 구조는 위 그림과 같다.오늘날에는 HMM과 GMM을 활용한 모델링 기법을 잘 사용하지는 않는다고 한다.language model, pronunciation model, acoustic model 등 매우 복잡한 컴포넌트들로 이루어진 고전적인 방식에 딥 러닝 기술이 접목되고 있기 때문이다.가령 HMM-DNN 구조도 그 예가 될 수 있다. 더 나아가 입력 음성 신호에서 음소(혹은 단어)시퀀스의 확률 $P(W|X)$를 곧바로 추정하는 end-to-end 방식 또한 개발되고 있다.참고[1] 고려대 김성범 교수님의 Hidden Markov Model 강의[2] 고려대 강필성 교수님의 Mixture of Gaussian 강의[3] ratsgo 님의 블로그[4] Dongchan’s Blog[5] Jonathan Hui’s Post" }, { "title": "오일러 공식(Euler's Formula) 정리", "url": "/posts/Euler's-Formula/", "categories": "Statistics & Mathmatics", "tags": "Euler's Formula", "date": "2022-07-17 00:00:00 +0900", "snippet": "이 포스트는 개인적으로 공부한 내용을 정리하고 필요한 분들에게 지식을 공유하기 위해 작성되었습니다.지적하실 내용이 있다면, 언제든 댓글 또는 메일로 알려주시기를 바랍니다.💡 오일러 공식 : $ e^{ix}=\\cos{x} + i\\sin{x} $00. Intro 오일러 공식은 세상에서 가장 아름다운 수학 공식으로 알려져있으며, 천재 수학자 오일러에 의해 정의되었음 오일러 공식은 지수함수와 삼각함수에 대한 관계를 나타내며, 전자공학, 진동학, 제어공학 등에서 매우 중요한 수학적 토대가 되었음 특히, 필자는 음성 AI를 공부하며 음성 신호를 시간 도메인에서 주파수 도메인으로 변환하는 푸리에 변환을 공부하며 오일러 공식을 접하게 되었고, 이를 아래와 같이 정리하고자 함 복소평면 상에서 실수 측 좌표 $a$와 허수측 좌표 $b$ 위치에 있는 점은 $a+ib$라는 복소수에 대응됨 복소평면 상에서 반지름이 1인 단위원을 그려놓고, 실수 측과의 각도, 즉, 편각이 $x$인 위치에 있는 이 복소수는 실수 부분과 허수 부분이 각각 $\\cos{x}$와 $i\\sin{x}$에 대응되어 $\\cos{x}+i\\sin{x}$에 대응됨 그리고 이 수는 각도 $x$에 따라 달라지는 일종의 함수이므로, $f(x)=\\cos{x}+i\\sin{x}$라고 표현할 수 있음01. f(x)의 성질제1차 성질$f(a) \\times f(b)$$= (\\cos{a}+i\\sin{a}) \\times (\\cos{b}+i\\sin{b})$$= \\cos{a} \\times (\\cos{b}+i\\sin{b}) + i\\sin{a} \\times (\\cos{b}+i\\sin{b})$$=\\cos{a}\\cos{b}+i\\cos{a}\\sin{b} + i\\sin{a}\\cos{b}+i^2\\sin{a}\\sin{b}$$=\\cos{a}\\cos{b}+i\\cos{a}\\sin{b} + i\\sin{a}\\cos{b}-\\sin{a}\\sin{b}$$=(\\cos{a}\\cos{b}-\\sin{a}\\sin{b})+i(\\cos{a}\\sin{b}+\\sin{a}\\cos{b})$$=\\cos{(a+b)}+i\\sin{(a+b)}$ (공식 참고) 삼각함수의 곱을 합과 차로 표현$= f(a+b)$ [제1차 성질]제2차 성질$f(x) \\times f(x) = f(x+x)$${f(x)}^2 = f(2x)$ [제2차 성질]제3차 성질$\\cfrac{1}{f(x)}=\\cfrac{1}{f(x)} \\times 1$$= \\cfrac{1}{f(x)} \\times \\cfrac{f(-x)}{f(-x)} = \\cfrac{f(-x)}{f(x) \\times f(-x)}$이때, 분모에 [제1차 성질]을 적용하면,$f(x) \\times f(-x) = f(x-x) = f(0) = \\cos{(0)}+i\\sin{(0)}$ 이고,$\\cos{(0)}=1$ 이고, $\\sin{(0)}=0$ 이므로, $f(0)=1$이 됨따라서, 분모가 1이 되므로 아래의 식이 유도됨$\\cfrac{1}{f(x)} = f(-x)$ [제3차 성질]제4차 성질[제3차 성질]의 유도 과정에서 도출한 $f(0)=1$ [제4차 성질]제5차 성질$f\\prime(x)=(\\cos{x}+i\\sin{x})\\prime$$=(\\cos{x})\\prime + (i\\sin{x})\\prime$ … 더해져 있는 것의 미분은 앞 뒤를 각각 미분하는 것과 동일함$=-\\sin{x}+i\\cos{x}$$=i^2\\sin{x}+i\\cos{x}$$=i(\\cos{x}+i\\sin{x})$$=if(x)$ [제5차 성질]중요한 발견! 위에서 정리한 복소평면 상에서의 함수 $f(x)$의 성질은 자연상수 $e$를 밑으로 하는 지수함수 $e^x$와 그 성질이 매우 비슷함 $f(a) \\times f(b) = f(a+b)$ [제1차 성질] $e^a \\times e^b=e^{a+b}$ ${f(x)}^2 = f(2x)$ [제2차 성질] ${e^x}^2=e^{2x}$ $\\cfrac{1}{f(x)} = f(-x)$ [제3차 성질] $\\cfrac{1}{e^x}=e^{-x}$ $f(0)=1$ [제4차 성질] $e^0=1$ $f\\prime(x)=if(x)$ [제5차 성질] 특히, $e^{ix}$의 성질은 [제5차 성질]까지 모두 만족함 $f(a) \\times f(b) = f(a+b)$ [제1차 성질] $e^{ia} \\times e^{ib}=e^{i(a+b)}$ ${f(x)}^2 = f(2x)$ [제2차 성질] ${e^{ix}}^2=e^{i2x}$ $\\cfrac{1}{f(x)} = f(-x)$ [제3차 성질] $\\cfrac{1}{e^{ix}}=e^{-ix}$ $f(0)=1$ [제4차 성질] $e^{i \\times 0}=1$ $f\\prime(x)=if(x)$ [제5차 성질] $(e^{ix})\\prime = ie^{ix}$ 💡 복소평면 단위 원 위의 복소수가 지수함수의 성질을 만족한다!$e^{ix}=\\cos{x} + i\\sin{x}$ 가 성립한다!02. 오일러 공식의 정리 지수함수 $e^{ix}$는 복소평면 단위 원 상의 함수 $\\cos{x} + i\\sin{x}$와 동일함 따라서 지수함수 $e^{ix}$는 주기함수의 성질이 있음오일러 등식 오일러 등식 $e^{i \\pi}=-1$ 이므로, $e^{i \\pi}+1=0$이 성립함 해석 $e$는 미적분을 대표하는 수 $i$는 복소수를 대표하는 수 $\\pi$는 기하를 대표함 0과 1은 어떤 정보를 표현하는 최소 단위에 해당함 ⇒ 이렇게 중요하고 대표적인 숫자들이 단지 $+$와 $=$만으로 표현된다는 것은 엄청난 사건임 03. 참고[1] DMT PARK 님의 강의[2] Wikipedia" }, { "title": "베이즈 정리 기본 개념", "url": "/posts/Bayes'-Theorem/", "categories": "Statistics & Mathmatics", "tags": "Bayes Theorem", "date": "2022-07-16 00:00:00 +0900", "snippet": "이 포스트는 개인적으로 공부한 내용을 정리하고 필요한 분들에게 지식을 공유하기 위해 작성되었습니다.지적하실 내용이 있다면, 언제든 댓글 또는 메일로 알려주시기를 바랍니다.베이즈 정리💡 확률론 패러다임의 전환 : 연역적 추론에서 귀납적 추론으로베이즈 정리의 공식$ P(H|E)=\\cfrac{P(E|H)P(H)}{P(E)} $ H(Hypothesis) : 가설 혹은 ‘어떤 사건이 발생했다는 주장’ E(Evidence) : 새로운 정보 베이즈 정리는 두 확률 번수의 사전 확률과 사후 확률 사이의 관계를 나타내는 정리임 사전 확률 $P(H)$ : 아직 사건 E에 관한 어떠한 정보도 알지 못하는 것을 의미함 어떤 사건이 발생했다는 주장에 관한 신뢰도 사후 확률 $P(H|E)$ : 사건 E 값이 주어진 경우에 대한 H의 사후 확률 새로운 정보를 받은 후 갱신된 신뢰도 베이즈 정리를 이해하기 어려웠던 이유 빈도 주의(frequentism)의 확률 관점에 익숙하기 때문임 빈도 주의와 베이지안 주의 빈도 주의 : “100번 동전을 던졌을 때 50번은 앞면이 나온다.” 베이지안 주의 : “동전의 앞면이 나왔다는 주장의 신뢰도가 50%다.” 확률을 ‘주장에 대한 신뢰도’로 해석하는 관점 빈도 주의 (기존의 통계학) 연역적 사고에 기반 확률 계산, 유의성 검정 엄격한 확률 공간을 정의하거나 집단의 분포를 정의하고 파생 결과물을 수용함베이지안 주의 (새로운 통계학) 귀납적 추론 방법 확률은 빈도 주의 방식으로 계산되는 것이 아니라, ‘믿음의 정도(Degree of belief)’로 정의되어 믿음을 수량화한 개념으로 봄 더욱 다양한 상황에 확률을 부여할 수 있음 (빈도 주의로는 모든 것을 무한히 시행할 수 없으므로) 추가되는 정보를 바탕으로 사전 확률 $P(H)$를 $P(H|E)$로 갱신함 추가 근거 확보를 통해 진리로 더 다가갈 수 있다는 철학을 내포함예제 1 질병 A의 발병률은 0.1%로 알려져있다. 이 질병이 실제로 있을 때 질병이 있다고 검진할 확률(민감도)은 99%, 질병이 없을 때 실제로 질병이 없다고 검진할 확률(특이도)는 98%라고 하자. 만약 어떤 사람이 질병에 걸렸다고 검진 받았을 때, 이 사람이 정말로 질병에 걸렸을 확률은? Hypothesis H : 실제로 병이 있다. $P(H)=0.001$ Evidence E : Positive로 병을 진단 받았다. $P(E|H)=0.99$ $P(E^c|H^c)= 0.98$ $ P(H|E)=\\cfrac{P(E|H)P(H)}{P(E)} $ 이때 우리는 $P(E)$를 모르는데 $P(E)$는 $P(E|H)P(H) + P(E|H^c)P(H^c)$로 계산할 수 있으며, 이는 파란 박스와 초록 박스 영역에 해당됨$ P(H|E)=\\cfrac{P(E|H)P(H)}{P(E|H)P(H) + P(E|H^c)P(H^c)} $$ P(H|E)=\\cfrac{0.001 \\times 0.99}{0.001 \\times 0.99 + 0.999 \\times 0.02} = 0.047 $ 47% 정도의 신뢰도로 질병에 걸렸다고 보는 것임예제 2 예제 1에서 한 번 양성 판정을 받았던 사람이 두 번째 검진을 받고 또 양성 판정을 받았을 때, 이 사람이 실제로 질병에 걸린 확률은? 우리가 원래 알고 있던 발병률은 사전 확률 $P(H)=0.001$이었는데, 증거 E를 가지고 새로 알게된 정보에 따르면, 사후 확률 $P(H|E)=0.047$로 주장에 대한 신뢰도가 갱신되었음 예제 2에서는 사후 확률 $P(H|E)=0.047$가 사전 확률 $P(H)=0.047$로써 사용됨 예제 1에서와 동일한 방식으로 계산하되, 수정된 사전 확률로써 계산하면 아래와 같음$ P(H|E)=\\cfrac{P(E|H)P(H)}{P(E|H)P(H) + P(E|H^c)P(H^c)} $$ P(H|E)= \\cfrac{0.047 \\times 0.99}{0.047 \\times 0.99 + 0.953 \\times 0.02}=0.709 $ 70% 정도의 신뢰도로 질병에 걸렸다고 보는 것임정리 데이터가 사전 확률을 사후 확률로 업데이트함 새로운 데이터를 반영할 수 있음 사전 분포 적용을 통해 기존 지식의 통합이 가능함 모수 공간을 줄이는 효과 데이터를 직접 반영하여 사후 분포를 구성함 (빈도 주의와의 차이) 모수가 많고 복잡한 모델까지 추론 가능함참고[1] 공돌이의 수학정리노트[2] [스탠코리아 StanKorea] 베이즈 통계학 소개 Introduction to Bayesian Statistics | 베이즈 정리 &amp; 베이즈 추론 | 베이지안이 되어야 할 이유" }, { "title": "Causal Discovery와 PC 알고리즘", "url": "/posts/Causal-Discovery-and-PC-algorithm/", "categories": "Causal Inference", "tags": "Causal Inference, Causal Discovery, Root Cause Analysis", "date": "2022-05-12 00:00:00 +0900", "snippet": "이 포스트는 개인적으로 공부한 내용을 정리하고 필요한 분들에게 지식을 공유하기 위해 작성되었습니다.지적하실 내용이 있다면, 언제든 댓글 또는 메일로 알려주시기를 바랍니다. 본 포스트의 상당 내용은 인과추론의 데이터과학 강의를 정리한 것임을 밝힙니다.00. 들어가며필자가 인과추론을 공부하기 시작한 이유는 클라우드 인프라 자원의 장애 발생에 대한 근본 원인을 탐지하는 기술을 연구하기 위해서입니다.관련된 선행 연구를 보았을때, 많은 경우에 인프라 자원에 대하여 인과그래프를 구축하고,이를 대상으로 BFS/DFS 탐색을 하든 나름의 랭킹 알고리즘을 활용하든 하여 장애를 탐지하는 방식을 쓰는 것을 확인했습니다.또, 특정 연구들은 인과그래프를 구축하기 위해서 PC 알고리즘이라는 것을 활용하기도 했습니다.이러한 연구들을 파악하기 위해서 기본적인 인과추론에 대한 이해가 필요했었고, 인과추론이라는 새로운 영역을 공부하게 됐습니다.그리고 드디어 인과그래프를 구축하기 위해서 많은 선행 연구들이 사용했던, 그리고 선행 연구를 보며 가장 궁금했던 PC 알고리즘을 다루고자 합니다.01. Causal Discovery지금까지 공부했던 Structural Causal Model은 모두 잘 정의되어 있는 인과그래프가 이미 존재한다는 것을 전제로 하고 있습니다.위 그림을 보겠습니다. 잘 정의되어 있는 인과그래프는 Joint Distribution으로 표현될 수 있습니다.그리고 이러한 그래프와 Joint Distribution을 따르는 데이터를 활용하면 인과관계의 효과를 추정할 수 있습니다.이러한 방식이 지금까지 공부했던 Structural Causal Model 입니다.그런데 현실에서는 인과그래프를 구축하기 어려운 경우가 많습니다.우리는 신이 아니기 때문에, 어떤 변수가 다른 변수에 어떻게 영향을 주는지 명확히 알기 어려운 것이죠.이러한 문제가 Structural Causal Model의 한계점이기도 합니다.즉, 완벽한 그래프가 주어진다면, 이론적으로 완벽한 인과적 효과를 계산할 수 있는 방법이긴 하지만, ‘완벽한 그래프’가 구축되기 어려우며, 상당한 도메인 지식도 필요로 할 것입니다.이러한 문제를 어느정도 완화해줄 수 있는 방법이 있는데, Causal Discovery가 그것입니다.그림에서 점선으로 표시된 화살표를 보겠습니다. Structural Causal Model의 역방향으로 흐르고 있죠.Causal Discovery는 Structural Causal Model과 반대로, 데이터가 존재할 때, 해당 데이터를 분석하여 데이터 내 Joint Distribution을 파악하고, 파악한 내용들로 인과그래프를 직접 도출하는 방식입니다.이처럼 데이터를 활용해서 역으로 인과그래프의 구조 자체를 도출하는 방식이기에 Structure Identification이라고도 불립니다.위의 장표는 Causal Discovery의 전체적인 구조를 보여줍니다.우선, 데이터 상에 존재하는 변수들 간의 Joint Distribution을 이용해서 변수들이 독립인지, 종속인지를 파악해야 합니다.그리고 몇 가지의 가정들을 만족했다는 전제하에 Causal Discovery 알고리즘을 돌립니다.그러면 Equivalence Class라고 부르는 인과그래프가 도출됩니다.이에 대해서 하나씩 살펴보겠습니다.02. Causal Discovery를 위한 가정Causal Discovery는 세 가지 가정이 필요합니다. Acyclicity (for DAG) Assumption Causal Markov Assumption Faithfulness AssumptionAcyclicity 가정은 DAG 그래프를 활용하기 때문에 설명을 생략하고, 나머지 가정에 대해서 알아보겠습니다.Causal Markov Assumption확률 변수 $X_1$, $X_2$, $X_3$의 Joint Distribution은 $P(X_1, X_2, X_3)=P(X_1)P(X_2|X1)P(X_3|X_1,X_2)$로 표현할 수 있습니다.만약 아래와 같이 그래프가 주어지면 어떨까요?Causal Markov Assumption은 이와 같이 인과그래프가 주어졌을 때, 특정 노드는 자신에게 직접적으로 영향을 주는 노드에게만 종속되며, 이외의 모든 노드들과는 독립이라는 가정입니다.이를 수식으로 $P(X_1, X_2, X_3)=P(X_1)P(X_2|X1)P(X_3|X_2)$로 표현할 수 있습니다.즉, $X_3$는 $X_2$에만 직접적인 영향을 받고, $X_1$으로부터는 간접적으로만 영향을 받기 때문에 수식의 $P(X_3|X_2)$ 부분이 바뀐 것을 볼 수 있습니다.Faithfulness Assumption아래와 같은 그래프를 가정해보겠습니다.노드 $A$와 노드 $D$는 d-connected 되어있습니다.$A \\rightarrow B \\rightarrow D$의 경로와 $A \\rightarrow C \\rightarrow D$ 경로가 존재하기 때문이죠.그런데 만약, $A \\rightarrow B \\rightarrow D$의 경로와 $A \\rightarrow C \\rightarrow D$ 경로가 각각 서로의 효과를 상쇄하는 정반대의 인과적 효과를 낸다면 어떻게 될까요?예를 들어서, $A \\rightarrow B \\rightarrow D$의 경로는 $+1$의 인과적 효과를, $A \\rightarrow C \\rightarrow D$의 경로는 $-1$의 인과적 효과를 낸다면, 둘의 효과가 상쇄될 것입니다.Faithfulness Assumption은 이러한 효과는 존재하지 않으며, 따라서 경로 내에 있는 노드들은 반드시 종속적인 관계여야 한다고 가정합니다.위와 같은 가정을 마쳤으면, Causal Discovery 알고리즘을 적용하여 인과 그래프를 도출할 수 있습니다.03. 다양한 Causal Discovery 알고리즘인과 그래프를 도출할 수 있는 Causal Discovery 종류는 아래와 같이 굉장히 다양합니다.(참고) 이 표는 여기에서 가져왔습니다.이들 중 어떠한 알고리즘이 특별히 다른 알고리즘보다 뛰어나다고 하기는 어렵습니다. 다만, 구현하는 방식에서의 디테일들이 다릅니다.그리고 가장 유명한 알고리즘이자, 필자로 하여금 인과추론을 공부하게 했던 알고리즘이 바로 Conditional Independence 가정을 활용하는 PC 알고리즘 입니다.PC 알고리즘을 이해하기 위해서 먼저 한 가지 더 알아야할 것이 있는데요. Markov Equivalence Class가 그것입니다.04. Markov Equivalence ClassMarkov Equivalence Class란, 동일한 skeleton과 V-structure를 가지며, 동일한 Conditional Dependency를 가지는 그래프들의 집합으로 정의할 수 있습니다.말이 어렵지만, 그림을 보며 이해하면 쉽게 알 수 있습니다.위의 세 그래프는 모두 동치(Equivalent)하다고 할 수 있습니다.왜냐하면, 세 그래프 모두 $X$와 $Z$ 및 $X$와 $Y$ 간의 관계는 직접적으로 연결되어 있어서 서로 Dependent하고,$Y$와 $Z$는 $X$를 통해서 연결되어 있어서 서로 Dependent하며, $X$를 Conditioning 하면 $Y$와 $Z$가 Conditionally Independent 해지는 구조이기 때문입니다.이렇게 $X$, $Y$, 그리고 $Z$로 표현할 수 있는 모든 DAG 그래프는 다음과 같습니다.즉, 데이터의 Joint Distribution 내에 존재하는, 노드들 간 하나의 종속(또는 독립) 관계들로 그려낼 수 있는 동치 그래프가 이렇게 여러 개 존재한다는 것입니다.문제는, 이와 같이 하나의 종속(또는 독립) 관계로 여러 그래프가 도출된다면, 이 중 어떤 그래프가 옳은 인과 그래프인지 특정할 수 없게됩니다.여기서 빨간색 박스 부분을 주목해야 합니다. Collider로 V-structure를 이루고 있는 모양이죠.Collider 꼴로 이루어진 노드 간 종속 관계는 동치인 그래프가 여러 개 존재하지 않고, 단 하나의 그래프만이 존재합니다.즉, Collider 꼴은 노드 간 종속(또는 독립) 관계를 확인할 수 있다면, 단 하나의 인과 그래프로 특정할 수 있는 구조라는 것입니다.이러한 이유로 인해 Collider 구조는 Causal Discovery에서 핵심적인 역할을 합니다.05. PC 알고리즘PC 알고리즘은 이를 개발한 Peter Spirtes와 Clark Glymour의 이름을 따서 만들어졌습니다. 이는 확률적으로 독립인 두 변수는 인과적으로 연결되어있지 않다는 아이디어를 기반으로 합니다.앞서 Causal Discovery를 위한 가정과 Markov Equivalence Class 및 Collider(V-structure) 구조의 중요성을 인지했다면, PC 알고리즘 또한 쉽게 이해할 수 있습니다.그럼, PC 알고리즘을 차근차근 살펴보겠습니다.Ground Truth 그래프우리가 PC 알고리즘을 이용하여 궁극적으로 도출하고 싶은 Ground Truth 그래프는 위와 같다고 합시다.STEP 01PC 알고리즘 STEP 01첫번째 단계는 모든 노드들이 완전히 연결되어 있는 Complete Undirected Graph로 시작합니다.STEP 02두번째 단계에서는 노드 간 Conditionally Independent한지 여부를 확인하여 Unconditionally Independent한 노드 사이의 간선을 제거합니다.예를 들어서, Ground Truth 그래프를 보았을 때, $X$와 $Y$는 어떠한 Conditioning을 수행하지 않는다 하더라도 서로 독립입니다.이러한 관계를 Unconditionally Independent 하다고 표현합니다.해당 노드 사이의 간선을 제거합니다. 그 결과는 다음과 같습니다.PC 알고리즘 STEP 02STEP 03세번째 단계에서는 두 노드 간 다른 노드가 있는 경우, 사이에 있는 노드를 Conditioning 해보았을 때 두 노드가 Conditional Independent하다면, 두 노드 사이의 간선을 제거합니다.예를 들어, STEP 02에서 $X-Z-W$ 경로에서 $Z$를 Conditioning 했더니 $X$와 $W$가 Independent 해졌다고 합시다. 그러면 $X-W$ 사이의 간선이 제거됩니다.이러한 과정을 반복하고 나면, 아래 그림과 같이 Skeleton이라 부르는 뼈대가 형성됩니다.PC 알고리즘 STEP 03, SkeletonSTEP 04네번째 단계에서는 Markov Equivalence Class에서 살펴보았던 V-structure 구조를 이용합니다.앞서 보았듯, Collider의 V-structure 구조는 동치인 여러 그래프가 도출되는 것이 아닌 단 하나의 그래프만 도출됩니다.이를 이용하여 Skeleton을 유향 그래프로 바꾸어 줍니다.예를 들어, STEP 03의 Skeleton을 보면, ($X-Z$, $Y-Z$), ($Y-Z$, $W-Z$), ($X-Z$, $W-Z$) 쌍으로 $Z$를 향해 화살표를 그어봄으로써 Collider를 만들 수 있습니다.그런데 이러한 경우의 수 중 ($Y \\rightarrow Z$, $W \\rightarrow Z$) 또는 ($X \\rightarrow Z$, $W \\rightarrow Z$)로 Collider를 만들 경우, $Z$를 Conditioning 했을 때, 두 노드 간 Dependency가 생기지 않고, Independent한 관계가 되기 때문에 Collider가 될 수 없습니다.따라서 $Z$를 Conditioning 했을 때 두 노드인 $X$와 $Y$ 간 Dependency가 생기는 ($X \\rightarrow Z$, $Y \\rightarrow Z$) 구조로 Collider를 만들 수 있습니다.이러한 방식으로 Collider를 만들어가면 아래와 같은 그래프가 나타납니다.PC 알고리즘 STEP 04STEP 05마지막 절차는 Orientation Propagation으로 불립니다. 남아있는 무방향 간선들을 활용하여 Collider가 되지 않는 쪽으로 방향을 설정해줍니다.그 결과 아래와 같이 Ground Truth와 유사한 인과 그래프를 도출할 수 있습니다.PC 알고리즘 STEP 0506. PC 알고리즘 활용해보기PC 알고리즘은 Causal Discovery Toolbox 파이썬 라이브러리를 사용하여 돌려볼 수 있습니다.다음 예제는 여기를 참고했음을 먼저 밝힙니다.이 예제에서는 1994년 미국의 Census Income Data Set 데이터를 활용합니다.데이터의 대략적인 생김새는 다음과 같습니다.코드와 실행 결과는 다음과 같습니다.# 라이브러리를 임포트함import pickleimport cdtimport networkx as nximport matplotlib.pyplot as plt# 데이터를 불러옴df = pickle.load( open( \"df_causal_discovery.p\", \"rb\") )# Skeleton 그래프를 그림glasso = cdt.independence.graph.Glasso()skeleton = glasso.predict(df)# 그래프를 시각화함fig = plt.figure(figsize=(15,10))nx.draw_networkx(skeleton, font_size=18, font_color='r')# Causal Discovery를 활용함# PC 알고리즘model_pc = cdt.causality.graph.PC()graph_pc = model_pc.predict(df, skeleton)# 그래프를 시각화함fig=plt.figure(figsize=(15,10))nx.draw_networkx(graph_pc, font_size=18, font_color='r')07. 정리하며이번 포스트에서는 Causal Discovery와 PC 알고리즘에 대해서 알아보았습니다.인과 그래프를 먼저 구축한 후 인과관계를 추론하는 기존의 방법과는 달리, 데이터를 바탕으로 인과 그래프 자체를 도출하는 Causal Discovery는 아직도 학계에서 많은 연구가 이루어지고 있는 분야입니다.아쉽게도 Causal Graph 자체를 정확하게 검증할 수 있는 방법은 세상에 없다고 합니다.그만큼 훗날, Causal Discovery 방법론들이 이러한 한계점을 극복할 수 있는 대안이 될 수 있을 것입니다.참고자료[1] 인과추론의 데이터과학[2] Introduction to Causal Inference (Brady Neal)[3] Causal Discovery- Shawhin Talebi의 블로그" }, { "title": "Query2Box_Reasoning Over Knowledge Graphs In Vector Space Using Box Embeddings (논문 및 Stanford CS224w 내용 정리)", "url": "/posts/Query2Box/", "categories": "Knowledge Graph", "tags": "Reasoning, Knowledge Graph", "date": "2022-05-11 00:00:00 +0900", "snippet": "이 포스트는 개인적으로 공부한 내용을 정리하고 필요한 분들에게 지식을 공유하기 위해 작성되었습니다.지적하실 내용이 있다면, 언제든 댓글 또는 메일로 알려주시기를 바랍니다. 본 포스트 내용은 Stanford CS224w와 Query2Box 논문을 정리하였습니다.들어가기에 앞서추론(reasoning) 이란 ?추론(reasoning)이란, 온톨로지(i.e., knowledge base) 상에 명확하게 표현되어 있지 않은 사실(지식)에 대해 기계가 논리적(i.e., 의미론적(semantic))으로 추론하는 것을 의미한다.온톨로지에서 지식은 논리학을 다루는데, 논리학은 원론적으로 명제논리(propositional logic)를 기반으로 한다. 즉, 논리적 연결사(logical connective)에 의해 참 혹은 거짓을 따질 수 있는 문제에 관한 논리를 다루는 것이다. 이러한 명제논리의 기초 위에 술어논리(predicate logic)가 성립한다. 술어논리는 ‘주어’와 ‘술어’로 구성된 문장에서 ‘주어’에 한정기호를 사용하는 방식으로, 대표적으로는 1차 논리(First-order Logic(FOL))가 있다. 온톨로지 기반의 AI는 1차 논리 계산에 근거하여 정답을 내놓는다.우리는 주어진 상황에 대한 지식을 가지고 새로운 사실을 유도하는 데 익숙해 있다. 실제 우리가 알고 있는 모든 과학적 사실들이 일정한 추론의 틀에서 비롯되었다고 하여도 과언이 아니다. 즉, 추론(reasoning, inference, argument)이란, 이미 알고 있는 명제를 기초로 하여 새로운 명제를 유도하는 과정으로 전제(premise)와 결론(conclusion) 간의 논리적 관계를 다룬다.본 논문은 임베딩 공간에서 벡터로 표현된 KG를 어떻게 추론(reasoning)하는지에 대해서 다룬다. 특히, conjunction(∧), disjunction(∨), existential quantifier(∃) 등으로 복잡하게 표현되는 multi-hop 질의에 대해서도 임베딩 공간에서 결과를 추론할 수 있는 방법론을 제시한다.질의의 유형별 추론KG에서 어떠한 사실을 추론하기 위한 질의는 아래와 같이 나눌 수 있다. One-hop Queries (e.g.) Where did Hinton graduate? Path Queries(Multi-hop Queries) (e.g.) Where did Truing Award winners graduate? Conjunctive Queries (e.g.) Where did Canadians with Turing Award graduate? 기타 (Existential Positive First-order(EPFO) Queries) (e.g.) Where did Canadians with Turing Award or Nobel Graduate? One-hop 질의간단한 One-hop 질의에 대해 임베딩을 활용하여 추론한다면, KG completion의 link prediction 문제를 푸는 방식으로 해결할 수 있다. link prediction은 (h, r, ?) 혹은 (?, r, t)가 주어졌을 때, 누락된 ?를 알아내는 문제이므로 one-hop 질의에 대해 추론할 수 있다.Path 질의Path 질의는 one-hop 질의에서 여러 relation이 추가되어 정답을 찾아가는 경로가 길어진 형태이다. 즉, “Where did Turing Award winners graduate?” 라는 질의에 답을 찾기 위해서는 아래와 같이 “Turing Award”라는 anchor node로부터 “win”과 “graduate” relation을 순회하며 최종적인 정답을 추론해야 한다.그러나 KG는 인간이 입력한 데이터로 구성된 그래프이기 때문에 본연적으로 incomplete하다. 따라서 missing edge에 대한 순회가 제한되기 때문에 추론 결과 또한 제한될 수밖에 없다. 그렇다면 KG completion을 미리 수행하여 완벽한 KG에 대해서 path 질의에 대해 추론하면 되지 않는가? 이 경우, 그래프는 매우 복잡해지므로 그래프를 순회하기 위한 시간 복잡도가 intractable 할 정도로 늘어나게 된다.이처럼, 불완전한 KG에서 path 질의의 정답을 추론하기 위해서는 임베딩을 활용했던 one-hop 추론 방법을 multi-hop에 응용함으로써 가능하다. 이는, anchor node로부터 이어지는 relation들을 질의 q로 정의하고, q를 임베딩하는 방식이다. 이때 질의 벡터 q는 entity들의 수와 상관 없이 anchor node 및 relation 벡터들의 단순한 합으로 임베딩한다.이후 과정은 TransE와 유사하다. TransE에서 h + r = t 가 됨을 이용했던 것처럼, 질의 벡터 q는 원하는 추론 결과 근처에 존재하게 될것이므로, q에 대해 nearest neighbor search를 한다면 추론 결과 노드들을 구할 수 있다. 이는 직접 그래프를 순회하지 않고 approximation으로 추론을 하는 방법으로 시간 복잡도가 O(V)로 적다.Conjunctive 질의conjunction(∧)으로 이루어진 복잡한 질의의 경우, 어떻게 KG에서 추론할 수 있을까? “Where did Canadians with Turing Award graduate?” 질의를 예로 들어보자.만약, KG가 complete 하다면, 위와 같이 순회를 함으로써 쉽게 답을 구할 수 있겠으나, 언제나 그렇듯 KG는 항상 incomplete하다. 따라서 이 또한 path 질의에서와 같이 질의 자체를 벡터로 임베딩함으로써 정답을 approximation 하는 방법으로 접근해 볼 수 있다.위와 같이 anchor node들인 “Turing Award”와 “Canada”에서 각각의 질의 벡터를 통해 q1과 q2 지점으로 projection을 완료했다. 즉, 두 지점 사이의 ‘어떠한 지점’(i.e., intersection)이 바로 두 질의의 공통된 부분에 해당되므로 해당 지점의 근처가 논리적으로 질의들의 conjunction을 구현한 부분이 된다. 그렇다면 ‘어떠한 지점’은 어떻게 구할 수 있을까?벡터들의 intersection은 아래와 같이 DeepSets으로 구현한 neural intersection operator J를 통해 구할 수 있다. 즉, DeepSets 모델에 인풋으로 질의 임베딩을 넣으면, 아웃풋으로 질의의 intersection 임베딩 벡터가 나오는 형태이다.이처럼 intersection 임베딩 벡터로 ‘어떠한 지점’을 구하고 해당 지점에서 남은 경로마저 approximation 한 후, nearest neighbor search를 수행하면, conjunctive 질의에 대한 최종적인 추론이 가능하다.Query2BoxBox Embedding지금까지는 질의(i.e., 그래프 상에서의 relation)를 하나의 벡터로 임베딩하여 정답을 approximation하여 추론하였다. 그러나, Query2Box 논문은 질의를 기하학적인 box로 임베딩을 한다. box는 hyper-rectangle로 표현되며, box 형태의 질의 임베딩은 아래와 같이 정의된다.(강의 자료 및 원 논문을 함께 정리하는 본 글은 원 논문과 약간의 notation 차이가 있다.)$\\mathbf{q}=(Center(\\mathbf{q}), Offset(\\mathbf{q}))\\in \\mathbb{R^{2d}}$이때 Center는 box의 중심 좌표를, Offset은 해당 축에서 box의 중점으로부터 모서리까지의 길이(즉, 너비(?))를 의미하고, 각각 d 차원의 벡터로 표현된다.위와 같이 box 임베딩을 활용한다면, 질의가 임베딩 공간에 projection되는 부분이 ‘어떠한 지점’이 아닌 ‘어떠한 영역’으로 표현된다. 즉, 질의의 결과에 해당하는 entity들을 모두 포함하는 영역이 되는 것이다.box 형태로 질의를 임베딩한다면, intersection 연산을 잠재 공간 상에서 기하학적으로 수행할 수 있다. 단순히 질의 box들이 겹치는 부분들이 intersection(i.e., conjunction)인 것이다. 매우 직관적이라는 장점이라고 할 수 있다.box 임베딩을 학습하기 위한 파라미터는 다음과 같다.1) entity embeddings : d 차원 각각의 entity는 offset이 0인 box로 본다. 즉, box 형태가 사라져 점으로만 표현되는 느낌이다.2) relation(i.e., query) embeddings : 2d 차원 최초의 entity에 대한 box는 (v 벡터, 0 벡터)로, d차원의 v벡터를 중점으로 크기가 0인 box로 볼 수 있다. 각각의 relation(질의)은 box 형태를 input으로 받아 새로운 box를 output으로 낸다. 3) intersection operator φ and β intersection을 수행하는 DeepSets 모델에 존재하는 파라미터로, 그래프의 크기가 어떠한지와 관계없이 φ와 β의 파라미터 수는 독립적이다. 벡터를 대상으로 intersection을 수행하지 않고, box를 대상으로 intersection을 수행한다. box 임베딩에 대해서 더욱 구체적으로 살펴보자.Geometric Projection Operatorgeometric projection은 질의 벡터 r(i.e., relation)을 통해 기존의 box q(c.f., 단일 entity 또한 크기 0인 box)가 공간상에서 새로운 box q’으로, 기하학적으로 projection되는 과정을 말한다. 이를 수식으로 표현하면 다음과 같다.(강의 자료 및 원 논문을 함께 정리하는 본 글은 원 논문과 약간의 notation 차이가 있다.)$Center(\\mathbf{q'})=Center(\\mathbf{q})+Center(\\mathbf{r})$$Offset(\\mathbf{q'})=Offset(\\mathbf{q})+Offset(\\mathbf{r})$이 때 offset은 항상 0보다 크거나 같으므로, 질의 벡터 r에 의해 새로이 projection되는 box는 항상 기존의 box의 크기와 같거나 커지게 된다. 생각해보면, box가 계속해서 커져야 더 많은 entity들을 포함시킬 수 있으니 당연한 것이다.질의 벡터로 새로이 box를 projection하면, 위와 같이 box가 겹치는 intersection이 생길테고, 그것이 바로 논리적으로는 conjunction에 해당하는 것이다. 그렇다면, 공간 상에 존재하는 이 intersection을 어떻게 집어낼 것인가?Geometric Intersection Operatorgeometric intersection operator는 이러한 box들의 intersection을 모델링한다.위 그림에서와 같이, box들이 겹치는 영역에 대해 intersection(i.e., conjunction)이 구현된 새로운 box로 정의하기 위해서는 box의 정의에 따라 새로운 box에 대한 center와 offset을 구해야 한다.1) intersection box 영역에서의 center새로운 box의 center의 경우, 위 그림과 같이 intersection을 구하고자 하는 box들의 center들을 이어 만든 빨간색 영역 안에 존재해야 한다. Query2Box 논문에서는 해당 영역에서 새로운 box의 center를 구하기 위해서 기존 box들의 center들을 대상으로 self-attention 메커니즘을 적용하여 계산한다. 이를 수식으로 나타내면 아래와 같다.(강의 자료 및 원 논문을 함께 정리하는 본 글은 원 논문과 약간의 notation 차이가 있다.)$ Center(\\mathbf{q_{inter}}) = \\sum_iw_i\\odot Center(\\mathbf{q_i})$$w_i={\\cfrac {exp(MLP(Center(\\mathbf{q_i})))} {\\sum_jexp(MLP(Center(\\mathbf{q_j})))}}$$where \\ \\ Center(\\mathbf{q_i}) \\in \\mathbb{R^d} ,\\ w_i \\in \\mathbb{R^d} \\ and \\ \\odot is \\ the \\ element-wise \\ product$이 때, $MLP(\\cdot)$는 multi layer perceptron을, $w_i$는 attention weight를 의미한다. (c.f., 원 논문에서는 attention weight를 구하기 위해서 $\\mathbb{R^d}$차원인 $Center(\\mathbf{q_i})$ 대신 $\\mathbb{R^{2d}}$차원인 $\\mathbf{q_i}$ 를 $MLP$의 input으로 간주한다. 이때의 $MLP$는 $\\mathbb{R^{2d}}\\rightarrow\\mathbb{R^d}$로의 함수이다.)2) intersection box 영역에서의 offset새로운 box의 offset 또한 구해보자. intersection box의 offset은 반드시 intersection을 수행하려는 input box들의 offset보다 작아야 한다. 그 이유는, 앞서 질의 벡터를 활용한 projection으로 box를 키움으로써 많은 후보 entity들을 box 안에 포함시켰으니, 그 중에서 conjunction에 해당하는 entity들만 추려내야 하기 때문이다. offset을 구하기 위한 과정은 약간 더 복잡한데, 그 과정은 아래와 같다.(강의 자료 및 원 논문을 함께 정리하는 본 글은 원 논문과 약간의 notation 차이가 있다.)$Offset(\\mathbf{q_{inter}})=Min(Offset(\\mathbf{q_1}), \\ldots,Offset(\\mathbf{q_n})) \\odot \\sigma(DeepSets(\\{Offset(\\mathbf{q_1}), \\ldots, Offset(\\mathbf{q_n})\\}))$$where \\ \\sigma(\\cdot) \\ is \\ the \\ sigmoid \\ function $이때 $DeepSets({\\mathbf{x_1, \\ldots, x_N}})=MLP((1/N) \\ \\cdot \\ \\sum_{i=1}^N MLP(\\mathbf{x_i}))$로 정의할 수 있는데, 즉 input box들의 offset에 대한 평균적인 representation을 $MLP$로써 뽑아내는 기능을 수행한다. 이는 sigmoid $\\sigma(\\cdot)$ 함수를 거쳐서 (0, 1)의 output 범위를 가지게 되며 input box의 offset 중 최솟값과 곱해지는데, 이러한 과정에서 intersection box의 offset은 반드시 input box의 offset보다 작은 값을 가질 수 있게 된다.이 모든 과정을 거쳐서 구한 intersection 영역의 center와 offset은 아래와 같이 임베딩 공간에서 conjunction의 기능을 수행하게 된다.Entity-to-box Distance그렇다면 projection을 통해서 box $\\mathsf{q}$를 구했을 때, $\\mathsf{q}$와 실제 우리가 추론하고자 했던 entity들은 공간 상에서 얼마나 가까운 곳에 존재할까? Query2Box는 query box $\\mathsf{q}\\in\\mathbb{R^{2d}}$와 entity vector $\\mathsf{v}\\in\\mathbb{R^d}$ 가 주어졌을 때, 아래와 같이 그 거리를 정의한다.(강의 자료 및 원 논문을 함께 정리하는 본 글은 원 논문과 약간의 notation 차이가 있다.)$dist_{box}(\\mathsf{q, v})=dist_{outside}(\\mathsf{q, v})+\\alpha \\ \\cdot \\ dist_{inside}(\\mathsf{q, v})$$where \\\\ \\mathsf{q_{max}}=Center(\\mathsf{q})+Offset(\\mathsf{q}) \\in\\mathbb{R^d} , \\ \\ \\mathsf{q_{min}}=Center(\\mathsf{q})-Offset(\\mathsf{q}) \\in\\mathbb{R^d}$$and \\ \\ 0\\lt\\alpha\\lt1 \\ is \\ a \\ fixed \\ sclar$이때 $dist_{outside}$는 box 바깥에 위치한 entity 벡터의 위치부터 box의 가장 가까운 모서리까지의 거리를, $dist_{inside}$는 box 내부에 위치한 entity 벡터의 위치부터 box의 중점까지의 거리를 의미하며 아래와 같이 표현된다.(강의 자료 및 원 논문을 함께 정리하는 본 글은 원 논문과 약간의 notation 차이가 있다.)$dist_{outside}(\\mathsf{q,v})= \\lVert Max(\\mathsf{v-q_{max}, 0})+Max(\\mathsf{q_{min}-v, 0}) \\rVert_1 \\ ,$$dist_{inside}(\\mathsf{q,v})= \\lVert Center(\\mathsf{q})-Min(\\mathsf{q_{max}}, Max\\mathsf{(q_{min}, v})) \\rVert_1$독특한 점은, 거리를 구하는 식 $dist_{box}(\\mathsf{q, v})=dist_{outside}(\\mathsf{q, v})+\\alpha \\ \\cdot \\ dist_{inside}(\\mathsf{q, v})$에서 $dist_{inside}$ 앞에 $\\alpha$가 붙는다는 것이다. 왜일까? 이는 entity 벡터가 box 안에 존재할 때는 query box의 중점과 “충분히” 가깝기 때문에 그 거리에는 downweight를 가하는 것이다. 즉, 이때의 $dist_{outside}$는 0의 값을 가지며, $\\alpha$의 값만큼 scale된 $dist_{inside}$의 값으로만 거리에 대한 값이 결정된다.Training Objective질의에 대해서 추론하고자 하는 사실(i.e., entity 벡터)과 질의에 대한 projection인 box 사이의 거리인 $dist_{box}$를 계산할 수 있게 되었다. 그렇다면 이제부터는 질의와 그에 대한 정답이 학습 데이터셋으로 존재할 때, 목적함수인 loss function을 정의함으로써 Query2Box를 학습할 수 있다. loss function은 다음과 같다.(강의 자료 및 원 논문을 함께 정리하는 본 글은 원 논문과 약간의 notation 차이가 있다.)$\\mathcal{L}=-log \\ \\sigma(\\gamma-dist_{box}(\\mathsf{q,v}))-\\sum_{i=1}^k {1 \\over k} log \\ \\sigma(dist_{box}(\\mathsf{q, v_j'})-\\gamma),$$where \\ \\gamma \\ represents \\ a \\ fixed \\ scalar \\ margin,$$v \\in \\lbrack q \\rbrack \\ is \\ a \\ positive\\ entity,$$v_j'\\notin \\lbrack q \\rbrack \\ is\\ the\\ i-th\\ negative\\ entity$$and\\ k\\ is\\ the\\ number\\ of\\ negative\\ entities.$위의 그림을 보면(수식은 약간 다르지만 결국 같은 이야기다.), (왼쪽)질의에 대해 정확한 정답에 해당하는 벡터 $v$는 query box와의 거리가 가까울수록 box에 포함될 수 있으므로 $dist_{box}$를 최소화하는 쪽으로 최적화된다. 반면에, (오른쪽)질의에 대한 오답으로 형성된 벡터 $v’$은 query box와 거리가 멀수록 box에 포함되지 않을 수 있으므로 $dist_{box}$를 최대화 하는 방향으로 최적화된다.또한 $\\gamma$는 TransE에서와 같이 margin을 의미한다. 그림의 왼쪽의 경우, $\\gamma$보다 작은 영역은 loss가 매우 작으므로, $\\gamma$보다 작은 영역에서 loss 값이 형성되는 것을 penalize 하여 loss를 부풀린다. 반대로, 오른쪽의 경우, $\\gamma$보다 큰 영역이 매우 작은 loss 값을 가지므로, 해당 영역부터 penalize 하여 loss를 부풀린다.Tractable Handling Of Disjunction Using Disjunctive Normal Form(DNF)지금까지는 path 질의, conjunctive 질의를 효과적으로 box를 이용하여 추론하였다. 그러나 우리가 다루어야 할 질의들은 이 외에도 disjunction(∨), existential quantifier(∃) 등 더욱 복잡한 논리가 표현되어 있을 수 있다. 이러한 질의를 Existential Positive First-order(EPFO) 질의라 부른다.EPFO 질의처럼 disjunction이 포함된 질의를 처리할 수 있는 가장 직관적인 방법은 기하학적인 box에 대해 union 연산을 수행하는 것이다. 즉, entity set ${S_1, S_2, \\cdots, S_n}$이 주어졌을 때 $\\cup_{i=1}^nS_i$를 수행하는 것이다. 하지만, 임베딩 공간 상에서 box(혹은 entity)는 어디에나 존재할 수 있다. 따라서 현실적으로 box에 대해서 union을 취하는 연산은 간단한 box의 형태가 아닐 것이다. 즉, box에 대한 union 연산은 닫혀있지 않다.이러한 문제를 다루기 위해서, Query2Box는 EPFO 질의를 논리적으로 동치 관계인 Disjunctive Normal Form(DNF)으로 변환할 것을 제안한다.여기서 잠깐! DNF의 정의를 잠깐만 간단하게 짚고 가보자. 명제논리에서 “atomic sentence”란 참 또는 거짓으로 표현할 수 있는 단 하나의 명제로 구성되어 있는 최소 단위 문장을 의미한다. 이때 atomic sentence를 “literal”이라고 부르는데, not을 의미하는 negation(¬) 기호가 없는 경우를 positive literal, negation 기호가 있는 경우를 negative literal이라 부른다. DNF란, “(literal들의 conjunction들)에 대한 disjunction”으로 이루어진 형태를 뜻하며 그 예는 아래와 같다. ${\\displaystyle (A\\land \\neg B\\land \\neg C)\\lor (\\neg D\\land E\\land F)}$ ${\\displaystyle (A\\land B)\\lor C}$ $A\\land B$ ${\\displaystyle A}$즉, Query2Box의 제안대로 1차 논리(First-order Logic(FOL))를 DNF로 전환하는 것은 결국 conjunction 질의들에 대하여 마지막 과정에서 단 한번의 disjunction, 즉, 단 한번의 union 연산만을 수행하는 것을 의미한다.Transformation to DNF모든 1차 논리는 논리적으로 동치인 DNF 형태로 변환할 수 있다(Davey &amp; Priestley, 2002). Query2Box 논문에서는 아래와 같이 computation graph의 space 상에서 직접 모든 union 연산을 최후의 step으로 옮김으로써 DNF를 구현하였다.다시 말하자면, conjunctive query들을 먼저 임베딩 한 후, 이를 마지막 단계에서 aggregate 하는 방식을 쓴다는 것이 핵심이다.Aggregation앞서 정의했듯이 conjunctive 질의를 box $\\mathbf{q_i}$라고 표현한다면, DNF 형태로 수식을 표현하자면 아래와 같다.$ DNF \\ \\mathsf{q}=\\mathsf{q_1}\\lor\\mathsf{q_2}\\lor\\cdots\\lor\\mathsf{q_m} $만약 우리가 추론하고자 하는 정답 $v$가 conjunctive 질의 $\\mathbf{q_i}$ 중 하나의 정답이라면, 이는 곧 논리적으로 $\\mathbf{q}$의 정답이라고 볼 수 있다. 즉, $v$가 conjunctive 질의 $\\mathbf{q_i}$ 중 어느 하나와 임베딩 공간 상에서 가까이 위치한다면, $v$는 궁극적으로 $\\mathbf{q}$와 가깝다. 따라서 DNF를 적용할 경우, 목적식인 거리 함수는 다음과 같이 정의된다.$dist_{agg}(\\mathsf{q,v})=min(dist_{box}(\\mathsf{q_{1},v}),dist_{box}(\\mathsf{q_{2},v}),\\cdots,dist_{box}(\\mathsf{q_{m},v}))$" }, { "title": "Matrix Factorization Techniques for Recommender Systems", "url": "/posts/Matrix-Factorization-Techniques-for-Recommender-Systems/", "categories": "Recommender System", "tags": "Matrix Factorization, Recommender System", "date": "2022-05-10 00:00:00 +0900", "snippet": "이 포스트는 개인적으로 공부한 내용을 정리하고 필요한 분들에게 지식을 공유하기 위해 작성되었습니다.지적하실 내용이 있다면, 언제든 댓글 또는 메일로 알려주시기를 바랍니다. 본 포스트 내용은 Matrix Factorization Techniques for Recommender Systems을 번역한 글입니다.00. AbstractNetflix Prize competition에서 알 수 있듯, matrix factorization 기법은 implicit feedback, temporal effects, confidence level 등 부수적인 정보들을 아우를 수 있다는 점에서 전통적인 방식보다 제품을 추천하는 데 용이하다.01. Recommender System Strategies01-1. 추천시스템의 두 종류 : content filtering과 collaborative filtering추천시스템은 크게 content filtering과 collaborative filtering 두 종류로 구분할 수 있다.먼저, content filtering 방식부터 살펴보자. content filtering 방식은 콘텐츠가 유저에게 잘 추천될 수 있도록, 유저에 대한 profile과 콘텐츠에 대한 profile을 만들어 활용한다. 예를 들어, ‘유저’ profile의 경우, 인구통계학적 정보라든지 어떤 설문에 대한 답변 등으로 구성할 수 있을 것이다. 또한 ‘영화’ 콘텐츠의 profile 경우, 장르, 출연배우, 인기도, … 등으로 구성할 수 있을 것이다. 프로그램은 이렇게 구성한 profile 들을 기반으로 유저와 콘텐츠(product)를 매칭시키는 것이다. 물론, 이러한 content-based 전략도 위처럼 정의한 profile 정보 이외에도 쉽게 수집하기 어려운 외부 정보들까지 활용하기도 한다.content filtering 방식을 성공적으로 구현한 대표적인 사례로는 인터넷 라디오 서비스인 Pandora.com에서 활용되었던 Music Genome Project가 있다. 이를 구현하기 위해서, 숙련된 음악 분석가가 Music Genome Project의 음악들을 수백여개의 음악적 특징들을 기반으로 하여 스코어링을 했었다. 이렇게 구성한 정보들은 각 곡의 음악적 특징 뿐만 아니라, 청취자의 음악적 취향과 상당한 관계가 있는 요소들까지도 아우른다.위와 같은 content filtering 방식은 explicit한 profile을 만들어야만 한다. 이에 반해, content filtering의 대안이 되는 collaborative filtering 방식은 explicit한 profile 대신, 유저의 지난 거래정보나 평점 등 과거 행동만을 활용하여 추천한다. 즉, 특정 제품에 대하여 유저가 매겼던 평점 등 과거 정보와 해당 유저 사이의 상호관계성을 분석하고, 이를 토대로 새로이 유저-아이템 간의 관계를 발견하는 것이다.collaborative filtering은 특정 도메인에 종속되지 않을 뿐만 아니라, explicit한 profile을 구성하지 않아도 되기 때문에 profile을 구성해야만 하는 content filtering 방식의 한계를 극복할 수 있는 장점이 있다. 한편, content-based 방식보다 잘 작동한다는 장점이 있지만, 새로운 제품과 유저 간의 관계를 시스템이 알기 어렵기 때문에 `cold start 문제가 존재한다는 단점도 있다.01-2. Collaborative filtering의 두 종류 : neighborhood methods와 latent factor modelscollaborative filtering은 neighborhood methods와 latent factor model로 구분지어 볼 수 있다.먼저, neighborhood methods` 아이템들끼리의 이웃관계 또는 유저들끼리의 이웃관계를 중점적으로 고려한다. 아이템끼리의 관계를 고려하는 경우, 동일한 유저에 의해 평점이 매겨진 ‘이웃 아이템’들에도 유저의 선호도가 반영되어 있다고 본다. 즉, 동일한 유저에 의해서 유사한 평점을 받을 가능성이 있는 제품이 바로 ‘해당 제품의 이웃’이 되어 추천되는 것이다. ‘라이언 일병 구하기’를 예로 들어보자. 이 영화의 이웃은 전쟁 영화일수도, 스필버그의 영화일수도, 톰 행크스의 영화일수도 , …, 있을 것이다. 그래서 라이언 일병 구하기에 대한 해당 유저의 평점을 예측하기 위해서는 이 유저가 실제로 매긴 최근접 이웃 영화들을 살펴보아야 한다.유저들끼리의 이웃관계를 고려할 경우, 아래 그림처럼 유저들이 서로의 평점 정보를 보완해줄수도 있다.즉, 위 그림을 해석해보자면, Joe가 왼쪽 세 영화를 좋아하는 경우 Joe를 위한 추천을 하고자 한다면, 추천시스템은 ‘Joe가 좋아한 세 영화를 모두 좋아하는 유저’들을 ‘Joe와 유사한 유저’로 간주하여 그들이 좋아한 영화를 추천할 것이다. 여기서는 Joe가 좋아하는 영화를 모두 본 3명의 유저 중 2명이 좋아한 영화 Dune이 Joe에게 추천될 것이다.latent factor models는 사용자와 아이템을 잠재적인 요인(factor)들을 사용해서 나타낼 수 있다고 보는 모델로 neighborhood methods의 대안이 된다. 어떤 의미로 본다면, 위 content filtering 방식에서 숙련된 음악 분석가가 직접 음악의 특징들을 고려하여 평점을 매겼던 것을 대체하는 방식이라고 볼수도 있겠다. 영화를 예로 든다면, 이 factor들은 어떤 장르인지, 액션 요소는 얼마나 많은지, 아이들이 볼 수 있는 영화인지 등을 나타낼 것이고, 하나의 차원(dimension)으로써 표현될 것이다. 또한, 만약 유저로 예로 든다면, 각각의 factor들은 특정 유저가 해당 영화를 얼마의 score 만큼 좋아하는지를 표현한다고 볼 수 있겠다.아래 그림은 두 차원으로 간단하게 latent factor models의 아이디어를 표현한 것이다. 한 축은 여성-남성을 나타내는 차원의 축이고, 다른 한 축은 현실적(serious)-이상적(escapist) 성향을 나타내는 차원의 축이다. 이러한 모델에서는, 어떤 영화에 대해서 유저가 예측한 평균 평점은 그래프 상에서 영화와 유저의 벡터 내적이라고 볼 수 있겠다. 예를 들어, Gus는 영화 Dumb and Dumber를 좋아할 것으로 보이고, The Color Purple은 싫어할 것으로 보인다. 영화 Oceans 11과 유저 Dave는 두 차원의 중간 쯤 위치한 것으로 보아, 두 차원에 대해서는 중립적인 성향을 보이는 것으로 해석할 수 있다.02. Matrix Factorization Methodslatent factor 모델을 가장 성공적으로 구현한 사례가 바로 matrix factorization 모델이다. matrix factorization 모델은 아이템 평점 패턴으로부터 추론된 요인 벡터로 유저와 아이템을 표현하며, 유저와 아이템 요인 간 상호관계가 높을 때 추천으로 이어지게 된다. matrix factorization은 정확도가 높으며 확장성이 뛰어나서 많이 활용되는 방식이며, 무엇보다도 현실세계의 상황을 모델링하는 데 유연성있게 적용될 수 있어서 매우 효과적이다.추천시스템의 입력 데이터는 유저를 나타내는 차원과 아이템 선호도를 나타내는 다른 차원으로 구성된 행렬로 이루어져 있다. 추천시스템 데이터로 활용하기에 가장 편리한 데이터는 단연코 유저가 특정 제품에 자신의 선호도를 대놓고 표현한, 높은 퀄리티의 explicit feedback일 것이다. 이러한 데이터를 수집하기 위해서 많은 기업들이 별점과 좋아요 등을 수집하는 것이다. 그런데 대개, explicit feedback을 표현하는 행렬은 sparse하다. 왜냐하면 대부분의 유저들은 전체 수많은 아이템들 중 매우 일부분에 대해서만 평점을 부여하기 때문이다.matrix factorization의 가장 큰 강점 중 하나는 explicit feedback 이외의 여러 부가정보들을 통합하여 활용할 수 있다는 점이다. explicit feedback을 수집하기 어려운 상황에서, 추천시스템은 유저의 행동, 구매 내역, 검색 내역, 검색 패턴, 마우스의 움직임 등 implicit feedback으로 유저의 선호를 파악할 수 있다. 이러한 implicit feedback은 일반적으로 dense한 행렬로 표현될 수 있다.03. A Basic Matrix Factorization Modelmatrix factorization models는 유저-아이템을 $f$ 차원의 joint latent factor space(결합 잠재 요인 공간)에 근사한다. 이때, 유저와 아이템 간 상호작용은 공간 상에서 두 벡터의 내적으로 모델링된다. 즉, 각각의 아이템 $i$는 벡터 $q_i∈ℝ^f$로 표현되며, 각각의 유저는 벡터 $p_u∈ℝ^f$로 표현된다. 아이템 $i$ 에 대하여, 벡터 $q_i$의 element들은 해당 item들이 얼마나 긍정적인지, 부정적인지를 나타낸다고 볼 수 있다. 마찬가지로, 유저 $u$ 에 대하여, 벡터 $p_u$의 element들은 해당 유저가 얼마나 해당 아이템을 선호하는지, 긍부정의 정도를 내포하고 있다. 따라서 두 벡터의 내적 $q^T_ip_u$는 유저 $u$와 아이템 $i$의 상호작용(interaction), 즉, 유저 $u$의 아이템 $i$에 대한 전반적인 선호도를 내포한다고 볼 수 있겠다. 이렇게 구한 평점에 대한 추정값을 수식으로 표현하면 아래와 같다. 💡 (수식 1) $\\hat{r}_{ui}=q^T_ip_u$그렇다면, 각각의 아이템과 유저를 요인 벡터 $q_i,p_u∈ℝ^f$로 어떻게 mapping 할까? 이러한 mapping 작업만 잘 마무리할 수 있다면, 추천시스템은 어떠한 아이템이든 유저가 매길 평점을 쉽사리 예측해낼 수 있을텐데 말이다.그 방법은 information retrieval(IR) 분야에서 latent semantic factor를 발견하는 데 활용되는 기술인 singular value decompoistion(SVD) 모델과 큰 관련이 있다. 하지만 문제가 있다. SVD를 collaborative filtering 도메인에 적용하기 위해서는 유저-아이템 평점 행렬을 factoring 해야하지만, 유저-아이템 행렬은 sparse한 경우가 매우 많아서 전통적인 SVD를 그대로 적용하기 어렵기 때문이다. 그리고 행렬 내 우리가 알고 있는 정보들만을 대상으로 적용한다고 하더라도 과적합이 일어나기 일쑤다.기존 시스템은 비어있는 평점들을 채워서 평점 행렬을 최대한 dense하게 만들어 활용하려고 노력했다. 그러나, 이러한 방법은 데이터가 상당히 많아진 오늘날 적용하기에 대단히 수고로운 작업일 것이다. 정확하지 않은 방식으로 행렬을 dense하게 채워넣는 것은 상당한 정보를 왜곡하는 행동이기도 하다. 따라서 최근에는 관측된 평점만을 직접 활용하되, 과적합을 줄일 수 있는 정규화(regularized) 모델을 활용한다. 따라서 요인 벡터 $q_i,p_u∈ℝ^f$를 학습하기 위해서, 추천시스템은 관측된 평점들에 대해서 regularized squared error를 최소화 하는 방식을 활용한다. 💡 (수식 2) $\\min\\limits_{q^{\\star},p^{\\star}}\\sum\\limits_{(u,i)\\in \\kappa}(r_{ui}-q_{i}^{T} p_{u})^{2}+\\lambda(\\lVert q_{i}\\rVert^{2}+\\lVert p_{u}\\rVert^{2})$이때, $κ$는 평점을 알고 있는 $r_{ui}$에 대한 학습데이터 $(u, i)$ 쌍의 셋이다.추천시스템은 과거로부터 관측된 평점으로 모델을 학습한다. 그런데 우리가 풀고자 하는 문제는 이를 일반화하여 미래에 미지의 평점을 예측하는 것이다. 따라서 추천시스템은 정규화를 통해서 과적합을 피하는 방식으로 학습을 하는데, 위 수식에서 상수 $\\lambda$가 정규화의 강도를 조정하는 상수가 되겠다.04. Learning Algorithms(수식 2)를 최소화 하는 방법으로는 stochastic gradient descent(SGD)와 alternating least squares(ALS) 두 가지가 있다.04-1. Stochastic Gradient Descent먼저, prediction error는 아래와 같이 평점을 알고 있는 $r_{ui}$와 유저 및 아이템의 요인벡터를 내적한 값의 차이로 정의한다. 💡 (수식 3) $e_{ui}\\,\\overset{def}{=}\\,r_{ui}-q^T_ip_u$이를 참고하여 아래와 같이 학습률 $\\gamma$의 정도만큼 기울기의 반대 방향으로 파라미터를 변경해간다. 💡 (수식 4) $q_i \\leftarrow q_i + \\gamma \\cdot (e_{ui} \\cdot p_u - \\lambda \\cdot q_i )$ 💡 (수식 5) $p_u \\leftarrow p_u + \\gamma \\cdot (e_{ui} \\cdot q_i - \\lambda \\cdot p_u )$이 방식은 상대적으로 빠른 running time으로 구현이 가능하지만. 때로는 ALS 최적화 기법이 유리할 때도 있다.04-2. Alternating Least Squares요인 벡터 $q_i,p_u$는 미지수이므로 convex하지 못하다. 그러나 두 미지수 중 하나를 고정한다면, 최적화 문제는 2차(quadratic)식 문제가 되어 최적으로 풀 수 있게 된다. 따라서 ALS 기법은 $q_i$와 $p_u$를 번갈아가며 고정하여 문제를 푼다. 예를 들어, $p_u$를 고정할 땐 $q_i$를 least square 문제로 계산한다. 이러한 방식으로 (수식 2)가 최소로 수렴할 수 있다.05. Adding Biasescollaborative filtering에서 matrix factorization을 활용하는 데 이점으로는 다양한 데이터 및 기타 어플리케이션의 요구사항들을 활용할 수 있다는 점에서 유연하다는 것이다. 그러나 문제가 있다. (수식 1)은 유저와 아이템 간 상호작용을 내포하기는 하지만, 실제 현실적으로는 유저 또는 아이템과 관련한 평점이 일관적이지 않을 수 있다. 같은 대상을 평가하더라도 어떤 사람은 후하게, 어떤 사람은 박하게 평가할 수 있기 때문이다. 이러한 것을 bias(또는 intercepts)라고 부른다.이러한 이유로 (수식 1)을 진짜 평점이라고 여기는 것은 무리가 따른다. 즉, (수식 1)과 더불어 bias까지 고려해주어야 하는 것이다. 💡 (수식 6) $b_{ui}=\\mu + b_i + b_u$(수식 6)을 살펴보자. 평점 $r_{ui}$의 bias는 $b_{ui}$로 표기한다. 전체 평점의 평균은 $\\mu$로, $b_{u}$와 $b_{i}$는 각각 유저와 아이템의 평균으로부터 얻어진 편차로 볼 수 있다.복잡하니, 예를 들어보자. Joe라는 유저가 영화 타이타닉에 어떤 평점을 주었는지 예측하고 싶다고 해보자. 존재하는 모든 영화의 평균 평점이 3.7이라고 하면, 이것이 바로 $\\mu$ 값이 된다. 이제 타이타닉의 평점을 보았더니, 평균보다 0.5 만큼 평점이 높았다고 하자. 그리고 Joe는 까다로운 사람이라서 평균 평점보다 0.3만큼 낮게 평점을 부여했다고 하자. 그러면 영화 타이타닉에 대한 Joe의 bias는 (3.7 + 0.5 - 0.3)으로 3.9가 된다. 💡 (수식 7) $\\hat{r}_{ui} = \\mu + b_i + b_u +q^T_ip_u$이제는 (수식 7)과 같이 평점의 추정값이 더욱 구체화되었다. 즉, 실제 평균, 유저 bias, 아이템 bias, 그리고 유저-아이템의 상호작용을 내포하는 요인 벡터의 내적으로 구성된 것이다. 이로써 목적식을 재구성하면 아래와 같다. 💡 (수식 8) $\\min\\limits_{q^{\\star},p^{\\star}, b^{\\star}}\\sum\\limits_{(u,i)\\in \\kappa}(r_{ui}-\\mu-b_u-b_i-q_{i}^{T} p_{u})^{2}+\\lambda(\\lVert q_{i}\\rVert^{2}+\\lVert p_{u}\\rVert^{2} + {b_u}^2 +{b_i}^2)$06. Additional Input Sources앞서 언급했듯 추천시스템은 초창기에 평점 정보를 얻기 어려우므로 cold start 문제가 존재할 수 있다. 이 경우, 유저에 대한 추가적인 정보를 제공해줌으로써 문제를 해결할 수 있는데, 이때 활용할 수 있는 것이 바로 implicit feedback 이다. implicit feedback은 유저가 직접적으로 explicit 한 평점을 부여하지 않더라도 유저의 행동을 통해서 파악할 수 있다. 예를 들어, 매장에서 고객이 무엇을 구매했는지 내역을 보면 해당 고객의 경향을 파악할 수 있을 것이다.간단하게, 0과 1(boolean)로 implicit feedback을 받는다고 가정해보자. 이때 유저 u가 표한 implicit feedback을 표현한 아이템의 집합을 $N(u)$라고 표기한다고 해보자. 이제 아이템에 대해 implicit feedback을 표현했을 때 유저를 아래와 같이 정의할 수 있다. 💡 (수식 9) $\\sum\\limits_{i\\in N(u)}x_i$이때 새로운 요인(factor) 벡터는 $x_i∈ℝ^f$ 이다. 즉, 아이템 벡터와 동일한 $f$ 차원만큼 0과 1로 implicit feedback이 부여된 벡터이다. 그리고 이를 아래와 같이 정규화한다. 💡 (수식 10) ${|N(u)|}^{-0.5}\\sum\\limits_{i\\in N(u)}x_i$또 하나 사용할 수 있는 정보는 인구통계학 정보와 같이 이미 알려져있는 유저의 속성 정보이다. 이 또한 위와 같이 간단하게 0과 1의 boolean 속성으로 표현할 수 있다고 한다면, 유저 u에 대해 성별, 연령대, 우편번호, 연봉 등으로 $A(u)$라는 집합을 정의할 수 있겠다. 마찬가지로 이에 대한 새로운 요인 벡터 $y_a∈ℝ^f$를 통해서 아래와 같이 유저를 표현할 수 있다. 💡 (수식 11) $\\sum\\limits_{i\\in A(u)}y_a$위의 정보들을 종합하여 matrix factorization 모델을 더욱 풍부하게 표현할 수 있다. 💡 (수식 12) $\\hat{r}{ui} = \\mu + b_i + b_u +q^T_i \\left[ p_u + |N(u)|^{-0.5}\\sum\\limits{i\\in N(u)}x_i + \\sum\\limits_{i\\in A(u)}y_a \\right]$07. Temporal Dynamics지금까지는 평점 정보 등 모든 정보가 정적으로 정해져있다는 가정 하에서 계산을 하였지만, 실제로는 제품에 대한 인지도, 인기도 등이 수시로 변하며, 사용자의 선호도 또한 바뀐다. 그러므로 추천시스템이 시시각각 변하는 정보들 또한 반영할 수 있어야 한다.matrix factorization 기법은 그 자체로 시시각각 변하는 선호도에 대해서 정확도를 높이기에 적합하다. 위 수식들에서와 같이 평점에 대한 추정값을 여러 term으로 쪼개는 방식 덕에 시시각각 변하는 정보들 또한 쉽게 표현할 수 있다. 구체적으로, 아이템 bias ($b_i(t)$), 유저 bias($b_u(t)$), 유저 선호도($p_u(t)$)가 시시각각 달라지는 term이라 할 수 있다.이처럼 시간에 따라 변하는 term으로 평점에 대한 추정 값을 재구성해보면 아래와 같이 표현할 수 있다. 💡 (수식 13) $\\hat{r}_{ui}(t) = \\mu + b_i(t) + b_u(t) +q^T_ip_u(t)$08. Inputs with Varying Confidence Levels사실 모든 평점들이 동일한 가중치나 신뢰도를 가지지는 않는다. 예를 들어, 특정 아이템에 대해서 엄청나게 광고를 하면, 단기적으로 평점이 달라질 수 있다. 그리고 적대적인 고객이 있는 경우에 특정 아이템에 대해서 평점을 매우 박하게 줄수도 있다.게다가 implicit feedback을 이용하는 시스템의 경우, 현재 유저의 행동을 바탕으로 아이템에 대한 명확한 선호도를 정량적으로 측정하기 어렵기도 하다. ‘이 아이템을 좋아할 것 같…다.?’와 같은 대략적인 정보만 알 수 있을 것이다. 이 경우, 신뢰 점수(confidence score)를 도입하는 것이 효과적일 것이다. 예를 들어, 해당 유저가 얼마나 자주 그 아이템을 구매하였는지와 같이 행동의 빈도를 기반으로한 수치들을 토대로 신뢰도를 구하여 활용할 수 있다. 한번만 있었던 행동은 별 의미가 없겠으나, 반복적으로 일어난 일들에 대해서는 유저의 의도가 반영되어 있을 수 있기 때문이다.matrix factorization 모델은 이러한 신뢰도를 표현하기에도 적합하다. 더욱 의미 있는 사건에 대해서 많은 가중치를 주면 되기 때문이다. 이러한 평점 $r_{ui}$에 대한 신뢰도를 $c_{ui}$라고 표기한다면, 아래와 같은 수식으로 목적식을 표현함으로써 신뢰도를 반영할 수 있다. 💡 (수식 14) $\\min\\limits_{q^{\\star},p^{\\star}, b^{\\star}}\\sum\\limits_{(u,i)\\in \\kappa}c_{ui}(r_{ui}-\\mu-b_u-b_i-q_{i}^{T} p_{u})^{2}+\\lambda(\\lVert q_{i}\\rVert^{2}+\\lVert p_{u}\\rVert^{2} + {b_u}^2 +{b_i}^2)$" }, { "title": "(인과추론의 데이터과학) Bayesian Network의 증명", "url": "/posts/Causal-Bayesian-Network-02/", "categories": "Causal Inference", "tags": "Bayesian Network, Probabilistic Graphical Models", "date": "2022-05-09 00:00:00 +0900", "snippet": "이 포스트는 개인적으로 공부한 내용을 정리하고 필요한 분들에게 지식을 공유하기 위해 작성되었습니다.지적하실 내용이 있다면, 언제든 댓글 또는 메일로 알려주시기를 바랍니다. 본 포스트 내용은 인과추론의 데이터과학, 베이지안 네트워크 (Bayesian Network) 강의를 정리한 것임을 밝힙니다.00. 목표 Causal Graph 상의 $X$와 $Y$가 서로 독립인지 증명을 통해서 확인하고자 함 독립이라면, $X$와 $Y$ 간 Association(i.e., Correlation)이 존재하지 않음 종속이라면, $X$와 $Y$ 간 Association(i.e., Correlation)이 존재함 이를 위해, 두 변수 간의 관계를 $P(X,Y)=P(X)P(Y)$로 표현할 수 있는지 확인하고자 함01. Mediator 원인 변수 $X$는 Mediator M에 영향을 미친 후 결과 변수 $Y$에 영향을 줌 이때 Mediator M을 Conditioning하여 막으면, 정보 흐름이 막히게되어 $X$와 $Y$ 간의 Correlation(Association)이 사라짐$X$와 $Y$ 간에 Association이 있는지 증명 $X$와 $Y$가 서로 독립이 아님을 알고싶기 때문에, (좌변)$P(X,Y) \\neq$ (우변)$P(X)P(Y)$인지 확인하고자 함 (좌변)$P(X,Y)$ $=\\sum_{M}P(X,Y,M)$ M에 대해서 Marginalize하여 표현함 (참고) $P(X,Y,M) = P(X)P(M|X)P(Y|M)$ Bayesian Network Factorization $=\\sum_{M}P(X)P(M|X)P(Y|M)$ $=P(X)\\sum_{M}P(M|X)P(Y|M)$ 정리된 좌변 (설명) $P(X)$는 M에 영향받지 않으므로 (우변)$P(X)(Y)$ $=P(X)\\sum_{M}P(Y,M)$ M에 대해서 Marginalize하여 표현함 $=P(X)\\sum_{M}P(M)P(Y|M)$ 정리된 우변 만약, 정리된 좌변과 정리된 우변이 같다면, $X$와 $Y$는 독립임 즉, 정리된 좌변에서의 $P(M|X)$ 부분과 정리된 우변에서의 $P(M)$부분이 같으면 독립임 그러나, $P(M|X)=P(M)$이기 위해서는 $M{\\bot}X$, 즉, $M$과 $X$가 독립이어야 하지만, $X \\rightarrow$ M $\\rightarrow Y$의 Causal Graph에서 Causal Markov Assumption에 의해 두 변수는 종속적임 따라서, $P(M|X) \\neq P(M)$이므로, $X$와 $Y$는 종속이며, Association이 존재함$M$을 Conditioning하면, $X$와 $Y$ 간에 Association이 사라짐을 증명 M을 Conditioning 한다고 해도 $X$와 $Y$ 간에 Association이 있는지를 알고싶기 때문에, (좌변)$P(X,Y|M) \\neq$ (우변)$P(X|M)P(Y|M)$인지 확인해야 함 (좌변)$P(X,Y|M)$의 꼴을 만들어주기 위해서 $P(X,Y,M)$ $=P(M)P(X,Y|M)$ 정리된 좌변 (우변)$P(X|M)P(Y|M)$의 꼴을 만들어주기 위해서 $P(X,Y,M)$ $=P(X)P(M|X)P(Y|M)$ Bayesian Network Factorization $=P(M)P(X|M)P(Y|M)$ 정리된 우변 정리된 좌변과 정리된 우변을 이용하여 $P(M)P(X,Y|M)=P(M)P(X|M)P(Y|M)$ $P(X,Y|M)=\\cfrac{P(M)P(X|M)P(Y|M)}{P(M)}=P(X|M)P(Y|M)$ 따라서, $P(X,Y|M)=P(X|M)P(Y|M)$이 성립하므로, M을 Conditioning하면 $X$와 $Y$는 독립이되며, 두 변수 간 Association은 존재하지 않음02. Confounder Confounder는 $X$와 $Y$의 공통 원인이 되는 C가 존재하는 구조이며, 이는 선택 편향의 원인이 됨 $P(X,Y,C)=P(X|C)P(Y|C)P(C)$ Bayesian Network Factorization (설명) $X$와 $Y$는 부모노드 C에 영향을 받으므로 각각 $P(X|C)$, $P(Y|C)$로 표현하며, C는 어떠한 노드에도 영향받지 않으므로 $P(C)$로 표현함 $X$와 $Y$ 간에 Association이 있는지 증명 $X$와 $Y$가 서로 독립이 아님을 알고싶기 때문에, (좌변)$P(X,Y) \\neq$ (우변)$P(X)P(Y)$인지 확인하고자 함 (좌변)$P(X,Y)$의 꼴을 이용하여 $P(X,Y)$ $= \\sum_{C}P(X,Y,C)$ C에 대해서 Marginalize하여 표현함 $=\\sum_{C}P(X|C)P(Y|C)P(C)$ Bayesian Network Factorization $=\\sum_{C}P(X|C)P(Y)P(C|Y)$ (설명) $P(Y,C) = P(Y)(C|Y) = P(Y|C)P(C)$ 이므로 $=P(Y) \\sum_{C} P(X|C)P(C|Y)$ 정리된 좌변 (설명) $P(Y)$는 C에 영향받지 않으므로 (우변)$P(X)P(Y)$의 꼴을 이용하여 $P(X)P(Y) = P(Y)P(X)$ $= P(Y) \\sum_{C}P(X,C)$ C에 대해서 Marginalize하여 표현함 (설명) $P(X)=\\sum_{C}P(X,C)$ 이므로 $= P(Y) \\sum_{C}P(C)P(X|C)$ 정리된 우변 정리된 좌변과 정리된 우변을 이용하여 정리된 좌변$P(Y) \\sum_{C} P(X|C)P(C|Y)$와 정리된 우변$P(Y) \\sum_{C}P(C)P(X|C)$를 비교하여,$P(C|Y)=P(C)$가 성립한다면, 정리된 좌변$=$정리된 우변이 성립되어, $P(X,Y)=P(X)P(Y)$가 만족됨 그러나, Confounder는 $Y$ 자체가 부모노드 C에 직접적으로 영향을 받기 때문에 상호 의존 관계가 있을 수밖에 없으므로 $P(C|Y)=P(C)$가 성립될 수 없음 따라서, $P(C|Y) \\neq P(C)$이므로, $P(X,Y) \\neq P(X)(Y)$가 성립되어 $X$와 $Y$는 서로 독립일 수 없으며, C가 Conditioning되지 않는다면, 두 변수 간에는 Association이 존재함$C$를 Conditioning하면, $X$와 $Y$ 간에 Association이 사라짐을 증명 C를 Conditioning 한다고 해도 $X$와 $Y$ 간에 Association이 있는지를 알고싶기 때문에, (좌변)$P(X,Y|C) \\neq$ (우변)$P(X|C)P(Y|C)$인지 확인해야 함 (좌변)$P(X,Y|C)$의 꼴을 만들어주기 위해서 $P(X,Y,C)$ $=P(C)P(X,Y|C)$ 정리된 좌변 (우변)$P(X|C)P(Y|C)$의 꼴을 만들어주기 위해서 $P(X,Y,C)$ $=P(X|C)P(Y|C)P(C)$ Bayesian Network Factorization 정리된 우변 정리된 좌변과 정리된 우변을 이용하여 $P(C)P(X,Y|C)=P(X|C)P(Y|C)P(C)$ $P(X,Y|C)=P(X|C)P(Y|C)$가 성립됨 따라서, C를 Conditioning하면 $P(X,Y|C)=P(X|C)P(Y|C)$가 성립되어 $X$와 $Y$는 독립이되므로, 두 변수 간 Association이 사라짐03. Collider Collider는 $X$와 $Y$가 원인이되어 공통의 결과인 C를 만들어내는 구조임 Collider는 C를 Conditioning하지 않으면 $X$와 $Y$ 간에 Association이 존재하지 않음 그런데, C를 Conditioning하면, $X$와 $Y$ 간에 Association이 형성됨 $P(X,Y,C)=P(X)P(Y)P(C|X,Y)$ Bayesian Network Factorization (설명) $X$와 $Y$는 자신에게 직접적인 영향을 주는 부모노드가 없으므로, 각각 $P(X)$, $P(Y)$로 표현하며, C는 $X$와 $Y$에 직접적인 영향을 받으므로 $P(C|X,Y)$로 표현함 $X$와 $Y$ 간에 Association이 있는지 증명 $X$와 $Y$가 서로 독립이 아님을 알고싶기 때문에, (좌변)$P(X,Y) \\neq$ (우변)$P(X)P(Y)$인지 확인하고자 함 (좌변)$P(X,Y)$ 정리된 좌변 (우변)$P(X)P(Y)$의 꼴을 이용하기 위해서 $P(X,Y) = \\sum_{C}P(X,Y,C)$ C에 대해서 Marginalize하여 표현함 $\\sum_{C}P(X)P(Y)P(C|X,Y)$ (설명) Collider 구조에서의 Bayesian Network Factorization에 의하여 $=P(X)P(Y)\\sum_{C}P(C|X,Y)$ (설명) Marginal Probability $P(X)$와 $P(Y)$는 C에 영향받지 않으므로 $=P(X)P(Y)$ 정리된 우변 (설명) 결과 C를 도출할 수 있는 모든 확률값의 합은 항상 $\\sum_{C}P(C|X,Y)=1$이 성립하므로 정리된 좌변과 정리된 우변을 이용하여 $P(X,Y)=P(X)P(Y)$가 성립됨 따라서, C가 Conditioning되지 않는다면, $P(X,Y)=P(X)P(Y)$가 성립되어 두 변수는 독립이 되며, Association이 존재하지 않음$C$를 Conditioning하면, $X$와 $Y$ 간에 Association이 생겨남을 증명 C를 Conditioning 할 때 $X$와 $Y$ 간에 Association이 있는지를 알고싶기 때문에, (좌변)$P(X,Y|C)=$ (우변)$P(X|C)P(Y|C)$인지 확인해야 함 그러나, Collider의 경우, 위의 식이 아닌, (좌변)$P(X|C)=$(우변)$P(X|C,Y)$가 성립하는지를 대신하여 검토함으로써 독립 여부를 확인할 수 있음 (설명) (좌변)과 달리, (우변)에서는 $Y$까지 Conditioning 하였는데, 위를 만족할 경우, $C$가 Conditioning 되어있다면 이미 독립이 성립하여, $Y$가 추가로 Conditioning 되는지 여부가 아무런 영향을 주지 않는다고 해석할 수 있음 (좌변)$P(X|C)$을 이용하여 $P(X|C)$ $=\\cfrac{P(X)P(C|X)}{P(C)}$ 정리된 좌변 (우변)$P(X|C,Y)$의 꼴을 만들어주기 위해서 다음과 같은 트릭을 사용함 $P(X,C|Y)$ 일종의 트릭?으로 시작함 $=P(X|Y)P(C|Y,X)$ 도출된 식 1 $=P(C|Y)P(X|Y,C)$ 도출된 식 2 도출된 식 1과 도출된 식 2를 이용하여 $P(X|Y)P(C|Y,X) = P(C|Y)P(X|Y,C)$ $\\cfrac{P(X|Y)P(C|Y,X)}{P(C|Y)} = P(X|Y,C) = P(X|C,Y)$ 정리된 우변 정리된 좌변과 정리된 우변을 이용하여 $\\cfrac{P(X)P(C|X)}{P(C)} = \\cfrac{P(X|Y)P(C|Y,X)}{P(C|Y)}$이라면 $X$와 $Y$는 독립이 성립함 이를 정리하면, $\\cfrac{P(C|X)}{P(C)} = \\cfrac{P(C|Y,X)}{P(C|Y)}$로 표현할 수 있음 (설명) Collider에서는 $Y$를 Conditioning 하는지 여부와 상관없이 독립이므로, $P(X)=P(X|Y)$가 성립함 따라서, $\\cfrac{P(C|X)}{P(C)} = \\cfrac{P(C|Y,X)}{P(C|Y)}$가 성립하는지를 확인하면 됨 좌변식은 $X$를 Conditioning하지 않았을 때에 대비하여, $X$를 Conditioning 했을 때 $C$에 미치는 영향(Effect of $X$ on $C$)을 의미함 우변식은 $Y$가 Conditioning 되어있는 상황에서 $X$를 Conditioning하지 않았을 때에 대비하여, $Y$가 Conditioning 되어있는 상황에서 $X$를 Conditioning 했을 때 $C$에 미치는 영향(Effect of $X$ on $C$ after controlling for Y)을 의미함 그러나, Multivariate Regression에서도 그러하듯, 어떠한 통제 변수가 추가되면 나머지 요인들도 반드시 영향을 받게됨 더욱 수학적인 증명은 생략함 따라서, 추가된 통제 변수 $Y$는 반드시 결과에 영향을 미치기 때문에 $\\cfrac{P(C|X)}{P(C)} \\neq \\cfrac{P(C|Y,X)}{P(C|Y)}$이 됨 따라서, Collider에서는 C를 Conditioning하면 $X$와 $Y$의 관계가 독립이 아니게되어 두 변수 간 Association이 생겨남" }, { "title": "(인과추론의 데이터과학) Bayesian Network의 개념", "url": "/posts/Causal-Bayesian-Network-01/", "categories": "Causal Inference", "tags": "Bayesian Network, Probabilistic Graphical Models", "date": "2022-05-08 00:00:00 +0900", "snippet": "이 포스트는 개인적으로 공부한 내용을 정리하고 필요한 분들에게 지식을 공유하기 위해 작성되었습니다.지적하실 내용이 있다면, 언제든 댓글 또는 메일로 알려주시기를 바랍니다. 본 포스트 내용은 인과추론의 데이터과학, 베이지안 네트워크 (Bayesian Network) 강의를 정리한 것임을 밝힙니다. Probability $P(A)$ A라는 사건이 일어날 확률, 다른 사건에 전혀 영향받지 않음 Unconditional Probability 또는 Marginal Probability라고도 불림 $P(A|B)$ B라는 사건이 일어난 상황에서 A라는 사건이 일어날 조건부 확률 Conditional Probability라고 불림 $P(A{\\cap}B)=P(A,B)$ A라는 사건과 B라는 사건이 동시에 나타날 확률 Joint Probability라고 불림 1) $=P(A)P(B|A)$ A가 일어났고, A가 일어난 상황에서 B가 일어난 확률 2) $=P(B)P(A|B)$ B가 일어났고, B가 일어난 상황에서 A가 일어난 확률 a와 b를 이용하여 Bayes' Theorem을 정의할 수 있음 $P(B|A) = \\cfrac{P(B)P(A|B)}{P(A)}$ Joint Probability $P(A,B,C) = P(A)P(B,C|A) = P(A)P(B|A)P(C|A,B)$ Joint Probability는 바로 계산할 수 없으므로, Chain Rule을 통해 Conditional Probability로 풀어준 후 계산함 Marginalize Conditional Probability 또는 Joint Probability를 Marginal Probability로 바꾸는 작업 (예) Independent $A{\\bot}B$ Orthogonal 함 $P(A|B)=P(A)$ $P(A,B)=P(A)P(B|A)=P(A)P(B)$ $\\Leftrightarrow$ Dependent (Correlation 또는 Association이 있음) Conditional Independent 특정 조건 하에서(Conditioning 했을 때) 독립이 되는 경우임 $(A,B|C)=P(A|C)P(B|C)$ $C$라는 조건 하에서 $A$와 $B$가 독립이 됨 Causal Markov Assumption (under DAG) Directly Acyclic Graph(DAG)가 주어져야지만 Causal Markov Assumption을 가정할 수 있음 만약, 그래프가 없는 상황에서 Joint Probability를 계산한다면, Chain Rule을 적용해서 풀어야 함 (e.g.) $P(X,Y,Z)=P(X)P(Y,Z|X)=P(X)P(Y|X)P(Z|X,Y)$ Causal Markov Assumption은 그래프에서 자신에게 직접적인 영향을 주는 노드에만 영향을 받는다는 가정임 (e.g.) 그래프가 $X \\rightarrow Y \\rightarrow Z$로 주어졌고, 여기에 Causal Markov Assumption을 적용한다면? $P(X,Y,Z)=P(X)P(Y|X)P(Z|Y)$ 즉, $P(Z|Y)$를 보면, $Z$는 자신에게 직접적인 영향을 주는 부모 노드인 $Y$만을 조건으로 함 이처럼 Causal Graph의 Joint Probability를 조건부 확률꼴로 분해하는 것을 Bayesian Network Factorization이라고 함 " }, { "title": "공부하며 정리하는 인과추론 02", "url": "/posts/Causal-Inference-02/", "categories": "Causal Inference", "tags": "Causal Inference, Root Cause Analysis", "date": "2022-05-03 00:00:00 +0900", "snippet": "이 포스트는 개인적으로 공부한 내용을 정리하고 필요한 분들에게 지식을 공유하기 위해 작성되었습니다.지적하실 내용이 있다면, 언제든 댓글 또는 메일로 알려주시기를 바랍니다. 본 포스트의 상당 내용은 인과추론의 데이터과학 강의를 정리한 것임을 밝힙니다.지난 이야기복잡한 IT 환경에서 이상징후 및 장애가 발생되었을 때, 이를 인과추론의 방식으로 해결해보고자 하는 큰 꿈을 품고 첫 포스트인 공부하며 정리하는 인과추론 01을 올렸습니다.기계학습 기법에 익숙했던 필자에게는 다소 생소한 데이터 분석 분야라는 것을 알게되었고, 어렵지만 차근차근 공부하며 정복해보고자 하는 욕심이 생겼습니다. 또한 추천시스템 도입 사례와 심슨의 역설 예제를 통해서 인과관계를 어떻게 정의하는지에 따라 인과추론 결과가 달라질 수 있다는 점도 살펴보았습니다.이번 포스트에서는 인과추론의 양대산맥인 Potential Outcomes Framework와 Structural Causal Model(SCM)의 개괄을 살펴보려 합니다.이번 포스트도 역시나 인과추론을 처음 접하는 필자가 인과추론의 데이터과학 강의를 듣고 해당 내용을 중심으로 정리합니다.따라서 자세한 내용은 해당 강의를 보시길 추천드립니다.인과추론의 양대산맥인과관계를 알아내기 위한 인간의 고민은 아리스토텔레스 시대까지도 거슬러 올라갈 수 있을 만큼 굉장히 오래된 역사를 가진다고 합니다(참고).인간의 사유에 근거한, 철학적인 접근으로 인과관계가 무엇인지 고민했던 것이죠.현대는 데이터의 시대입니다. 이에 따라, 인간의 사유에만 의존했던 과거의 철학적 접근 방식을 너머, 더욱 시스템적이고 과학적인 방법으로 인과관계를 분석하려는 방식이 개발되었습니다.위 그림이 바로 그것인데요. 이들은 인과추론의 양대산맥으로, 왼쪽은 Potential Outcomes Framework라는 인과추론 방식이며, 오른쪽은 Structural Causal Model이라는 인과추론 방식입니다.Potential Outcomes Framework는 하버드의 Donald Rubin 교수님이 만든 방법이며, Structural Causal Model은 UCLA의 Judea Pearl 교수님이 개발했다고 합니다.무엇이 다를까요? 구체적인 방법론의 상세 내용은 추후에 하나씩 다루겠지만, 지금은 간략하게만 짚고 가봅시다.Potential Outcomes Framework는 ‘만약 타임머신을 타고 과거로 돌아갔는데 그 원인이 없었더라면 현재 결과는 어땠을까?’라는 관점에서 인과관계를 정의합니다.제목 그대로 Potential Outcome, 즉, 잠재적 결과를 이용하여 인과관계를 보려는 것이죠. 반면에, Structural Causal Model은 인과관계로 표현할 수 있는 변수들을 인과그래프로 모델링한 후, 인과관계를 분석해보려는 시도입니다.이 두 방법 중 어느 방법이 특별히 더 우수하다거나 상호배타적인 관계라고 할 수는 없습니다. 다만, 결이 다른 접근 방법이라고 보면 좋을 것 같습니다.Potential Outcomes Framework의 경우, 해당 방법론의 초석을 다진 연구자들이 최근 노벨 경제학상을 받았다고 합니다.한편, Structural Causal Model을 개척한 Judea Pearl 교수님은 컴퓨터과학 분야에서 가장 권위 있는 상인 Turing Award를 수상했다고 합니다.이러한 단편적인 예만 보아도 두 방식의 차이가 있는데, 전자는 사회과학 분야를 바탕으로 발전되어 왔으며, 후자는 컴퓨터과학 분야를 바탕으로 발전되었다고 합니다.중요한 것은, 결이 다른 두 방법론을 잘 이해하고, 우리가 풀고자 하는 문제에 더 적합한 방법론이 무엇인지 결정하여 잘 활용하는 데 있습니다.훑어보는 Potential Outcomes Framework앞서, Potential Outcomes Framework는 잠재적 결과를 이용하여 인과관계를 분석한다고 했습니다. 이 말에 대해서 조금 더 들여다보도록 하죠.Counterfactual과 Control Group‘독서가 성적에 미치는 영향’을 심슨가족 캐릭터로 예를 들어봅시다.위 그림의 왼쪽을 보았을 때, 책을 읽고 있는 리사(여자)가 진짜 책을 읽었기 때문에 성적이 올랐는지를 Potential Outcomes Framework 관점에서 분석하려 합니다.그러면 리사가 (1)책을 읽은 후 받은 성적과 (2)타임머신을 타고 책을 읽기 전으로 돌아간 후, 이번에는 책을 읽지 않아본 상태로 받은 성적을 비교해보아야 합니다.이때 전자를 (1)실제 결과라고 하고, 후자를 (2)잠재적 결과(Potential Outcome)라 하며, 실제 결과와 잠재적 결과의 차이인 (1)-(2)를 처방(Treatment)의 인과적 효과(Causal Effect)라고 합니다.또한 (2)잠재적 결과를 실제 (1)이라는 사실과 반대되는 사실이라 하여 반사실(Counterfactual)이라고 부릅니다. 아래와 같이 표현할 수 있습니다. Causal effect of the treatment= (Actual outcome for treated if treated) - (Potential outcome for treated if not treated (i.e., Counterfactual))사실 여기에는 문제가 있습니다. 현실 세계에서는 타임머신이 존재하지 않기 때문에 실제로는 잠재적 결과를 관측할 수 없다는 점입니다.이러한 문제를 Fundamental Problem of Causal Inference라고 부릅니다.이처럼 우리는 현실에서 반사실에 대한 잠재적 결과를 관측할 수 없기 때문에 대안을 찾아야 합니다.그 대안은 나와 다른 행동을 한 집단인 Control Group을 관측해보는 것입니다.위 그림의 오른쪽으로 예를 들어보자면, 리사(여자)가 진짜 책을 읽었기 때문에 성적이 올랐는지를 분석하기 위해서 책을 읽지 않은 다른 사람, 즉 바트(남자)와 비교하는 것입니다.즉, 바트가 Control Group이 되는 것이죠. Control Group인 바트가 책을 읽지 않고 받는 성적은 관측 가능하기 때문에, 책을 읽은 리사의 성적과 비교 가능할 것입니다.아래와 같이 표현할 수 있습니다. Observed effect of the treatment= (Actual outcome for treated if treated) - (Actual outcome for untreated if not treated (i.e., Control Group))선택편향(Selection Bias)그렇다면, 실제 결과와 ‘Counterfactual의 잠재적 결과’가 아닌, ‘Control Group의 실제 결과’를 비교하는 방식이 동일한 인과적 효과를 낼 것이라고 확신할 수 있을까요?분명히 차이가 있을 수밖에 없을 것입니다.예를 들어, 리사가 책을 읽었기 때문에 책을 읽지 않은 Control Group인 바트보다 성적이 잘 나온 것인지, 아니면 애초에 리사가 너무나 똑똑해서 책을 읽지 않았어도 성적이 잘 나왔을 것인지 명확하게 말하기 어렵습니다.이처럼, 나와 ‘나의 반사실에 대한 잠재적 결과’가 아닌 ‘남의 결과’를 비교하면서 발생하는 차이를 선택편향(Selection Bias)라고 합니다. 아래와 같이 분해하여 표현할 수 있습니다. Observed effect of the treatment (decomposition)= (Outcome for treated if treated) - (Outcome for untreated if not treated (i.e., Control Group))= (Outcome for treated if treated) - (Outcome for treated if not treated) + (Outcome for treated if not treated) # Zero Some- (Outcome for untreated if not treated) = (Outcome for treated if treated) - (Outcome for treated if not treated) # Causal Effect+ (Outcome for treated if not treated) - (Outcome for untreated if not treated) # Selection Bias= Causal Effect + Selection Bias비교할 수 있는 Control Group 찾기 (Ceteris Paribus)앞서, 관측 가능한 Control Group을 이용하여 비교하면 선택편향이 발생하기 때문에 정확한 인과추론이 어려워진다는 것을 살펴보았습니다.그럼 선택편향 자체를 없앨 수만 있다면 관측 가능한 Control Group을 이용하면서도 인과추론이 가능해지지 않을까요?만약, Control Group이 반사실 집단, 즉, Counterfactual과 동일하다면, 선택편향은 사라질 것입니다.즉, Counterfactual과 최대한 비슷하게 Control Group을 구성하면, 선택편향이 최소화되어 Control Group을 Counterfactual를 대신하여 비교할 수 있다는 것입니다.이는 Control Group을 구성할 때, 타임머신을 타고 과거로 돌아가서 원인이 되는 일을 내가 실제로 행하였는지(즉, 처방을 받았는지(treated)) 여부만 제외하고 Counterfactual과 모든 조건을 동일하게 설정하면 됩니다.이처럼 나머지 모든 조건을 동일하게 둔다는 설정을 라틴어로 Ceteris Paribus라고 합니다.이와 같이 Potential Outcomes Framework는 Counterfactual과 가장 가까운 Control Group을 찾아낼 수 있도록 연구 디자인을 고안하는 접근 방식을 취합니다.하지만 Ceteris Paribus를 만족하는 설정으로 Control Group을 구성하는 것 또한 쉬운 일이 아닙니다.왜냐하면, 현실 세계에서는 우리가 관측하고자 하는 Control Group을 구성하는 Selection Process를 완벽하게 통제하기 어렵기 때문입니다.위 그림은 보조금을 받은 집단과 보조금을 받지 못한 Control Group을 구성하는 과정을 나타내는 예입니다.주목할 것은, Control Group으로 구성된 보조금을 받지 못한 집단의 경우, 보조금 자체를 신청하지 않은 사람도 있겠으나, 어떤 이유에서든지 보조금을 지원했는데 탈락하여 받지 못한 사람도 있을 수 있다는 것입니다.이 경우, 같은 Control Group에 속해있는 사람이라 해도 그 성격이 매우 다를 것이고, 결과적으로 이렇게 구성된 Control Group으로는 Cetris Paribus를 만족하기 어려울 것입니다.결과적으로 인과관계에 대한 추론은 더욱더 어려워질 것입니다.한편, Selection Process를 완전하게 통제할 수 있는 이상적인 경우가 있기는 합니다.바로 Control Group을 구성하는 방식을 동전 던지기로 결정하는 등 완전히 무작위로 정하면 되는데요.이 방법은 머릿속에서 상상하기로 가장 이상적으로 Counterfactual과 가까운 Control Group을 구성할 수 있겠지만, 윤리적 문제나 실현 불가능성 등의 이유로 현실에서 활용하기 어렵습니다.예를 들어, 담배와 폐암의 인과관계를 보기 위해 Control Group을 무작위로 뽑은 후 흡연을 강제할 수는 없겠죠.정리하자면, Potential Outcomes Framework는 무작위로 Control Group을 구성하여 비교하면 인과관계를 쉽게 도출할 수 있겠지만, 현실적으로 어려우니, 이를 대신할 수 있는 적절한 연구 디자인을 고민함으로써 인과관계를 추론한다고 이해하면 좋을 것 같습니다.이에 대한 방법론도 무척 많지만, 기회가 되면 다음 포스트에서 다루겠습니다.훑어보는 Structural Causal Model(SCM)Causal Inference의 또다른 양대산맥으로 볼 수 있는 Sturctural Causal Model 또한 간략하게 훑어보겠습니다.Structural Causal Model은 기본적으로 Bayesian Network를 활용하여 인과관계를 표현하고 추론하는 접근방식입니다.Bayesian Network란, 랜덤 변수의 집합과 유향 비순환 그래프(Directed Acyclic Graph, DAG)를 통하여 그 집합을 조건부 독립으로 표현하는 확률 그래픽 모델입니다.말이 어렵네요. 자세한 내용은 추후에 다루도록 하고, 간단하게 그래프의 노드는 변수를, 엣지(화살표)는 인과관계를 표현한다고 생각하고 넘어갑시다.Causal Graph위 그림은 유향 비순환 그래프로 인과관계를 표현한 Causal Graph의 종류입니다. 각각을 해석하면 다음과 같습니다. (Direct) Causal Effect 원인 변수 $D$가 결과 변수 $Y$에게 직접적으로 영향을 주는 경우입니다. Mediator (Chain) 원인 변수 $D$가 어떠한 중재 변수 $X$를 통하여 결과 변수 $Y$에게 간접적으로 영향을 주는 경우입니다. Confounder (Fork) 변수 $D$와 변수 $Y$에 영향을 주는 공통 변수(Common Cause) $X$가 존재하는 경우입니다. 이때 $X$는 Confounder(교란요인)이라고 부르기도 합니다. 예시는 다음과 같습니다. ($X$ -&gt; $D$ 예시) 술을 마셔서 신발을 신고 잠을 잤다. ($X$ -&gt; $Y$ 예시) 술을 마셔서 다음 날 머리가 아프다. Collider (Immorality) 변수 $D$에도 영향을 받고 변수 $Y$에도 영향을 받는 공통의 결과 변수 $X$가 존재하는 경우입니다. 예시는 다음과 같습니다. ($D$ -&gt; $X$ 예시) 야간 교대근무를 하면 너무 졸리다. ($Y$ -&gt; $X$ 예시) 수면 무호흡증 때문에 잘 못 자면 너무 졸리다. 아래의 그림은 위와 같이 표현될 수 있는 Causal Graph에서 어떻게 연관성(Association)을 해석할 수 있는지 보여줍니다.먼저, $B$ -&gt; $A$ -&gt; $X$를 보면, $B$노드는 원인이 되어 $A$노드를 거쳐서 $X$노드의 결과로 작용됩니다.한편, $B$ -&gt; $Z$ -&gt; $Y$를 보면, $B$노드는 원인이 되어 $Z$노드를 거쳐서 $Y$노드의 결과로 작용됩니다.즉, $X$노드와 $Y$노드 모두 간접적으로 $B$노드의 정보를 공유하고 있습니다. 즉, 두 노드 간 Causal Association이 있다고 볼 수 있습니다.이번에는 $X$노드를 원인 변수로, $Y$노드를 결과 변수로 간주하고 살펴보겠습니다.이 경우는 $X$ -&gt; $W$ -&gt; $Y$ 경로만이 간접적으로나마 Causal Association을 가집니다.그 이외의 경로들은 인과성이 없으므로, Noncausal Association이라 할 수 있는데, 이러한 경로들을 Backdoor Path라고 하며, 아래와 같습니다.정리하자면, Structural Causal Model을 활용한 인과추론 방법은 위와 같은 Noncausal Association을 만드는 모든 Backdoor Path들을 차단함으로써 인과적인 효과를 구하는 것을 목적으로 합니다.d-separation과 d-connection실제로 Causal Graph는 매우 복잡합니다. 그 안에는 수많은 Mediator와 Confounder, 그리고 Collider가 복잡하게 존재할 것입니다.복잡한 그래프 내에서 임의의 두 노드가 의존성을 가지고 있는지 혹은 분리되어 있는지를 확인할 수 있는데, 이러한 일종의 규칙을 d-separation이라고 합니다.여기서의 d는 ‘방향성(direction)’을 의미합니다. 그림을 보면서 이해해보겠습니다.위 그래프에서 ‘특정 노드로 가는 경로를 차단하는 행위’를 Conditioning이라고 표현합니다.원래 그래프에서는 노드 $X$에서 $Y$는 연결되어 있습니다. 즉, d-connected되어 있죠.그런데, 만약 노드 $A$를 Conditioning 한다고 하면, $A$노드로 향하는 경로가 끊겨버립니다.이로 인해 $X$노드에서 $Y$노드로 가는 경로는 차단되는데, 이는 $X$와 $Y$ 사이의 정보 흐름이 차단되어 인과적 연관성마저 사라지게 됩니다. 즉, d-separated 되는 것입니다.반면, 원래 그래프에서 노드 $C$로 가는 경로를 Conditioning하여 차단한다 하더라도, $X$노드에서 $Y$노드는 연결되어 있습니다. 즉, d-connection 되어 있는 것입니다.do-operatorStructural Causal Model은 이처럼 복잡한 그래프에서 Noncausal Association을 만드는 Backdoor Path들을 Conditioning 함으로써 인과관계 효과를 분석하는 방식입니다.그런데 그래프가 매우 복잡한 상황에서 이러한 행위들을 일일이 손으로 한땀한땀 할 수는 없겠죠.Structural Causal Model을 개척한 Judea Pearl 교수님은 이 과정을 체계적으로 수행하고 분석하기 위해서 do-operator를 제안합니다.do-operator는 Confounder로 인해 Backdoor Path가 열려있는 상황에서 Backdoor Path를 차단하는 방법으로, 원인 변수에 영향을 주는 모든 요인을 배제하는 상태로 만들어주는 연산입니다.복잡합니다. 그런데, 개념만 이해하자면, 앞서 Potential Outcomes Framework에서의 Counterfactual처럼 실제로 구할 수 있는 개념이라기보다는 추상적인 개념입니다.즉, 물리적으로 실제 그래프에서 원인 변수에 영향을 주는 요인을 차단한다기 보다는 상상속에서 이루어진다고 생각하면 좋을 것 같네요.위의 그림을 살펴보며 이해해봅시다. $T$노드가 $Y$노드와 인과적 연관성이 있는지 분석하고자 하는데, 왼쪽의 방식은 빨간 점선으로 표현되는 Backdoor Path가 열려있어서 인과관계 분석이 어렵습니다.오른쪽과 같이 do-operator를 적용하여 상상속에서 Backdoor Path를 차단한다면, $T$노드와 $Y$노드의 인과적 연관성을 쉽게(?) 구할 수 있어보입니다.그런데 do-operator가 추상적 개념인데 이것을 도대체 어떻게 계산할 수 있다는 것일까요?do-operator로 표현한 그래프는 실제로 계산이 가능한 조건부확률의 형태로 변환하여 계산할 수 있는데, Judea Pearl 교수님은 이를 가능하도록 하는 일종의 수학적 규칙 집합인 do-calculus를 제안했습니다.이러한 일련의 과정을 Identification이라고 합니다.이때, Identification이 적용되어 변환이 되는 경우도 있겠으나, 불가능한 경우도 있으며, 이러한 Non-identifiable한 경우는 주어진 그래프로 인과적 효과를 구할 수 없음을 의미합니다.정리하자면, Structural Causal Model은 어떠한 현상에 대해서 변수 간의 관계 등을 그래프 형태로 표현하는 방법을 제시하였고, do-operator를 통해서 인과적인 효과를 추론하고자 하는 접근 방법이라고 이해할 수 있겠습니다.정리하며이번 포스트에서는 인과추론의 양대산맥인 Potential Outcomes Framework와 Structural Causal Model을 간략하게나마 훑어보았습니다.내용이 정말로 방대하고 어려워서 많은 공부의 필요성을 느낍니다.본 포스트의 주 참고 자료인 인과추론의 데이터과학이 큰 도움이 된 것 같습니다.이후에는 본 포스트에서 다룬 주요 내용들을 더욱 자세히 살펴본 후 정리하겠습니다." }, { "title": "공부하며 정리하는 인과추론 01", "url": "/posts/Causal-Inference-01/", "categories": "Causal Inference", "tags": "Causal Inference, Root Cause Analysis", "date": "2022-05-02 00:00:00 +0900", "snippet": "이 포스트는 개인적으로 공부한 내용을 정리하고 필요한 분들에게 지식을 공유하기 위해 작성되었습니다.지적하실 내용이 있다면, 언제든 댓글 또는 메일로 알려주시기를 바랍니다. 본 포스트의 상당 내용은 인과추론의 데이터과학 강의를 정리한 것임을 밝힙니다.인과추론을 통해 달성하고자 하는 것IT 운영 관리에서의 근본원인분석과거에는 소프트웨어를 하나의 커다란 덩어리로 개발하는 Monolithic방식으로 개발이 이루어졌습니다.기업이 HW를 구입하면, HW에 대해서 잘 아는 개발자들이 주어진 HW 환경에서 잘 작동할 수 있는 SW를 기획하고 설계했었죠.그런데 HW의 성능은 구입하는 순간부터 변화하지 않기 때문에, IT 인프라가 확대될 때 거기에 맞는 최적의 SW 성능을 계산하여 개발해야만 했습니다.하지만 이제는 클라우드 시대입니다. 클라우드를 활용하면 필요에 따라서 HW의 성능을 유연하게 확장하거나 축소할 수 있습니다.따라서 많은 기업들이 기존의 온프레미스 환경에서 구축하여 운영하던 IT 인프라를 클라우드로 전환하고 있습니다.이에 따라서 SW의 개발 방식도 바뀌게 되었는데, 클라우드 환경에서 Micro Service Architecture(MSA) 방식으로 개발하는 경우가 대표적입니다.MSA 개발 방식은 소프트웨어를 단독으로 실행 가능하고 독립적으로 배치될 수 있는 서비스 단위로 구분하여 마치 레고 블록을 조립하듯 개발하는 방식입니다.HW를 유연하게 확장하거나 축소할 수 있다는 클라우드 환경의 장점과, 개별 서비스 단위들을 필요에 따라 독립적으로 개발 및 배포할 수 있다는 MSA 방식은 찰떡 궁합인 셈이죠.그러나 MSA 방식에도 단점이 있습니다. 바로, 전체 소프트웨어가 커질수록, MSA의 복잡도가 기하급수적으로 늘어날 수 있다는 점입니다.IT 인프라 관리의 관점에서 볼 때, 이러한 복잡성은 클라우드 인프라에서의 이상징후탐지(Anomaly Detection)와 장애에 대한 근본원인분석(Root Cause Analysis, RCA)을 어렵게 하는 요인이 됩니다.즉, Micro Service로 이루어진 시스템에는 각 서비스 컴포넌트들 간 수백~수천가지의 상호 연관성이 존재하고, 이러한 서비스 컴포넌트들이 클라우드 환경에 분산되어 있습니다.이때 개별 컴포넌트마다 각각 매우 많은 메트릭(latency, throughput, resource, error, …)이 측정되는데, 특정 이상징후나 장애가 발생했을 때, 이에 대한 원인을 파악하기 위해 이들을 분석하는 일이 쉽지 않습니다.필자는 이처럼 복잡한 IT 인프라 환경에서 이상징후 및 장애가 발생되었을 때, 이를 해결할 수 있는 AI-ops 기술에 관심을 가지고 있습니다.이를 위해서 인과추론(Cause Inference)의 방법론을 공부하여 정리하고, 추후 IT 인프라에 적용하는 연구를 진행해보고자 합니다.인과추론이 무엇인가?데이터 사이언스 vs 데이터 분석필자와 같이 AI를 전공한 사람은 대부분 인과추론도 기계학습의 한 분야일 것이라고 생각할 수 있습니다.마치 다양한 학습 데이터 X가 있고 정답인 y를 예측하는 문제를 푸는 방식처럼 말이죠.전형적인 데이터 사이언스적인 접근방법이라고 할 수 있습니다.물론 최근에는 인과추론에도 기계학습 기법들을 도입하는 연구가 있다고 합니다만, 기본적인 접근 방법만 놓고 본다면 다소 차이가 있어 보입니다.필자가 AI-ops에 관심을 가지고서 IT 인프라 운영에서 근본원인분석을 수행한 선행연구들을 조사했을 때도 지금까지 배워왔던 기계학습 기술들과는 사뭇 다른 접근법을 취하는 것이 대부분이었습니다.예를 들어서, Causality Graph를 구축하여 장애의 근본원인을 분석하려 한다는 등 말이죠.역시나 기계학습 방식의 접근법에 저의 생각이 오버피팅(?) 되었던지라, 그래프라는 단어가 나오자마자 ‘그래프 임베딩’과 같은 단어들이 머릿속에 먼저 등장했는데요.인과추론의 Introduction을 공부하고 나서야 ‘인과추론이 기계학습과는 결이 다르구나’를 깨달았습니다.결론부터 말하자면, 인과추론은 기계학습과는 달리 원인과 결과의 관계를 합리적으로 알아가기 위한 일련의 방법론을 통칭하는데, 지금까지 배워왔던 기계학습, 즉 데이터 사이언스와는 다른 접근법을 보입니다.오히려 데이터 분석의 영역이라고 봐야겠네요.위 그림은 일반적인 ‘데이터 사이언스’ 방식인 Prediction과 ‘데이터 분석’ 방식인 인과추론이 어떻게 다른지를 간략히 보여줍니다.즉, Prediction은 대개 AI 모델이 학습 데이터를 통해 정답을 예측하는 문제라면, 인과추론은 연구 디자인 방식(Design-based Approach) 또는 그래프 기반 방식(Graph-based Approach)을 활용하는 문제입니다.(각각에 대한 세부적인 내용은 추후 다루겠습니다.) 하여간, 지금 딱 보아도 무언가 접근 방식이 다르죠.인과추론?필자가 인과추론을 공부하며 참고하고 있는 인과추론의 데이터과학에서는 다음과 같은 추천시스템의 협업필터링을 예로 들어 인과추론의 필요성을 설명합니다.어떤 기업이 추천시스템을 도입하고자 하는데, 추천시스템을 도입하는 것이 정말로 사용자의 구매로 이어지는 ‘원인’이 되는지 확인하고 싶다고 합시다.이 예에서 사용자 A가 라면과 콜라를 구입했습니다. 사용자 B도 라면과 콜라를 구입했네요.둘은 비슷한 물건들을 구입했으니 비슷한 사용자라고 볼 수 있겠습니다.사용자 A는 생수도 구매했는데, 추천시스템 알고리즘은 사용자 A와 비슷한 사용자 B에게도 생수를 추천했습니다.만약, 여기서 사용자 B가 생수를 구매했다면, 과연 사용자 B가 생수를 구매한 것이 추천시스템이 잘 작동했기 때문이었을까요?물론 그럴 수도 있겠지만, 생수를 구매한 ‘원인’이 ‘추천시스템’이었다고 단정하기는 어렵겠습니다.예를 들어, 사용자 A와 사용자 B가 모두 자취생이었기 때문에 라면과 콜라를 구매했었고, 자취생이므로 집에 정수기를 두기보다는 생수를 사먹는 것이 편했다고 합시다.그러면 추천시스템이 추천하지 않았더라도 애초에 사용자 B는 생수를 구매했을 수 있습니다.즉, ‘진짜 그것이 원인이 되어서 그 결과를 내었는가?’에 대해서 데이터를 분석하여 보다 합리적이고 체계적으로 답을 내고싶은 것이 인과추론입니다.심슨의 역설로 보는 인과추론또 다른 예를 들어봅시다.위의 예시는 인과추론을 공부하기 시작한 분들이라면 제일 처음으로 봤을 법한 표일겁니다. 심슨의 역설이라 불리는 표죠.이해를 쉽게 하기 위해서 표의 행에 해당하는 Treatment A와 B를 각각 화이자(A)와 모더나 백신(B)이라고 가정해봅시다. 각 %는 사망률을 의미합니다.어떤 백신을 접종받는 것이 좋을까요? ‘Total’ 열을 보면, 사망률이 16%인 화이자(A) Treatment를 받는 편이 사망률이 19%인 모더나(B) Treatment를 받는 것보다 나아 보입니다.그런데, 경증 환자(Mild 열) 그룹만 놓고 보면 사망률이 10%인 모더나(B) Treatment를 받는 것이 나아보입니다.독특한 점은 중증 환자(Severe 열) 그룹만 놓고 보아도 모더나(B) Treatment를 받는 것이 좋아보입니다.즉, 종합적으로 놓고 보면 화이자(A) Treatment가 더 사망률이 낮아서 좋아보이지만, 개별 그룹끼리 놓고 보면 모더나(B) Treatment가 더 좋아보인다는 겁니다.이렇듯 심슨의 역설은 데이터만 놓고 결론을 내리기는 어렵다는 사실을 보여줍니다.사실 이 문제는 인과관계를 어떻게 정의하냐에 따라서 결론이 완전히 달라질 수 있습니다. 두 가지 시나리오로 예를 들어보겠습니다.심슨의 역설 - 시나리오 1 : 경증/중증이 처방의 원인이 되는 경우이 그래프는 경증/중증을 의미하는 Condition C에 따라서 어떤 백신(Treatment T)을 처방하게 되는지 결정되는 경우가 표현된 인과 그래프입니다.예를 들기 위해서 가정을 좀 해보겠는데, 화이자(A)는 상대적으로 구하기 쉬운 반면, 모더나(B)는 굉장히 희귀해서 구하기 어렵고 값도 더 비싸다고 가정해봅시다.그래서 의사가 구하기 쉬운 화이자(A)는 경증 환자에게 처방하기로 하고, 구하기 어렵고 비싼 모더나(B)는 중증 환자에게 처방하기로 합니다.다시 말해서, 경증/중증이기 때문에 화이자/모더나가 처방된 상황으로, Condition이 Treatment의 원인이되고, 이에 대한 결과로 Treatment가 결정되는 상황인 것입니다.이를 C -&gt; T(처방)으로 표현합니다.또한, 상식적으로 중증 환자는 더 쉽게 사망에 이를 것입니다. 이를 C -&gt; Y(결과)로 표현합니다.이렇게 인과관계를 가정한다면, 경증/중증 여부, 즉 Condition C가 백신 처방 T의 원인이 되기도 하며, 사망률 Y의 원인이 되기도 합니다.이처럼 처방과 사망률 모두에 연관되어 있어서 특정 원인과 결과의 연관성을 왜곡시키는 C와 같은 공통 원인 변수를 교란변수라 부릅니다.구체적인 내용은 추후에 다루겠지만, 교란변수가 있는 경우, 교란변수를 조정함으로써 C -&gt; T의 인과관계를 끊어내야 합니다.즉, 경증/중증의 Condition과 상관 없이, 동일한 Condition을 가진 그룹 내에서만 비교를 하도록 실험이 설정되면 가능하겠죠.이렇게 C -&gt; T의 인과관계를 끊어내면, T -&gt; Y의 인과관계에만 집중하여 분석할 수 있습니다.T -&gt; Y 인과관계만 놓고 본다면, 각 그룹에서 더 좋은 백신을 처방 하는 것(원인)이 더 낮은 사망률(결과)로 이어진다는 것을 의미합니다.정리하자면, 위와 같은 인과관계 설정에서는 경증/중증 각각의 그룹에서 더 낮은 사망률을 기록한 백신 B를 처방하는 것이 바람직하게 됩니다.심슨의 역설 - 시나리오 2 : 처방이 경증/중증의 원인이 되는 경우이번에는 시나리오 1과는 다른 예를 들어보겠습니다.화이자(A)를 처방하는지 또는 모더나(B)를 처방하는지에 따라서 환자의 경증/중증 여부가 달라지는 독특한 설정을 해보겠습니다.예를 들어, 모더나(B)는 아주아주 구하기 힘들어서, 모더나를 처방 받는 환자는 대략 1년을 기다려야 한다고 극단적으로 가정해보겠습니다.반면 화이자(A)는 이처럼 기다릴 필요 없이 바로 처방받을 수 있다고 합시다.이 경우, 모더나(B)를 처방 받은 사람이 실제로 백신을 투여받기까지 1년 동안 병세가 점점 심해져서 결국 중증이 되어 사망할 가능성이 높아질 수 있습니다.즉, 어떤 백신을 처방했는지가 경증/중증에 영향을 미쳐서 사망률에도 영향을 주는 T -&gt; C -&gt; Y의 인과관계가 생긴 것입니다.이 경우, 모더나(B) 자체의 효과는 화이자(A)보다 좋을 수 있겠지만, 경증 환자를 중증으로 만들어버릴 정도로 오랜 시간 백신 투여가 지연되게 되어 사망에 이르게 되므로, 화이자(A)를 처방하는 편이 낫습니다.심슨의 역설에서 살펴볼 수 있듯, 인과관계를 어떻게 정의하느냐에 따라 결론이 달라질 수 있습니다.정리하며이번 포스트에서는 인과추론이 무엇이며, 왜 필요한지 간략하게나마 살펴보았습니다.기계학습에 익숙한 필자에게는 다소 낯선 접근 방법이기도 하지만, 독특한 방식으로 데이터를 분석하여 인과관계를 파악한다는 방식이 신기하기도 합니다.IT 인프라의 운영 관리에서 많이 연구되고 있는 방식인만큼, 더욱 공부할 필요성을 느낍니다.다음 포스트에서는 인과추론의 양대산맥으로 볼 수 있는 Potential Outcome Framework와 Structural Causal Model을 간단하게 살펴보겠습니다.참고자료[1] 인과추론의 데이터과학[2] Introduction to Causal Inference (Brady Neal)" } ]
