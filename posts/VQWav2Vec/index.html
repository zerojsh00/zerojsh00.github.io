<!DOCTYPE html><html lang="ko" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="(Speech Recognition) VQ-Wav2Vec 리뷰 및 설명" /><meta name="author" content="simon sanghyeon" /><meta property="og:locale" content="ko" /><meta name="description" content="이 포스트는 개인적으로 공부한 내용을 정리하고 필요한 분들에게 지식을 공유하기 위해 작성되었습니다. 지적하실 내용이 있다면, 언제든 댓글 또는 메일로 알려주시기를 바랍니다." /><meta property="og:description" content="이 포스트는 개인적으로 공부한 내용을 정리하고 필요한 분들에게 지식을 공유하기 위해 작성되었습니다. 지적하실 내용이 있다면, 언제든 댓글 또는 메일로 알려주시기를 바랍니다." /><link rel="canonical" href="https://zerojsh00.github.io/posts/VQWav2Vec/" /><meta property="og:url" content="https://zerojsh00.github.io/posts/VQWav2Vec/" /><meta property="og:site_name" content="Simon’s Research Center" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-07-22T00:00:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="(Speech Recognition) VQ-Wav2Vec 리뷰 및 설명" /><meta name="twitter:site" content="@" /><meta name="twitter:creator" content="@simon sanghyeon" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"simon sanghyeon"},"dateModified":"2022-07-31T21:50:46+09:00","datePublished":"2022-07-22T00:00:00+09:00","description":"이 포스트는 개인적으로 공부한 내용을 정리하고 필요한 분들에게 지식을 공유하기 위해 작성되었습니다. 지적하실 내용이 있다면, 언제든 댓글 또는 메일로 알려주시기를 바랍니다.","headline":"(Speech Recognition) VQ-Wav2Vec 리뷰 및 설명","mainEntityOfPage":{"@type":"WebPage","@id":"https://zerojsh00.github.io/posts/VQWav2Vec/"},"url":"https://zerojsh00.github.io/posts/VQWav2Vec/"}</script><title>(Speech Recognition) VQ-Wav2Vec 리뷰 및 설명 | Simon's Research Center</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Simon's Research Center"><meta name="application-name" content="Simon's Research Center"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "AMS" } }, tex2jax: { inlineMath: [ ['$', '$'] ], displayMath: [ ['$$', '$$'] ], processEscapes: true, } }); MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) { alert("Math Processing Error: "+message[1]); }); MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) { alert("Math Processing Error: "+message[1]); }); </script> <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script><meta name="google-site-verification" content="J_a4XJ2oefe52p6EYvjTFdh9LW5Yc5RyGg1HpQOjWaA" /><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> <img src="/assets/img/avatar.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Simon's Research Center</a></div><div class="site-subtitle font-italic">성장하는 연구원의 공책</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/zerojsh00" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['zerojsh00','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>(Speech Recognition) VQ-Wav2Vec 리뷰 및 설명</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>(Speech Recognition) VQ-Wav2Vec 리뷰 및 설명</h1><div class="post-meta text-muted"><div> By <em> Sanghyeon </em></div><div class="d-flex"><div> <span> Posted <em class="timeago" data-ts="1658415600" data-toggle="tooltip" data-placement="bottom" data-tooltip-df="llll" > 2022-07-22 </em> </span> <span> Updated <em class="timeago" data-ts="1659271846" data-toggle="tooltip" data-placement="bottom" data-tooltip-df="llll" > 2022-07-31 </em> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1792 words"> <em>9 min</em> read</span></div></div></div><div class="post-content"><p>이 포스트는 개인적으로 공부한 내용을 정리하고 필요한 분들에게 지식을 공유하기 위해 작성되었습니다. 지적하실 내용이 있다면, 언제든 댓글 또는 메일로 알려주시기를 바랍니다.</p><hr /><h1 id="01-개요">01. 개요</h1><p><code class="language-plaintext highlighter-rouge">VQ-Wav2Vec</code>의 핵심은 Wav2Vec에 <code class="language-plaintext highlighter-rouge">Vector Quantization</code>을 적용하였다는 점이다. VQ-Wav2Vec은 Wav2Vec 방식과 유사한 self-supervised context prediction task를 수행하며 학습되는데, continuous한 음성 신호의 세그먼트(segments)를 quantization(양자화) 함으로써 discrete한 representation으로 학습하는 방식을 제안한다. 이러한 discretization은 <code class="language-plaintext highlighter-rouge">Gumbel-Softmax</code>와 <code class="language-plaintext highlighter-rouge">k-means 클러스터링</code>을 통해서 수행할 수 있다.</p><p>왜 굳이 discretization을 수행하는 것일까? BERT와 같은 NLP 태스크에서는 입력되는 단어들의 시퀀스가 discrete한데, VQ-Wav2Vec 방식으로 discretization을 수행하면 이산화된 음성 신호를 BERT 같은 모델에 직접 입력값으로 사용할 수 있을 것이라는 아이디어에서 착안된 것이다.</p><p>실제로 VQ-Wav2Vec 저자들은 실험을 통해서 BERT와 함께 학습하여 TIMIT 음소 분류 문제 및 WSJ 음성 인식 문제에서 새로운 SOTA를 달성했다고 주장한다.</p><hr /><h1 id="02-vq-wav2vec의-학습">02. VQ-Wav2Vec의 학습</h1><p><img data-src="/assets/img/2022-07-22-VQWav2Vec/fig01.png" alt="fig01" data-proofer-ignore></p><p>VQ-Wav2Vec은 기본적으로 Wav2Vec과 동일한 방식으로, negative 오디오 샘플로부터 true 오디오 샘플을 구별해내는 <code class="language-plaintext highlighter-rouge">contrastive loss</code>를 최소화하며 학습한다.</p><p>새롭게 추가된 부분이 있다면, 위 그림 (a)에서 연두색 $q$ 부분이다. 기존 Wav2Vec에서는 <code class="language-plaintext highlighter-rouge">encoder network</code>인 $f:\mathcal{X} \mapsto \mathcal{Z}$와 <code class="language-plaintext highlighter-rouge">context network</code>인 $g:\mathcal{\hat{Z}} \mapsto \mathcal{C}$가 컨볼루션 네트워크로 구성되어 있을 뿐이었다.</p><p>VQ-Wav2Vec에서는 새롭게 <code class="language-plaintext highlighter-rouge">quantization module</code> $q:\mathcal{Z} \mapsto \mathcal{\hat{Z}}$이 추가되었다. 즉, encoder network $f$는 30ms의 원시 음성 신호를 10ms의 dense representation $\mathbf{z}$로 인코딩하는데, quantizer $q$에 의해 dense representation $\mathbf{z}$가 discrete한 <code class="language-plaintext highlighter-rouge">원 핫 벡터(one-hot vector)</code>로 바뀌게 된다. 최종적으로 이러한 one-hot 벡터를 이용하여 다시금 dense representation $\mathbf{\hat{z}}$를 복원해낸다. 이처럼 dense representation $\mathbf{z}$를 discrete한 one-hot 벡터로 바꾸는 방법은 <code class="language-plaintext highlighter-rouge">Gumbel-Softmax</code>를 활용하는 방법과 <code class="language-plaintext highlighter-rouge">K-means 클러스터링</code>을 활용하는 방법이 있다. 이후 과정을 Wav2Vec과 동일하게 학습한다.</p><h2 id="gumbel-softmax를-활용한-방법"><span class="mr-2">Gumbel-Softmax를 활용한 방법</span><a href="#gumbel-softmax를-활용한-방법" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h3 id="gumbel-softmax에-대한-간단한-개념"><span class="mr-2">Gumbel-Softmax에 대한 간단한 개념</span><a href="#gumbel-softmax에-대한-간단한-개념" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 300 300'%3E%3C/svg%3E" data-src="/assets/img/2022-07-22-VQWav2Vec/fig02.png" alt="fig02" width="300" height="300" data-proofer-ignore></p><p>우선 <a href="https://arxiv.org/pdf/1611.01144.pdf">Gumbel-Softmax</a>를 간단하게 살펴보자. 위의 그림 (1)과 같은 일반적인 뉴럴 네트워크 구조에서 $\mathbf{x}(\theta)$와 같이 deterministic 하며 미분 가능한 노드에서는 체인 룰에 의해서 backpropagation을 수행할 수 있다. 반면, (2)와 같이 중간에 한 노드에서 softmax - argmax 등을 거쳐 categorical 변수들에 대해 sampling을 수행하는 노드는 stochastic한 요소가 들어가게 되어 backpropagation을 수행할 수 없게된다.</p><p>이러한 문제를 해결하기 위해 Gumbel-Softmax는 확률적으로 sampling을 할 수 있으면서도 backpropagation이 가능한 방식을 제시한다. 원 논문의 설명은 장황하지만, VQ-Wav2Vec 논문을 참고하여 간단하게 아래와 같이 정리할 수 있다.</p><p><strong>[수식 1]</strong> $p_j=\cfrac{\exp{(l_j+v_j)/\tau}}{\sum_{k=1}^{V}\exp{(l_k+v_k)/\tau}}$</p><p>각 notation에 대한 설명은 다음과 같다.</p><ul><li>$l \in \mathbb{R}^V$은 encoder network를 거쳐서 나온 dense representation $\mathbf{z}$에 대해 linear layer와 ReLU, 그리고 또 한번의 linear layer를 통과한 로짓값이다.<li><p>$u$는 uniform distribution $U(0, 1)$에서 랜덤하게 sampling한 값들이며, 이를 활용하여 log 연산을 취함으로써 다음과 같이 $v = -\log(-\log(u))$를 정의한다. 이를 코드로 보면 아래와 같다.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre>  <span class="kn">import</span> <span class="n">torch</span>
  <span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
  <span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
  <span class="kn">from</span> <span class="n">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>

  <span class="k">def</span> <span class="nf">sample_gumbel</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-20</span><span class="p">):</span>
      <span class="n">U</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">shape</span><span class="p">).</span><span class="nf">cuda</span><span class="p">()</span>
      <span class="k">return</span> <span class="o">-</span><span class="nc">Variable</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="o">-</span><span class="n">torch</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">U</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span> <span class="o">+</span> <span class="n">eps</span><span class="p">))</span>
</pre></table></code></div></div><li><p>$\tau$는 temperature로 불리는데, 이 값이 0에 가까울수록 one hot 벡터처럼 categorical한 분포를 가지게되며, 값이 클수록 uniform한 분포를 가지게 된다.</p><p><img data-src="/assets/img/2022-07-22-VQWav2Vec/fig03.png" alt="fig03" data-proofer-ignore></p><li><p>$p_j$를 코드로 보면 아래와 같다.</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>  <span class="k">def</span> <span class="nf">gumbel_softmax_sample</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">temperature</span><span class="p">):</span>
      <span class="n">y</span> <span class="o">=</span> <span class="n">logits</span> <span class="o">+</span> <span class="nf">sample_gumbel</span><span class="p">(</span><span class="n">logits</span><span class="p">.</span><span class="nf">size</span><span class="p">())</span>
      <span class="k">return</span> <span class="n">F</span><span class="p">.</span><span class="nf">softmax</span><span class="p">(</span><span class="n">y</span> <span class="o">/</span> <span class="n">temperature</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></table></code></div></div><p>앞서 Gumbel-Softmax의 핵심은 softmax-argmax 등의 stochastic 연산을 뉴럴 네트워크 내 노드에서 수행하여도 backpropagation이 가능해진다고 했다. 이에 대해서는 아래와 같은 트릭이 적용된다.</p></ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">gumbel_softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">temperature</span><span class="p">):</span>
    <span class="s">"""
    input: [*, n_class]
    return: [*, n_class] an one-hot vector
    """</span>
    <span class="n">y</span> <span class="o">=</span> <span class="nf">gumbel_softmax_sample</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">temperature</span><span class="p">)</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="nf">size</span><span class="p">()</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">ind</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">y_hard</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">y</span><span class="p">).</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">y_hard</span><span class="p">.</span><span class="nf">scatter_</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">ind</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">y_hard</span> <span class="o">=</span> <span class="n">y_hard</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="o">*</span><span class="n">shape</span><span class="p">)</span>
    <span class="nf">return </span><span class="p">(</span><span class="n">y_hard</span> <span class="o">-</span> <span class="n">y</span><span class="p">).</span><span class="nf">detach</span><span class="p">()</span> <span class="o">+</span> <span class="n">y</span>
</pre></table></code></div></div><p>이 때의 return 값을 주목해보겠다. 순전파 연산에서는 <code class="language-plaintext highlighter-rouge">(-y).detach() + y</code>로 y는 소거되고, 결과적으로 softmax 연산을 통해 구한 one-hot 벡터인 <code class="language-plaintext highlighter-rouge">y_hard</code> 변수가 return된다. 한편, backpropagation 연산에서는 <code class="language-plaintext highlighter-rouge">.detach()</code> 함수가 적용되어 있지 않은 y에 대해서만 gradient가 흘러갈 수 있게된다. 즉, backpropagation이 가능한 것이다!</p><h3 id="gumbel-softmax를-활용한-vq-wav2vec-학습"><span class="mr-2">Gumbel-Softmax를 활용한 VQ-Wav2Vec 학습</span><a href="#gumbel-softmax를-활용한-vq-wav2vec-학습" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 300 300'%3E%3C/svg%3E" data-src="/assets/img/2022-07-22-VQWav2Vec/fig04.png" alt="fig04" width="300" height="300" data-proofer-ignore></p><p>quantizer $q$에 의해서, 10ms로 인코딩된 dense representation $\mathbf{z}$는 위의 과정을 거쳐 discrete한 one-hot 벡터로 바뀌게 된다. 이제 이 one-hot 벡터는 codebook이라 불리는 임베딩 행렬 $\mathbf{e} \in \mathbb{R}^{V \times d}$와 곱해짐으로써 $\mathbf{\hat{z}}=\mathbf{e}_i$벡터를 얻게 된다.</p><h2 id="k-means-클러스터링을-활용한-방법"><span class="mr-2">K-means 클러스터링을 활용한 방법</span><a href="#k-means-클러스터링을-활용한-방법" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 300 300'%3E%3C/svg%3E" data-src="/assets/img/2022-07-22-VQWav2Vec/fig05.png" alt="fig05" width="300" height="300" data-proofer-ignore></p><p>앞서 살펴보았던 Gumbel-Softmax를 활용한 방식은 결국 벡터를 quantization하기 위한 트릭이었다. 이에 대한 대안으로 저자는 K-means 클러스터링을 활용하는 방식도 제안하였는데, 이는 encoder network의 출력인 10ms의 벡터 $\mathbf{z}$와 임베딩 행렬 내의 벡터 $\mathbf{e}$들 간 유클리디안 거리를 계산하고, 이와 가장 가까운 벡터를 활용하여 $\mathbf{\hat{z}}=\mathbf{e}_i$벡터를 얻는 방식이다. 이러한 방식도 미분 불가능한 $\arg \min$연산을 포함하지만, Gumbel-Softmax 때와 같이 역전파 과정을 섬세히 설계함으로써 backpropagation이 가능하도록 설정할 수 있다.</p><hr /><h1 id="03-vq-wav2vec을-접목한-bert-사전-학습">03. VQ-Wav2Vec을 접목한 BERT 사전 학습</h1><p>VQ-Wav2Vec의 학습을 마치고 나면, discretization이 적용된 오디오 데이터 특징을 추출할 수 있다. 이러한 discrete 입력값은 MLM 방식으로 학습하는 BERT의 사전 학습에 활용될 수 있다. 즉, BERT를 이용해서 입력값에 대한 양방향의 맥락을 학습하는 것이다.</p><p>BERT의 사전 학습을 마치고 나면, discrete 입력값이 BERT에 입력되었을 때, 양방향 맥락이 고려된 representation들이 추출될 수 있는데, 이는 곧 speech recognition 태스크의 음향 모델의 입력값이 될 수 있다.</p><hr /><h1 id="04-참고-문헌">04. 참고 문헌</h1><p>[1] <a href="https://arxiv.org/pdf/1910.05453.pdf">Baevski, Alexei, Steffen Schneider, and Michael Auli. “vq-wav2vec: Self-supervised learning of discrete speech representations.” arXiv preprint arXiv:1910.05453 (2019).</a><br /> [2] <a href="https://ratsgo.github.io/speechbook/docs/neuralfe/wav2vec">ratsgo 님의 블로그</a><br /> [3] <a href="https://youtu.be/mPtyfqWHs3s">김정희 님의 발표자료</a></p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/speech-recognition/'>Speech Recognition</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/speech-ai/" class="post-tag no-text-decoration" >Speech AI</a> <a href="/tags/wav2vec/" class="post-tag no-text-decoration" >Wav2Vec</a> <a href="/tags/feature-extraction/" class="post-tag no-text-decoration" >Feature Extraction</a> <a href="/tags/paper-review/" class="post-tag no-text-decoration" >Paper Review</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=%28Speech+Recognition%29+VQ-Wav2Vec+%EB%A6%AC%EB%B7%B0+%EB%B0%8F+%EC%84%A4%EB%AA%85+-+Simon%27s+Research+Center&url=https%3A%2F%2Fzerojsh00.github.io%2Fposts%2FVQWav2Vec%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=%28Speech+Recognition%29+VQ-Wav2Vec+%EB%A6%AC%EB%B7%B0+%EB%B0%8F+%EC%84%A4%EB%AA%85+-+Simon%27s+Research+Center&u=https%3A%2F%2Fzerojsh00.github.io%2Fposts%2FVQWav2Vec%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fzerojsh00.github.io%2Fposts%2FVQWav2Vec%2F&text=%28Speech+Recognition%29+VQ-Wav2Vec+%EB%A6%AC%EB%B7%B0+%EB%B0%8F+%EC%84%A4%EB%AA%85+-+Simon%27s+Research+Center" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div><script src="https://utteranc.es/client.js" repo="zerojsh00/zerojsh00.github.io" issue-term="pathname" theme="github-light" crossorigin="anonymous" async> </script></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/Network-Policy/">(K8S) 네트워크 정책(Network Policy) 기초 개념</a><li><a href="/posts/CNI-Weave/">(K8S) CNI Weave의 기초 개념</a><li><a href="/posts/Container-Networking-Interface/">(K8S) 네트워크 기초 정리 - CNI</a><li><a href="/posts/Storage-in-Docker/">(K8S) 도커의 스토리지(Storage in Docker)</a><li><a href="/posts/Security-Context/">(K8S) Security Context</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/k8s/">K8S</a> <a class="post-tag" href="/tags/kubernetes/">Kubernetes</a> <a class="post-tag" href="/tags/paper-review/">Paper Review</a> <a class="post-tag" href="/tags/security/">Security</a> <a class="post-tag" href="/tags/network/">Network</a> <a class="post-tag" href="/tags/speech-ai/">Speech AI</a> <a class="post-tag" href="/tags/scheduling/">Scheduling</a> <a class="post-tag" href="/tags/nlp/">NLP</a> <a class="post-tag" href="/tags/storage/">Storage</a> <a class="post-tag" href="/tags/asr/">ASR</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/Wav2Vec/"><div class="card-body"> <em class="timeago small" data-ts="1658329200" > 2022-07-21 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>(Speech Recognition) Wav2Vec(1.0) 리뷰 및 설명</h3><div class="text-muted small"><p> 이 포스트는 개인적으로 공부한 내용을 정리하고 필요한 분들에게 지식을 공유하기 위해 작성되었습니다. 지적하실 내용이 있다면, 언제든 댓글 또는 메일로 알려주시기를 바랍니다. 00. 들어가며 음성 전문가의 도메인 지식과 푸리에 변환 등을 거쳐 추출해내는 음성 신호인Mel-Frequency Cepstral Coefficients(MFCC)와는 달리...</p></div></div></a></div><div class="card"> <a href="/posts/Wav2Vec2/"><div class="card-body"> <em class="timeago small" data-ts="1659193200" > 2022-07-31 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>(Speech Recognition) Wav2Vec2.0 리뷰 및 설명</h3><div class="text-muted small"><p> 이 포스트는 개인적으로 공부한 내용을 정리하고 필요한 분들에게 지식을 공유하기 위해 작성되었습니다. 지적하실 내용이 있다면, 언제든 댓글 또는 메일로 알려주시기를 바랍니다. 00. 들어가며 2020년, Facebook에서 Wav2Vec 2.0을 발표했다. 앞서 살펴보았던 Wav2Vec 및 VQ-Wav2Vec과 마찬가지로, Wav2Vec 2.0 ...</p></div></div></a></div><div class="card"> <a href="/posts/MFCC/"><div class="card-body"> <em class="timeago small" data-ts="1658242800" > 2022-07-20 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>(Speech Recognition) 음성 신호 특징 추출과 MFCC</h3><div class="text-muted small"><p> 이 포스트는 개인적으로 공부한 내용을 정리하고 필요한 분들에게 지식을 공유하기 위해 작성되었습니다. 지적하실 내용이 있다면, 언제든 댓글 또는 메일로 알려주시기를 바랍니다. 00. 들어가며 Wav2Vec과 같이 뉴럴 네트워크 기반의 음성 신호 특징 추출 기법이 개발되기 전에는 음성 도메인 지식과 공식들에 기반하여 음성 신호의 특징을 추출하였다. 대표...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/Wav2Vec/" class="btn btn-outline-primary" prompt="Older"><p>(Speech Recognition) Wav2Vec(1.0) 리뷰 및 설명</p></a> <a href="/posts/Connectionist-Temporal-Classification/" class="btn btn-outline-primary" prompt="Newer"><p>(Speech Recognition) Connectionist Temporal Classification 리뷰 및 설명</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://github.com/zerojsh00">Sanghyeon</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/k8s/">K8S</a> <a class="post-tag" href="/tags/kubernetes/">Kubernetes</a> <a class="post-tag" href="/tags/paper-review/">Paper Review</a> <a class="post-tag" href="/tags/security/">Security</a> <a class="post-tag" href="/tags/network/">Network</a> <a class="post-tag" href="/tags/speech-ai/">Speech AI</a> <a class="post-tag" href="/tags/scheduling/">Scheduling</a> <a class="post-tag" href="/tags/nlp/">NLP</a> <a class="post-tag" href="/tags/storage/">Storage</a> <a class="post-tag" href="/tags/asr/">ASR</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/ko.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script>
